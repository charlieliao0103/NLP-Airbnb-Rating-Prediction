{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787923b4",
   "metadata": {},
   "source": [
    "# Predicting Star Ratings of Edinburgh Airbnbs through Review Texts Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a2bb0",
   "metadata": {},
   "source": [
    "# Notebook 5: Modelling_Review_Collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d621c2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505f46e",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f0775",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497aff3",
   "metadata": {},
   "source": [
    "## Import Libraries <a id='a1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eff6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Main Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scipy Library for sparse  matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import html\n",
    "import contractions\n",
    "import langid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from langid.langid import LanguageIdentifier\n",
    "\n",
    "# Download from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Feature Extraction Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Dummy Classifer \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Modelling Libraries\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db98bf",
   "metadata": {},
   "source": [
    "#### Loading Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae965a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collapsed review data\n",
    "df_collapsed_reviews_by_listing= joblib.load('data/df_collapsed_reviews_by_listing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834226c",
   "metadata": {},
   "source": [
    "#### Ignore userwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b6a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6581506",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90bd3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_tokenizer(sentence):\n",
    "    \n",
    "    # Remove HTML tags and entities\n",
    "    sentence = html.unescape(sentence)\n",
    "    sentence = re.sub(r'<[^>]+>', '', sentence)\n",
    "    \n",
    "    # Remove HTML white spaces \\r<br/> and <br/>\n",
    "    sentence = re.sub(r'(\\r<br/>)|(<br/>)', ' ', sentence)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    \n",
    "    # Lowercase text\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # Remove emails\n",
    "    sentence = re.sub(r'\\S*@\\S*\\s?', '', sentence)\n",
    "    \n",
    "    # Remove emojis\n",
    "    sentence = sentence.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove special characters\n",
    "    sentence = re.sub(r'[^A-Za-z\\s]', '', sentence)\n",
    "    \n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]+', '', sentence)\n",
    "    \n",
    "    # Remove weblinks\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    \n",
    "    # Expand contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Remove non-English text characters\n",
    "    if langid.classify(sentence)[0] != 'en':\n",
    "        sentence = ''\n",
    "    \n",
    "    # Remove English stopwords\n",
    "    eng_stop_words=stopwords.words('english')\n",
    "    # Append EDA insights driven stop words\n",
    "    eng_stop_words.extend(['apartment','flat','edinburgh','could', 'would', 'x', 'caroline', 'stay']) \n",
    "    stop_words = set(eng_stop_words)\n",
    "    tokens = sentence.split()\n",
    "    sentence = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "    \n",
    "    # Perform text stemming\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = ' '.join([lemmatizer.lemmatize(word, pos = 'v') for word in sentence.split()])\n",
    "    \n",
    "    # Tokenize cleaned sentence\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a4f60",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0b859",
   "metadata": {},
   "source": [
    "#### Check the uncollapsed review data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a881930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains all reviews listed individually is of dimension (5908, 45)\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains all reviews listed individually is of dimension {df_collapsed_reviews_by_listing.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cb17f",
   "metadata": {},
   "source": [
    "# Modelling Set up <a id='a3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a4d59",
   "metadata": {},
   "source": [
    "## Split the variables <a id='a3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669293d",
   "metadata": {},
   "source": [
    "We need to split the variables into dependent and independent variables before we start fitting the model. The target variable will be the sentiment scores. We will focus on the overall sentiment score and attempt to further analyse the reviews with the other sub-rating transformed sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the future model\n",
    "X = df_collapsed_reviews_by_listing.drop(['Overall_sentiment',\n",
    "                                          'accuracy_sentiment',\n",
    "                                          'cleanliness_sentiment',\n",
    "                                          'checkin_sentiment',\n",
    "                                          'communication_sentiment',\n",
    "                                          'location_sentiment',\n",
    "                                          'value_sentiment'], axis=1)\n",
    "y = df_collapsed_reviews_by_listing['Overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36fc6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (5908, 38)\n",
      "y Shape: (5908,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ce381f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>55.95759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-3.18805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom_num</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_availability</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_bath</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_year</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_year</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_month</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_year</th>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_from_Edinburgh</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_a few days or more</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_email</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_phone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_work_email</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>My wife and I stayed at this beautiful apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              0\n",
       "host_response_rate                                                                        100.0\n",
       "host_acceptance_rate                                                                       92.0\n",
       "host_is_superhost                                                                             1\n",
       "latitude                                                                               55.95759\n",
       "longitude                                                                              -3.18805\n",
       "accommodates                                                                                  2\n",
       "bathroom_num                                                                                1.0\n",
       "beds                                                                                        1.0\n",
       "minimum_nights                                                                                3\n",
       "maximum_nights                                                                               30\n",
       "has_availability                                                                              1\n",
       "number_of_reviews                                                                           532\n",
       "number_of_reviews_ltm                                                                        82\n",
       "instant_bookable                                                                              0\n",
       "calculated_host_listings_count                                                                1\n",
       "calculated_host_listings_count_entire_homes                                                   1\n",
       "calculated_host_listings_count_private_rooms                                                  0\n",
       "calculated_host_listings_count_shared_rooms                                                   0\n",
       "reviews_per_month                                                                          3.38\n",
       "private_bath                                                                                  1\n",
       "host_since_year                                                                            2009\n",
       "host_since_month                                                                             12\n",
       "first_review_year                                                                          2011\n",
       "first_review_month                                                                            1\n",
       "last_review_year                                                                           2023\n",
       "last_review_month                                                                            12\n",
       "host_from_Edinburgh                                                                           1\n",
       "host_response_time_a few days or more                                                         0\n",
       "host_response_time_within a day                                                               0\n",
       "host_response_time_within a few hours                                                         1\n",
       "host_response_time_within an hour                                                             0\n",
       "host_verifications_email                                                                      1\n",
       "host_verifications_phone                                                                      1\n",
       "host_verifications_work_email                                                                 0\n",
       "room_type_Entire home/apt                                                                     1\n",
       "room_type_Hotel room                                                                          0\n",
       "room_type_Private room                                                                        0\n",
       "comments                                      My wife and I stayed at this beautiful apartme..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f58e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b4732",
   "metadata": {},
   "source": [
    "The dependent variable stored as **X** contains all cleaned listing related numerical data as well as a column that contains the guest review data.\n",
    "\n",
    "The independent variable stored as **y** contains the **Overall sentiment score** that was transformed from the listing's average overall rating score:\n",
    "- 1 was denoted by Overall rating score > 4.8\n",
    "- 0 was denoted by Overall rating score < 4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17428dc3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c2127",
   "metadata": {},
   "source": [
    "## Target Variable Distribution <a id='a3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcfd84",
   "metadata": {},
   "source": [
    "In the EDA notebook, we analyzed the distribution of overall sentiments in the listing data and showed that the scores are balanced (**1: 58%, 0: 42%**). Now that we've merged all reviews with their corresponding listings and attached sentiment scores, it's important to recheck the distribution to ensure that the sentiment scores remain balanced after the data merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f062eb07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create distribution results for our target variable\n",
    "overall_sentiment_distribution=round(df_collapsed_reviews_by_listing['Overall_sentiment'].value_counts(normalize=True).sort_index()*100, 2)\n",
    "\n",
    "# Determine figure size\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create barplot\n",
    "ax = overall_sentiment_distribution.plot.bar(color='#FF5A5F')\n",
    "\n",
    "# Add labels\n",
    "plt.title('Overall Sentiment Distribution for All Reviews', fontsize=18)\n",
    "plt.xlabel('Overall Sentiment', fontsize=15)\n",
    "plt.ylabel('Proportion (%)', fontsize=15)\n",
    "plt.bar_label(ax.containers[0], size=14)\n",
    "plt.xticks(rotation = 360)\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "# plt.savefig('Overall_Sentiment_Distribution.jpg', dpi =300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7486abc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f94cdd",
   "metadata": {},
   "source": [
    "## Train Test Split <a id='a3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f9bcf",
   "metadata": {},
   "source": [
    "The modelling process starts by splitting our dataset into training and testing sets. This procedure is fundamental for the effective evaluation of our model performance.\n",
    "\n",
    "The training data is implemented upon which our model is built and refined, and the testing data provides the benchmark for assessing the model's predictive performance on unseen data. This ensures us to mitigate the risk of **overfitting**, as our model will not just memorize the data pattern but rather learns to generalize on new, unseen data.\n",
    "\n",
    "Additionally, it is important that this splitting process must precede any data transformation steps including random sampling, text vectorization and scaling to prevent potential **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c631f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows obtained in the training data is 4726, with 38 feature columns.\n",
      "The number of rows obtained in the testing data is 1182, with 38 feature columns.\n"
     ]
    }
   ],
   "source": [
    "# Split test data as 30% of all data, determine random state to make sure every split is the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Show the number of rows for training and testing dataset\n",
    "print(f'The number of rows obtained in the training data is {X_train.shape[0]}, with {X_train.shape[1]} feature columns.')\n",
    "print(f'The number of rows obtained in the testing data is {X_test.shape[0]}, with {X_train.shape[1]} feature columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d789bf1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24082bd3",
   "metadata": {},
   "source": [
    "## Helper Function <a id='a3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fdf2d",
   "metadata": {},
   "source": [
    "Our dataset includes multiple non-review features, in the later text vectorization stage, it is not necessary for these columns to be processed by the vectorizers. Hence, we require a helper function to handle these numerical columns separately, and generate a column transformer based on our selection on different text vectorizers including `CountVectorizer` and `TfidfVectorizer`. \n",
    "\n",
    "Additionally, the numerical features in our dataset vary across different ranges, necessitating the scaling of data during the modeling stage. However, the text vectorizers will return a sparse matrix after transformation, while scalers like `StandardScaler` and `MinMaxScaler` require a dense array as input. Hence, we'll also need a function to convert the sparse matrix into a dense array.\n",
    "\n",
    "This code is borrowed from [Allistair Cota](https://github.com/allistaircota/rate_my_restaurant/blob/main/notebooks/NB3-Modelling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b04ae5",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "| Vectorizer  | Scaler| \n",
    "|:-------:|:--------:|\n",
    "|[TF-IDF Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) |  [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  |\n",
    "|[Count-Vectorizer](https://en.wikipedia.org/wiki/Bag-of-words_model)  |[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03dfb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical column names\n",
    "numeric_columns = X.select_dtypes(exclude='object').columns.to_list()\n",
    "\n",
    "def define_col_trans(input_text, vectorizer):\n",
    "    '''\n",
    "    Returns a ColumnTransformer which first performs a \n",
    "    passthrough on the numeric columns, then applies\n",
    "    a vectorizer on the `text` column\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - input_text: str, to name the vectorizer tuple\n",
    "    - vectorizer: Sklearn text vectorizer\n",
    "    \n",
    "    RETURNS:\n",
    "    - col_trans: sklearn ColumnTransformer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_trans = ColumnTransformer([\n",
    "        ('numeric', 'passthrough', numeric_columns), # numerical_columns defined above\n",
    "        (input_text, vectorizer, 'comments') # 'comments' as review text feature column\n",
    "    ])\n",
    "    \n",
    "    return col_trans\n",
    "\n",
    "def convert_to_array(sparse_matrix):\n",
    "    '''\n",
    "    Converts sparse matrix to dense array\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - sparse_matrix: scipy.sparse.csr_matrix or numpy array\n",
    "    \n",
    "    RETURNS:\n",
    "    - If sparse_matrix is not a scipy.sparse.csr_matrix,\n",
    "      sparse_matrix is returned. Else, returns the dense array\n",
    "      form of sparse_matrix.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if type(sparse_matrix) == csr_matrix:\n",
    "    \n",
    "        return sparse_matrix.toarray()\n",
    "    \n",
    "    else:\n",
    "        return sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0f405",
   "metadata": {},
   "source": [
    "#### Text vectorizer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5772b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformers\n",
    "ct_bow = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))\n",
    "ct_tfidf = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a4670",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da07db",
   "metadata": {},
   "source": [
    "# Baseline Model <a id='a4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff30002",
   "metadata": {},
   "source": [
    "As we are developing the best performed models for predicting the class of guest sentiments, it is crucial to establish a baseline model for comparison. We will utilise a **Dummy Classifier** model, which makes predictions without accessing dataset features, essentially performing random guessing. By establishing this baseline, we can decide that any model performing worse than the baseline model will not proceed to further analysis.\n",
    "\n",
    "**Run Time**: 3mins 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f725f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Vectorize data using Bag of Words Vectorizer\n",
    "bow_vec = CountVectorizer(max_features = 500, # Only obtain top 500 features based on vectorizer results\n",
    "                            min_df=5, # Feature occurency should be bigger than 5 in the corpus\n",
    "                            tokenizer=customized_tokenizer)\n",
    "\n",
    "# Fit and transform on the vectorizer to training data\n",
    "X_train_tfidf_d = bow_vec.fit_transform(X_train['comments']).toarray()\n",
    "\n",
    "# Transform on both training data and testing data\n",
    "X_test_tfidf_d = bow_vec.transform(X_test['comments']).toarray()\n",
    "\n",
    "# Reset Index before concatenating\n",
    "X_train_reset_index = X_train.reset_index(drop=True)\n",
    "X_test_reset_index = X_test.reset_index(drop=True)\n",
    "\n",
    "# Merge the resulting arrays with the original numeric features\n",
    "X_train_tfidf_d_transformed = pd.concat([X_train_reset_index.drop(['comments'], axis=1),\n",
    "                                         pd.DataFrame(X_train_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis=1)\n",
    "\n",
    "X_test_tfidf_d_transformed = pd.concat([X_test_reset_index.drop(['comments'], axis=1), \n",
    "                                        pd.DataFrame(X_test_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis = 1)\n",
    "\n",
    "# Print shape of the vectorized training feature data\n",
    "print(f'X_train_transfomed_dummy : {X_train_tfidf_d_transformed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaddbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dummy Classifier - Baseline Model\n",
    "# Instantiate Dummy Classifier\n",
    "dummy_classifier = DummyClassifier()\n",
    "\n",
    "# Fit the Dummy Classifier on Training data\n",
    "dummy_classifier.fit(X_train_tfidf_d_transformed, y_train_sample)\n",
    "\n",
    "# Predict the fitted model on Testing Data\n",
    "y_predict_d = dummy_classifier.predict(X_test_tfidf_d_transformed)\n",
    "\n",
    "# Print F1 score\n",
    "print(f'The Accuracy Score (%) for the Baseline Model is: {round(accuracy_score(y_test, y_predict_d)*100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da9703",
   "metadata": {},
   "source": [
    "#### Classification report <a id='a4.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd46eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report to see specific classification evaluation metrics scores\n",
    "baseline_report = classification_report(y_test, y_predict_d)\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcce12",
   "metadata": {},
   "source": [
    "Based on the findings from the classification report, the model classification accuracy score achieved by the dummy classifier is **37.42%**. This baseline performance indicates that future models should aim to surpass this threshold to be considered effective. Therefore, our goal for future models is to achieve an accuracy score higher than 38%, indicating improved predictive capability and accuracy in classifying sentiments. \n",
    "\n",
    "**Note**: This result is reflected by the actual proportion of negative sentiments in the testing dataset as Dummy Classifier takes random guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ccdaa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45724545",
   "metadata": {},
   "source": [
    "# Modelling <a id='a5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6788586",
   "metadata": {},
   "source": [
    "After completing data cleaning, pre-processing, and model setup stages, we are ready to train models and make predictions. To determine the best-performing model, we will utilize **GridSearchCV** to find the optimal model with the best hyperparameters. Machine learning metrics and models to be used in our modeling process include:\n",
    "\n",
    "- Text Vectorizer: Bag of Words, TF-IDF\n",
    "- Scaler: StandardScaler\n",
    "- Models: Logistic Regression, Decision Tree Classifier, Random Forest Classifier.\n",
    "\n",
    "Note that for performance purposes, we will be vectorizing the datasets outside of grid search. We will then fit combinations of models to the training data that has been transformed by two types of text vectorizations. During the fitting process, **5-fold cross-validation** will be performed to improve model performance and interpretability. Finally, the model with the highest average validation F1 score will be selected and evaluated at the end of each GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4550b",
   "metadata": {},
   "source": [
    "## GridSearch_1: General Sweep <a id='a5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd48ba",
   "metadata": {},
   "source": [
    "During the first GridSearch, we will be searching for optimal hyperparameters over wide range implementing on the **Logistic Regresion** and **Decision Tree Classifier**. This GridSearch will be run and fitted on two vectorized training sets defined above and we will evaluate the model performances with a brief summary. The selections of models and parameters are summarized below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac438a43",
   "metadata": {},
   "source": [
    "|    Models   |    Hyperparameters   |   Ranges/Options  |\n",
    "|:-------------:|:-------------:|:-------------:|\n",
    "|    **TfidfVectorizer**     |     max_df   |    0.95     |\n",
    "|                  |     min_df  |    5       |\n",
    "|       **CountVectorizer**           |     max_df  |    0.95       |\n",
    "|                  |     min_df  |    5       |\n",
    "|    **Logistic Regression**     |    C     |    0.001, 0.01, 0.1, 1, 10    |\n",
    "|         |    penalty     |    'none', 'l2'     | \n",
    "|    **Decision Tree Classifier**     |     max_depth    |     2, 8, 32, 64, 128    |\n",
    "|                 |    min_samples_leaf     |     2, 4, 8    |\n",
    "|                 |     min_samples_split    |     2, 4, 8    |\n",
    "|                 |     criterion    |     'gini', 'entropy'    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe6e78",
   "metadata": {},
   "source": [
    "To save long execution times for future references, we will use a loading flag to prevent re-training models when it is already saved and can be loaded as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5def9d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming training sample data .....\n",
      "Training sample data transformed.\n",
      "Loaded pre-trained models\n",
      "CPU times: total: 41 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # First GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Fit and transform on training data using two types of vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow = ct_bow.fit_transform(X_train)\n",
    "X_train_ct_tfidf= ct_tfidf.fit_transform(X_train)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_1 = True\n",
    "\n",
    "if loaded_flag_1:\n",
    "    print('Loaded pre-trained models (Gridsearch_1)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_1_bow=joblib.load('data/fittedgrid_1_bow.pkl')\n",
    "    fittedgrid_1_tfidf=joblib.load('data/fittedgrid_1_tfidf.pkl')\n",
    "else:\n",
    "    # Define base pipeline\n",
    "    pipeline_1 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_1 = [\n",
    "\n",
    "        # Logistic Regression\n",
    "        {\n",
    "            'model'              : [LogisticRegression()],\n",
    "            'model__C'           : [0.001, 0.01, 0.1, 1, 10], # C parameter to control penalty weights\n",
    "            'model__penalty'     : ['none', 'l2'], # Control penalty types, l1: Lasso, l2: Ridge\n",
    "            'model__random_state': [123], # Control gradient descent starting point\n",
    "            'model__max_iter'    : [10000] # Make sure model iterates\n",
    "        },\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     :[123] # Control randomness of the estimator\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_1 = GridSearchCV(estimator=pipeline_1, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_1, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') \n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_1_bow = grid_1.fit(X_train_ct_bow, y_train_sample)\n",
    "    fittedgrid_1_tfidf = grid_1.fit(X_train_ct_tfidf, y_train_sample)\n",
    "    \n",
    "    # Save fittedgrid as pickle file\n",
    "    joblib.dump(fittedgrid_1_bow, 'data/fittedgrid_1_bow.pkl')\n",
    "    joblib.dump(fittedgrid_1_tfidf, 'data/fittedgrid_1_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdf6c7",
   "metadata": {},
   "source": [
    "#### Selected model results with Bag of Words transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19e90ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x000001900A481A80>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=32,\n",
      "                                        min_samples_leaf=2, min_samples_split=8,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2721 features, but StandardScaler is expecting 2674 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print Crossvalidated Score\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Model Train Score (%): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(fittedgrid_1_bow\u001b[38;5;241m.\u001b[39mscore(X_train_ct_bow,\u001b[38;5;250m \u001b[39my_train_sample)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100.00\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print Testing Score\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:471\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# callable\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultimetric_:\n\u001b[0;32m    473\u001b[0m     score \u001b[38;5;241m=\u001b[39m score[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py:85\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m pos_label \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1005\u001b[0m     X,\n\u001b[0;32m   1006\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1007\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1008\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1009\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1010\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1011\u001b[0m )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2721 features, but StandardScaler is expecting 2674 features as input."
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_bow.score(X_train_ct_bow, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow = ct_bow.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_bow.score(X_test_ct_bow, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e636d",
   "metadata": {},
   "source": [
    "#### Selected model results with TF-IDF transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd248403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_tfidf.score(X_train_ct_tfidf, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf = ct_tfidf.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_tfidf.score(X_test_ct_tfidf, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e1681f",
   "metadata": {},
   "source": [
    "#### Top 20 models with best F1 scores resulted with TF-IDF transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf33035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand column width to see full results\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Store results in a dataframe by sorting mean_test_score in descending order\n",
    "fittedgrid1_results_df = pd.DataFrame(fittedgrid_1_tfidf.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Extract ranking number, models with tuned hyperparameters, and corresponding test scores\n",
    "fittedgrid1_results = fittedgrid1_results_df[['rank_test_score', 'params', 'mean_test_score']].sort_values('mean_test_score', ascending=False)\n",
    "print('GridSearch 1 Cross Validation Results')\n",
    "\n",
    "# Show top 10 cross validation results\n",
    "fittedgrid1_results.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf06a9",
   "metadata": {},
   "source": [
    "Next, we will study the currently selected best model in more detail by examining if there are patterns in its misclassified reviews. We will first obtain the more specific evaluation results by looking at the classification report and plotting a corresponding confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df879c",
   "metadata": {},
   "source": [
    "#### GridSearch_1 Result Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363ac6d",
   "metadata": {},
   "source": [
    "From the first gridsearch, we successfully selected our current best model: Decision Tree Classifier with \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ecc65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202f5eb",
   "metadata": {},
   "source": [
    "## GridSearch_2 : Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1864da63",
   "metadata": {},
   "source": [
    "After the first grid search, we obtained more focused parameter ranges and a currently best performed DT model. Our next step is to aim for better interpretability and hopefully further enhance our model performance by adding n-grams to the vectorizer. N-grams are essentially pairs of consecutive words that help maintain the sequence and interpretability of the tokens. In our second grid search, we will use bigrams (2 words), trigrams (3 words), and remove single words for both the bag-of-words vectorizer and the TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1f739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 32.8 s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# # Second GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Define column transformers with ngrams added\n",
    "ct_bow_ngrams = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "ct_tfidf_ngrams = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "\n",
    "# Fit and transform on training data using new vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow_ngrams = ct_bow_ngrams.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf_ngrams= ct_tfidf_ngrams.fit_transform(X_train_sample)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_2 = True\n",
    "\n",
    "if loaded_flag_2:\n",
    "    print('Loaded pre-trained models (Gridsearch_2)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_2_bow=joblib.load('data/fittedgrid_2_bow.pkl')\n",
    "    fittedgrid_2_tfidf=joblib.load('data/fittedgrid_2_tfidf.pkl')\n",
    "else:\n",
    "\n",
    "    # Define base pipeline\n",
    "    pipeline_2 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_2 = [\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator\n",
    "        },\n",
    "\n",
    "        # Random Forest\n",
    "        {\n",
    "            'model'                   : [RandomForestClassifier()],\n",
    "            'model__n_estimators'     : [20,30,40,50], # Control number of trees in the forest\n",
    "            'model__max_depth'        : [8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator  \n",
    "        }  \n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_2 = GridSearchCV(estimator=pipeline_2, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_2, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') # Define GridSearch evaluation metric to be f1 score\n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_2_bow = grid_2.fit(X_train_ct_bow_ngrams, y_train_sample)\n",
    "    fittedgrid_2_tfidf = grid_2.fit(X_train_ct_tfidf_ngrams, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "959fd0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.64\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Test Score (%): 84.74\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_bow.score(X_train_ct_bow_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow_ngrams = ct_bow_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_bow.score(X_test_ct_bow_ngrams, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab674bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.94\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_tfidf.score(X_train_ct_tfidf_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf_ngrams = ct_tfidf_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_tfidf.score(X_test_ct_tfidf_ngrams, y_test)*100, 2)}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clcapstone",
   "language": "python",
   "name": "clcapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
