{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787923b4",
   "metadata": {},
   "source": [
    "# Predicting Star Ratings of Edinburgh Airbnbs through Review Texts Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a2bb0",
   "metadata": {},
   "source": [
    "# Notebook 5: Modelling_Review_Collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d621c2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505f46e",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f0775",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497aff3",
   "metadata": {},
   "source": [
    "## Import Libraries <a id='a1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eff6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Main Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scipy Library for sparse  matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import html\n",
    "import contractions\n",
    "import langid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from langid.langid import LanguageIdentifier\n",
    "\n",
    "# Download from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Feature Extraction Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Dummy Classifer \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Modelling Libraries\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db98bf",
   "metadata": {},
   "source": [
    "#### Loading Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae965a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collapsed review data\n",
    "df_collapsed_reviews_by_listing= joblib.load('data/df_collapsed_reviews_by_listing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834226c",
   "metadata": {},
   "source": [
    "#### Ignore userwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b6a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6581506",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b789d48",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'customized_tokenizer' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m customized_tokenizer \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/customized_tokenizer.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[38;5;241m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_class(module, name))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pickle.py:1582\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m-> 1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\pickle.py:331\u001b[0m, in \u001b[0;36m_getattribute\u001b[1;34m(obj, name)\u001b[0m\n\u001b[0;32m    329\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, subpath)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get attribute \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m                              \u001b[38;5;241m.\u001b[39mformat(name, obj)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, parent\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'customized_tokenizer' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "customized_tokenizer = joblib.load('data/customized_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a4f60",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0b859",
   "metadata": {},
   "source": [
    "#### Check the uncollapsed review data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a881930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains all reviews listed individually is of dimension (470695, 46)\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains all reviews listed individually is of dimension {df_reviews_by_listing.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cb17f",
   "metadata": {},
   "source": [
    "# Modelling Set up <a id='a3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a4d59",
   "metadata": {},
   "source": [
    "## Split the variables <a id='a3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669293d",
   "metadata": {},
   "source": [
    "We need to split the variables into dependent and independent variables before we start fitting the model. The target variable will be the sentiment scores. We will focus on the overall sentiment score and attempt to further analyse the reviews with the other sub-rating transformed sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the future model\n",
    "X = df_reviews_by_listing.drop(['listing_id',\n",
    "                               'Overall_sentiment',\n",
    "                               'accuracy_sentiment',\n",
    "                               'cleanliness_sentiment',\n",
    "                               'checkin_sentiment',\n",
    "                               'communication_sentiment',\n",
    "                               'location_sentiment',\n",
    "                               'value_sentiment'], axis=1)\n",
    "y = df_reviews_by_listing['Overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36fc6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (470695, 38)\n",
      "y Shape: (470695,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ce381f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>55.95759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-3.18805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom_num</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_availability</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_bath</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_year</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_year</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_month</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_year</th>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_from_Edinburgh</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_a few days or more</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_email</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_phone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_work_email</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>My wife and I stayed at this beautiful apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              0\n",
       "host_response_rate                                                                        100.0\n",
       "host_acceptance_rate                                                                       92.0\n",
       "host_is_superhost                                                                             1\n",
       "latitude                                                                               55.95759\n",
       "longitude                                                                              -3.18805\n",
       "accommodates                                                                                  2\n",
       "bathroom_num                                                                                1.0\n",
       "beds                                                                                        1.0\n",
       "minimum_nights                                                                                3\n",
       "maximum_nights                                                                               30\n",
       "has_availability                                                                              1\n",
       "number_of_reviews                                                                           532\n",
       "number_of_reviews_ltm                                                                        82\n",
       "instant_bookable                                                                              0\n",
       "calculated_host_listings_count                                                                1\n",
       "calculated_host_listings_count_entire_homes                                                   1\n",
       "calculated_host_listings_count_private_rooms                                                  0\n",
       "calculated_host_listings_count_shared_rooms                                                   0\n",
       "reviews_per_month                                                                          3.38\n",
       "private_bath                                                                                  1\n",
       "host_since_year                                                                            2009\n",
       "host_since_month                                                                             12\n",
       "first_review_year                                                                          2011\n",
       "first_review_month                                                                            1\n",
       "last_review_year                                                                           2023\n",
       "last_review_month                                                                            12\n",
       "host_from_Edinburgh                                                                           1\n",
       "host_response_time_a few days or more                                                         0\n",
       "host_response_time_within a day                                                               0\n",
       "host_response_time_within a few hours                                                         1\n",
       "host_response_time_within an hour                                                             0\n",
       "host_verifications_email                                                                      1\n",
       "host_verifications_phone                                                                      1\n",
       "host_verifications_work_email                                                                 0\n",
       "room_type_Entire home/apt                                                                     1\n",
       "room_type_Hotel room                                                                          0\n",
       "room_type_Private room                                                                        0\n",
       "comments                                      My wife and I stayed at this beautiful apartme..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f58e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b4732",
   "metadata": {},
   "source": [
    "The dependent variable stored as **X** contains all cleaned listing related numerical data as well as a column that contains the guest review data.\n",
    "\n",
    "The independent variable stored as **y** contains the **Overall sentiment score** that was transformed from the listing's average overall rating score:\n",
    "- 1 was denoted by Overall rating score > 4.8\n",
    "- 0 was denoted by Overall rating score < 4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17428dc3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c2127",
   "metadata": {},
   "source": [
    "## Target Variable Distribution <a id='a3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcfd84",
   "metadata": {},
   "source": [
    "In the EDA notebook, we analyzed the distribution of overall sentiments in the listing data and showed that the scores are balanced (**1: 58%, 0: 42%**). Now that we've merged all reviews with their corresponding listings and attached sentiment scores, it's important to recheck the distribution to ensure that the sentiment scores remain balanced after the data merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f062eb07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create distribution results for our target variable\n",
    "overall_sentiment_distribution=round(df_reviews_by_listing['Overall_sentiment'].value_counts(normalize=True).sort_index()*100, 2)\n",
    "\n",
    "# Determine figure size\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create barplot\n",
    "ax = overall_sentiment_distribution.plot.bar(color='#FF5A5F')\n",
    "\n",
    "# Add labels\n",
    "plt.title('Overall Sentiment Distribution for All Reviews', fontsize=18)\n",
    "plt.xlabel('Overall Sentiment', fontsize=15)\n",
    "plt.ylabel('Proportion (%)', fontsize=15)\n",
    "plt.bar_label(ax.containers[0], size=14)\n",
    "plt.xticks(rotation = 360)\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "# plt.savefig('Overall_Sentiment_Distribution.jpg', dpi =300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad260a",
   "metadata": {},
   "source": [
    "The current sentiment score distribution (37:63) is not as balanced as it was analysed in the listing level. This imbalance indicates a potential bias in the dataset, with a disproportionate number of reviews having positive sentiments compared to negative sentiments.\n",
    "\n",
    "To address this issue, we plan to **downsample** reviews with positive sentiments in the next sampling stage. This approach aims to create a more even distribution of the target variable, enhancing the model's ability to generalize across different sentiment categories. However, to avoid potential **data leakage**, we will only perform sampling on the **training** dataset after **Train Test Split**.\n",
    "\n",
    "We also conclude that this imbalance may be attributed to positive review bias, where guests are more inclined to leave positive reviews. Additionally, the reinforcement effect further amplifies this bias, as the presence of positive reviews may influence subsequent guests to also leave positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7486abc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f94cdd",
   "metadata": {},
   "source": [
    "## Train Test Split <a id='a3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f9bcf",
   "metadata": {},
   "source": [
    "The modelling process starts by splitting our dataset into training and testing sets. This procedure is fundamental for the effective evaluation of our model performance.\n",
    "\n",
    "The training data is implemented upon which our model is built and refined, and the testing data provides the benchmark for assessing the model's predictive performance on unseen data. This ensures us to mitigate the risk of **overfitting**, as our model will not just memorize the data pattern but rather learns to generalize on new, unseen data.\n",
    "\n",
    "Additionally, it is important that this splitting process must precede any data transformation steps including random sampling, text vectorization and scaling to prevent potential **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c631f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows obtained in the training data is 329486, with 38 feature columns.\n",
      "The number of rows obtained in the testing data is 141209, with 38 feature columns.\n"
     ]
    }
   ],
   "source": [
    "# Split test data as 30% of all data, determine random state to make sure every split is the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# Show the number of rows for training and testing dataset\n",
    "print(f'The number of rows obtained in the training data is {X_train.shape[0]}, with {X_train.shape[1]} feature columns.')\n",
    "print(f'The number of rows obtained in the testing data is {X_test.shape[0]}, with {X_train.shape[1]} feature columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d789bf1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2c8a",
   "metadata": {},
   "source": [
    "## Sampling <a id='a3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0b998",
   "metadata": {},
   "source": [
    "Since we have a large training dataset with nearly 330k rows and an imbalanced target variable, we will perform **downsampling** on the training dataset by randomly select a balanced number of rows for both positive labelled rows and negative labelled rows.\n",
    "\n",
    "We will eventually select 3% of the original training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b797218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that can perform downsampling on training data and make it perfectly balanced\n",
    "def downsample_train(X_train, y_train, target, proportion):\n",
    "    '''\n",
    "    Function only works on target variable as binary column. \n",
    "    \n",
    "    Returns downsampled X_train and y_train which\n",
    "    has downsampled to specified proportion of original\n",
    "    data, also makes sure y_train is balanced\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - X_train: dataframe, splitted feature training data\n",
    "    - y_train: dataframe, splitted farget training data\n",
    "    - target: str, target variable name\n",
    "    - proportion: float, specified downsample proportion of total training data\n",
    "    \n",
    "    RETURNS:\n",
    "    - X_train_sample: Downsampled X_train\n",
    "    - y_train_sample: Downsampled y_train\n",
    "    \n",
    "    '''\n",
    "    # Specify number of rows for each class \n",
    "    num_rows_each = round(proportion*X_train.shape[0]/2)\n",
    "    \n",
    "    # Temporarily concatenate X_train and y_train back to dataframe format\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # Split classes\n",
    "    df_pos = df_train[df_train[target] == 1]\n",
    "    df_neg = df_train[df_train[target] == 0]\n",
    "    \n",
    "    # Resplit X and y for both two classes\n",
    "    X_pos, y_pos = df_pos.drop(target, axis=1), df_pos[target]\n",
    "    X_neg, y_neg = df_neg.drop(target, axis=1), df_neg[target]\n",
    "    \n",
    "    # Select randomized samples from each class\n",
    "    X_pos_sample, y_pos_sample = resample(X_pos, y_pos, random_state=123, n_samples = num_rows_each, replace=False, stratify=y_pos)\n",
    "    X_neg_sample, y_neg_sample = resample(X_neg, y_neg, random_state=123, n_samples = num_rows_each, replace=False, stratify=y_neg)\n",
    "    \n",
    "    # Concatenate back downsampled data\n",
    "    X_train_sample = pd.concat([X_pos_sample, X_neg_sample], axis=0)\n",
    "    y_train_sample = pd.concat([y_pos_sample, y_neg_sample], axis=0)\n",
    "    \n",
    "    return X_train_sample, y_train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9718d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return downsampled training data\n",
    "X_train_sample, y_train_sample = downsample_train(X_train, y_train, 'Overall_sentiment', 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f0e590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current proportion of each sentiment score class is (%)\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: Overall_sentiment, dtype: float64\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "The current number of rows in the training data is 9884\n"
     ]
    }
   ],
   "source": [
    "# Check for current target variable distribution\n",
    "print('The current proportion of each sentiment score class is (%)')\n",
    "print((y_train_sample.value_counts(normalize=True))*100)\n",
    "print('\\n--------------------------------------------\\n')\n",
    "print(f'The current number of rows in the training data is {X_train_sample.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c215c",
   "metadata": {},
   "source": [
    "Thus we have downsampled our training data from nearly 330k (329486) rows to nearly 10k (9884), and we also obtained a balanced training data. We will hope that this will potentially improve our model performance and also help the models to generalize well in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338d9c3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24082bd3",
   "metadata": {},
   "source": [
    "## Helper Function <a id='a3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fdf2d",
   "metadata": {},
   "source": [
    "Our dataset includes multiple non-review features, in the later text vectorization stage, it is not necessary for these columns to be processed by the vectorizers. Hence, we require a helper function to handle these numerical columns separately, and generate a column transformer based on our selection on different text vectorizers including `CountVectorizer` and `TfidfVectorizer`. \n",
    "\n",
    "Additionally, the numerical features in our dataset vary across different ranges, necessitating the scaling of data during the modeling stage. However, the text vectorizers will return a sparse matrix after transformation, while scalers like `StandardScaler` and `MinMaxScaler` require a dense array as input. Hence, we'll also need a function to convert the sparse matrix into a dense array.\n",
    "\n",
    "This code is borrowed from [Allistair Cota](https://github.com/allistaircota/rate_my_restaurant/blob/main/notebooks/NB3-Modelling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b04ae5",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "| Vectorizer  | Scaler| \n",
    "|:-------:|:--------:|\n",
    "|[TF-IDF Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) |  [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  |\n",
    "|[Count-Vectorizer](https://en.wikipedia.org/wiki/Bag-of-words_model)  |[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03dfb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical column names\n",
    "numeric_columns = X.select_dtypes(exclude='object').columns.to_list()\n",
    "\n",
    "def define_col_trans(input_text, vectorizer):\n",
    "    '''\n",
    "    Returns a ColumnTransformer which first performs a \n",
    "    passthrough on the numeric columns, then applies\n",
    "    a vectorizer on the `text` column\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - input_text: str, to name the vectorizer tuple\n",
    "    - vectorizer: Sklearn text vectorizer\n",
    "    \n",
    "    RETURNS:\n",
    "    - col_trans: sklearn ColumnTransformer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_trans = ColumnTransformer([\n",
    "        ('numeric', 'passthrough', numeric_columns), # numerical_columns defined above\n",
    "        (input_text, vectorizer, 'comments') # 'comments' as review text feature column\n",
    "    ])\n",
    "    \n",
    "    return col_trans\n",
    "\n",
    "def convert_to_array(sparse_matrix):\n",
    "    '''\n",
    "    Converts sparse matrix to dense array\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - sparse_matrix: scipy.sparse.csr_matrix or numpy array\n",
    "    \n",
    "    RETURNS:\n",
    "    - If sparse_matrix is not a scipy.sparse.csr_matrix,\n",
    "      sparse_matrix is returned. Else, returns the dense array\n",
    "      form of sparse_matrix.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if type(sparse_matrix) == csr_matrix:\n",
    "    \n",
    "        return sparse_matrix.toarray()\n",
    "    \n",
    "    else:\n",
    "        return sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0f405",
   "metadata": {},
   "source": [
    "#### Text vectorizer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5772b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformers\n",
    "ct_bow = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))\n",
    "ct_tfidf = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a4670",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da07db",
   "metadata": {},
   "source": [
    "# Baseline Model <a id='a4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff30002",
   "metadata": {},
   "source": [
    "As we are developing the best performed models for predicting the class of guest sentiments, it is crucial to establish a baseline model for comparison. We will utilise a **Dummy Classifier** model, which makes predictions without accessing dataset features, essentially performing random guessing. By establishing this baseline, we can decide that any model performing worse than the baseline model will not proceed to further analysis.\n",
    "\n",
    "**Run Time**: 3mins 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f725f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transfomed_dummy : (9884, 537)\n",
      "CPU times: total: 4min 20s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Vectorize data using Bag of Words Vectorizer\n",
    "bow_vec = CountVectorizer(max_features = 500, # Only obtain top 500 features based on vectorizer results\n",
    "                            min_df=5, # Feature occurency should be bigger than 5 in the corpus\n",
    "                            tokenizer=customized_tokenizer)\n",
    "\n",
    "# Fit and transform on the vectorizer to training data\n",
    "X_train_tfidf_d = bow_vec.fit_transform(X_train_sample['comments']).toarray()\n",
    "\n",
    "# Transform on both training data and testing data\n",
    "X_test_tfidf_d = bow_vec.transform(X_test['comments']).toarray()\n",
    "\n",
    "# Reset Index before concatenating\n",
    "X_train_sample_reset_index = X_train_sample.reset_index(drop=True)\n",
    "X_test_reset_index = X_test.reset_index(drop=True)\n",
    "\n",
    "# Merge the resulting arrays with the original numeric features\n",
    "X_train_tfidf_d_transformed = pd.concat([X_train_sample_reset_index.drop(['comments'], axis=1),\n",
    "                                         pd.DataFrame(X_train_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis=1)\n",
    "\n",
    "X_test_tfidf_d_transformed = pd.concat([X_test_reset_index.drop(['comments'], axis=1), \n",
    "                                        pd.DataFrame(X_test_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis = 1)\n",
    "\n",
    "# Print shape of the vectorized training feature data\n",
    "print(f'X_train_transfomed_dummy : {X_train_tfidf_d_transformed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acaddbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score (%) for the Baseline Model is: 37.42 %\n"
     ]
    }
   ],
   "source": [
    "# # Dummy Classifier - Baseline Model\n",
    "# Instantiate Dummy Classifier\n",
    "dummy_classifier = DummyClassifier()\n",
    "\n",
    "# Fit the Dummy Classifier on Training data\n",
    "dummy_classifier.fit(X_train_tfidf_d_transformed, y_train_sample)\n",
    "\n",
    "# Predict the fitted model on Testing Data\n",
    "y_predict_d = dummy_classifier.predict(X_test_tfidf_d_transformed)\n",
    "\n",
    "# Print F1 score\n",
    "print(f'The Accuracy Score (%) for the Baseline Model is: {round(accuracy_score(y_test, y_predict_d)*100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da9703",
   "metadata": {},
   "source": [
    "#### Classification report <a id='a4.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bd46eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54     52835\n",
      "           1       0.00      0.00      0.00     88374\n",
      "\n",
      "    accuracy                           0.37    141209\n",
      "   macro avg       0.19      0.50      0.27    141209\n",
      "weighted avg       0.14      0.37      0.20    141209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report to see specific classification evaluation metrics scores\n",
    "baseline_report = classification_report(y_test, y_predict_d)\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcce12",
   "metadata": {},
   "source": [
    "Based on the findings from the classification report, the model classification accuracy score achieved by the dummy classifier is **37.42%**. This baseline performance indicates that future models should aim to surpass this threshold to be considered effective. Therefore, our goal for future models is to achieve an accuracy score higher than 38%, indicating improved predictive capability and accuracy in classifying sentiments. \n",
    "\n",
    "**Note**: This result is reflected by the actual proportion of negative sentiments in the testing dataset as Dummy Classifier takes random guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ccdaa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45724545",
   "metadata": {},
   "source": [
    "# Modelling <a id='a5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6788586",
   "metadata": {},
   "source": [
    "After completing data cleaning, pre-processing, and model setup stages, we are ready to train models and make predictions. To determine the best-performing model, we will utilize **GridSearchCV** to find the optimal model with the best hyperparameters. Machine learning metrics and models to be used in our modeling process include:\n",
    "\n",
    "- Text Vectorizer: Bag of Words, TF-IDF\n",
    "- Scaler: StandardScaler\n",
    "- Models: Logistic Regression, Decision Tree Classifier, Random Forest Classifier.\n",
    "\n",
    "Note that for performance purposes, we will be vectorizing the datasets outside of grid search. We will then fit combinations of models to the training data that has been transformed by two types of text vectorizations. During the fitting process, **5-fold cross-validation** will be performed to improve model performance and interpretability. Finally, the model with the highest average validation F1 score will be selected and evaluated at the end of each GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4550b",
   "metadata": {},
   "source": [
    "## GridSearch_1: General Sweep <a id='a5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd48ba",
   "metadata": {},
   "source": [
    "During the first GridSearch, we will be searching for optimal hyperparameters over wide range implementing on the **Logistic Regresion** and **Decision Tree Classifier**. This GridSearch will be run and fitted on two vectorized training sets defined above and we will evaluate the model performances with a brief summary. The selections of models and parameters are summarized below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac438a43",
   "metadata": {},
   "source": [
    "|    Models   |    Hyperparameters   |   Ranges/Options  |\n",
    "|:-------------:|:-------------:|:-------------:|\n",
    "|    **TfidfVectorizer**     |     max_df   |    0.95     |\n",
    "|                  |     min_df  |    5       |\n",
    "|       **CountVectorizer**           |     max_df  |    0.95       |\n",
    "|                  |     min_df  |    5       |\n",
    "|    **Logistic Regression**     |    C     |    0.001, 0.01, 0.1, 1, 10    |\n",
    "|         |    penalty     |    'none', 'l2'     | \n",
    "|    **Decision Tree Classifier**     |     max_depth    |     2, 8, 32, 64, 128    |\n",
    "|                 |    min_samples_leaf     |     2, 4, 8    |\n",
    "|                 |     min_samples_split    |     2, 4, 8    |\n",
    "|                 |     criterion    |     'gini', 'entropy'    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377c5ae",
   "metadata": {},
   "source": [
    "To save long execution times for future references, we will use a loading flag to prevent re-training models when it is already saved and can be loaded as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5def9d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming training sample data .....\n",
      "Training sample data transformed.\n",
      "Loaded pre-trained models\n",
      "CPU times: total: 41 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # First GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Fit and transform on training data using two types of vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow = ct_bow.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf= ct_tfidf.fit_transform(X_train_sample)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_1 = True\n",
    "\n",
    "if loaded_flag_1:\n",
    "    print('Loaded pre-trained models (Gridsearch_1)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_1_bow=joblib.load('data/fittedgrid_1_bow.pkl')\n",
    "    fittedgrid_1_tfidf=joblib.load('data/fittedgrid_1_tfidf.pkl')\n",
    "else:\n",
    "    # Define base pipeline\n",
    "    pipeline_1 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_1 = [\n",
    "\n",
    "        # Logistic Regression\n",
    "        {\n",
    "            'model'              : [LogisticRegression()],\n",
    "            'model__C'           : [0.001, 0.01, 0.1, 1, 10], # C parameter to control penalty weights\n",
    "            'model__penalty'     : ['none', 'l2'], # Control penalty types, l1: Lasso, l2: Ridge\n",
    "            'model__random_state': [123], # Control gradient descent starting point\n",
    "            'model__max_iter'    : [10000] # Make sure model iterates\n",
    "        },\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     :[123] # Control randomness of the estimator\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_1 = GridSearchCV(estimator=pipeline_1, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_1, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') \n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_1_bow = grid_1.fit(X_train_ct_bow, y_train_sample)\n",
    "    fittedgrid_1_tfidf = grid_1.fit(X_train_ct_tfidf, y_train_sample)\n",
    "    \n",
    "    # Save fittedgrid as pickle file\n",
    "    joblib.dump(fittedgrid_1_bow, 'data/fittedgrid_1_bow.pkl')\n",
    "    joblib.dump(fittedgrid_1_tfidf, 'data/fittedgrid_1_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdf6c7",
   "metadata": {},
   "source": [
    "#### Selected model results with Bag of Words transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19e90ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x000001900A481A80>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=32,\n",
      "                                        min_samples_leaf=2, min_samples_split=8,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2721 features, but StandardScaler is expecting 2674 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print Crossvalidated Score\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Model Train Score (%): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(fittedgrid_1_bow\u001b[38;5;241m.\u001b[39mscore(X_train_ct_bow,\u001b[38;5;250m \u001b[39my_train_sample)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100.00\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print Testing Score\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:471\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# callable\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultimetric_:\n\u001b[0;32m    473\u001b[0m     score \u001b[38;5;241m=\u001b[39m score[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py:85\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m pos_label \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1005\u001b[0m     X,\n\u001b[0;32m   1006\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1007\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1008\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1009\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1010\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1011\u001b[0m )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2721 features, but StandardScaler is expecting 2674 features as input."
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_bow.score(X_train_ct_bow, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow = ct_bow.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_bow.score(X_test_ct_bow, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e636d",
   "metadata": {},
   "source": [
    "#### Selected model results with TF-IDF transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd248403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_tfidf.score(X_train_ct_tfidf, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf = ct_tfidf.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_tfidf.score(X_test_ct_tfidf, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558cfa3",
   "metadata": {},
   "source": [
    "#### Top 20 models with best F1 scores resulted with TF-IDF transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e43e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand column width to see full results\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Store results in a dataframe by sorting mean_test_score in descending order\n",
    "fittedgrid1_results_df = pd.DataFrame(fittedgrid_1_tfidf.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Extract ranking number, models with tuned hyperparameters, and corresponding test scores\n",
    "fittedgrid1_results = fittedgrid1_results_df[['rank_test_score', 'params', 'mean_test_score']].sort_values('mean_test_score', ascending=False)\n",
    "print('GridSearch 1 Cross Validation Results')\n",
    "\n",
    "# Show top 10 cross validation results\n",
    "fittedgrid1_results.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab6f30",
   "metadata": {},
   "source": [
    "Next, we will study the currently selected best model in more detail by examining if there are patterns in its misclassified reviews. We will first obtain the more specific evaluation results by looking at the classification report and plotting a corresponding confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df879c",
   "metadata": {},
   "source": [
    "#### GridSearch_1 Result Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32bef9",
   "metadata": {},
   "source": [
    "From the first gridsearch, we successfully selected our current best model: Decision Tree Classifier with \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ecc65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202f5eb",
   "metadata": {},
   "source": [
    "## GridSearch_2 : Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726365d",
   "metadata": {},
   "source": [
    "After the first grid search, we obtained more focused parameter ranges and a currently best performed DT model. Our next step is to aim for better interpretability and hopefully further enhance our model performance by adding n-grams to the vectorizer. N-grams are essentially pairs of consecutive words that help maintain the sequence and interpretability of the tokens. In our second grid search, we will use bigrams (2 words), trigrams (3 words), and remove single words for both the bag-of-words vectorizer and the TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1f739c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 32.8 s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# # Second GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Define column transformers with ngrams added\n",
    "ct_bow_ngrams = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "ct_tfidf_ngrams = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "\n",
    "# Fit and transform on training data using new vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow_ngrams = ct_bow_ngrams.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf_ngrams= ct_tfidf_ngrams.fit_transform(X_train_sample)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_2 = True\n",
    "\n",
    "if loaded_flag_2:\n",
    "    print('Loaded pre-trained models (Gridsearch_2)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_2_bow=joblib.load('data/fittedgrid_2_bow.pkl')\n",
    "    fittedgrid_2_tfidf=joblib.load('data/fittedgrid_2_tfidf.pkl')\n",
    "else:\n",
    "\n",
    "    # Define base pipeline\n",
    "    pipeline_2 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_2 = [\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator\n",
    "        },\n",
    "\n",
    "        # Random Forest\n",
    "        {\n",
    "            'model'                   : [RandomForestClassifier()],\n",
    "            'model__n_estimators'     : [20,30,40,50], # Control number of trees in the forest\n",
    "            'model__max_depth'        : [8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator  \n",
    "        }  \n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_2 = GridSearchCV(estimator=pipeline_2, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_2, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') # Define GridSearch evaluation metric to be f1 score\n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_2_bow = grid_2.fit(X_train_ct_bow_ngrams, y_train_sample)\n",
    "    fittedgrid_2_tfidf = grid_2.fit(X_train_ct_tfidf_ngrams, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "959fd0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.64\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Test Score (%): 84.74\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_bow.score(X_train_ct_bow_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow_ngrams = ct_bow_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_bow.score(X_test_ct_bow_ngrams, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab674bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.94\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_tfidf.score(X_train_ct_tfidf_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf_ngrams = ct_tfidf_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_tfidf.score(X_test_ct_tfidf_ngrams, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8294bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot graphs for bow fitted grid with bow transformed data \n",
    "extract_key_words_plot(fittedgrid_2_tfidf, ct_tfidf_ngrams, 20, 'ct_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ef9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aad35629",
   "metadata": {},
   "source": [
    "# Predicting Star Ratings of Edinburgh Airbnbs through Review Texts Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaf80d",
   "metadata": {},
   "source": [
    "# Notebook 4: Modelling_Review_Uncollapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f247c3",
   "metadata": {},
   "source": [
    "In this notebook, we will further process our Airbnb reviews using natural language processing (NLP) and machine learning techniques. We will first define a customized tokenizer to remove any irrelevant contents from the text and separate the review texts into individual words. Next, we will set up for modelling stage including define the Baseline Score for future model evaluation.  After that, we will utilize different machine learning models and attempt to find the best-performing models by tuning hyperparameters using GridSearch. Finally, we will use evaluation metrics to assess our results.\n",
    "\n",
    "**Note**: The review data used in this notebook is the cleaned and processed review dataset with listing information aggregated to each review. The reviews are **not collapsed** to each Airbnb Listing.\n",
    "\n",
    "### Brief summary\n",
    "\n",
    "- We will define a customized tokenizer to further process our review texts.\n",
    "- We will set up our modeling stage by checking if our target variable is balanced, and define several helper functions for future use.\n",
    "- We will define a baseline model to compare our future model accuracy.\n",
    "- We will use several gridsearches to find the best model with best interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d53ab4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bcab73",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590c6e3",
   "metadata": {},
   "source": [
    "1. [**Import Libraries**](#a1)<br>\n",
    "\n",
    "2. [**Customized Tokenizer**](#a2)<br>\n",
    "    \n",
    "3. [**Modelling Set Up**](#a3)<br>\n",
    "    3.1.[Split Variables](#a3.1)<br>\n",
    "    3.2.[Target Varaible Distribution](#a3.2)<br>\n",
    "    3.3.[Train Test Split](#a3.3)<br>\n",
    "    3.4.[Sampling](#a3.4)<br>\n",
    "    3.5.[Helper Function](#a3.5)<br>\n",
    "        \n",
    "4. [**Baseline Model**](#a4)<br>\n",
    "    4.1.[Baseline Model Evaluation](#a4.1)<br>\n",
    "5. [**Modelling**](#a5)<br>\n",
    "    5.1.[GridSearch_1: General Sweep](#a5.1)<br>\n",
    "    5.2 [GridSearch_2: Ngrams](#a5.2)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf79d76f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760409fb",
   "metadata": {},
   "source": [
    "## Import Libraries <a id='a1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560c86dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Main Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scipy Library for sparse  matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import html\n",
    "import contractions\n",
    "import langid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from langid.langid import LanguageIdentifier\n",
    "\n",
    "# Download from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Feature Extraction Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Dummy Classifer \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Modelling Libraries\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9178a0f",
   "metadata": {},
   "source": [
    "#### Loading Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c6c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncollapsed review data\n",
    "df_reviews_by_listing= joblib.load('data/df_reviews_by_listing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93f3aa",
   "metadata": {},
   "source": [
    "#### Ignore userwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3fcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf3579d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd4865",
   "metadata": {},
   "source": [
    "# Customized Text Tokenizer <a id='a2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5d316",
   "metadata": {},
   "source": [
    "Our ultimate goal is to use machine learning models to accurately predict guests' sentiment scores, determining whether they will give a rating of over 4.8 or not. To enable the models to comprehend the review texts, we must first separate the documents into individual tokens. This task requires defining various tokenizing requirements to remove irrelevant text components from the data. Therefore, our customized text tokenizer should be able to:\n",
    "- Lowercase text\n",
    "- Remove punctuations\n",
    "- Remove Whitespaces\n",
    "- Remove HTML white spaces of format <br/>\n",
    "- Remove emails\n",
    "- Remove emojis\n",
    "- Remove English Stop words\n",
    "- Remove special characters\n",
    "- Remove numbers\n",
    "- Remove weblinks\n",
    "- Expand contractions\n",
    "- Remove Non-English Text Characters (Mixed with English review that was not detected and filtered in the pre-processing stage)\n",
    "- Perfome Texts Lemmatization (each word is mapped to a fixed, meaningful common root form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d7baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_tokenizer(sentence):\n",
    "    \n",
    "    # Remove HTML tags and entities\n",
    "    sentence = html.unescape(sentence)\n",
    "    sentence = re.sub(r'<[^>]+>', '', sentence)\n",
    "    \n",
    "    # Remove HTML white spaces \\r<br/> and <br/>\n",
    "    sentence = re.sub(r'(\\r<br/>)|(<br/>)', ' ', sentence)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    \n",
    "    # Lowercase text\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # Remove emails\n",
    "    sentence = re.sub(r'\\S*@\\S*\\s?', '', sentence)\n",
    "    \n",
    "    # Remove emojis\n",
    "    sentence = sentence.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove special characters\n",
    "    sentence = re.sub(r'[^A-Za-z\\s]', '', sentence)\n",
    "    \n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]+', '', sentence)\n",
    "    \n",
    "    # Remove weblinks\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    \n",
    "    # Expand contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Remove non-English text characters\n",
    "    if langid.classify(sentence)[0] != 'en':\n",
    "        sentence = ''\n",
    "    \n",
    "    # Remove English stopwords\n",
    "    eng_stop_words=stopwords.words('english')\n",
    "    # Append EDA insights driven stop words\n",
    "    eng_stop_words.extend(['apartment','flat','edinburgh','could', 'would', 'x', 'caroline', 'stay']) \n",
    "    stop_words = set(eng_stop_words)\n",
    "    tokens = sentence.split()\n",
    "    sentence = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "    \n",
    "    # Perform text stemming\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = ' '.join([lemmatizer.lemmatize(word, pos = 'v') for word in sentence.split()])\n",
    "    \n",
    "    # Tokenize cleaned sentence\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aec368",
   "metadata": {},
   "source": [
    "#### Save function as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c99998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/customized_tokenizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(customized_tokenizer, 'data/customized_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8d74e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bd516",
   "metadata": {},
   "source": [
    "#### Check the uncollapsed review data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db6294b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains all reviews listed individually is of dimension (470695, 46)\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains all reviews listed individually is of dimension {df_reviews_by_listing.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e1d401",
   "metadata": {},
   "source": [
    "# Modelling Set up <a id='a3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2c1a10",
   "metadata": {},
   "source": [
    "## Split the variables <a id='a3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca736dca",
   "metadata": {},
   "source": [
    "We need to split the variables into dependent and independent variables before we start fitting the model. The target variable will be the sentiment scores. We will focus on the overall sentiment score and attempt to further analyse the reviews with the other sub-rating transformed sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb36d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the future model\n",
    "X = df_reviews_by_listing.drop(['listing_id',\n",
    "                               'Overall_sentiment',\n",
    "                               'accuracy_sentiment',\n",
    "                               'cleanliness_sentiment',\n",
    "                               'checkin_sentiment',\n",
    "                               'communication_sentiment',\n",
    "                               'location_sentiment',\n",
    "                               'value_sentiment'], axis=1)\n",
    "y = df_reviews_by_listing['Overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80eead59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (470695, 38)\n",
      "y Shape: (470695,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6c594a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>55.95759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-3.18805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom_num</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_availability</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_bath</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_year</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_year</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_month</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_year</th>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_from_Edinburgh</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_a few days or more</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_email</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_phone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_work_email</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>My wife and I stayed at this beautiful apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              0\n",
       "host_response_rate                                                                        100.0\n",
       "host_acceptance_rate                                                                       92.0\n",
       "host_is_superhost                                                                             1\n",
       "latitude                                                                               55.95759\n",
       "longitude                                                                              -3.18805\n",
       "accommodates                                                                                  2\n",
       "bathroom_num                                                                                1.0\n",
       "beds                                                                                        1.0\n",
       "minimum_nights                                                                                3\n",
       "maximum_nights                                                                               30\n",
       "has_availability                                                                              1\n",
       "number_of_reviews                                                                           532\n",
       "number_of_reviews_ltm                                                                        82\n",
       "instant_bookable                                                                              0\n",
       "calculated_host_listings_count                                                                1\n",
       "calculated_host_listings_count_entire_homes                                                   1\n",
       "calculated_host_listings_count_private_rooms                                                  0\n",
       "calculated_host_listings_count_shared_rooms                                                   0\n",
       "reviews_per_month                                                                          3.38\n",
       "private_bath                                                                                  1\n",
       "host_since_year                                                                            2009\n",
       "host_since_month                                                                             12\n",
       "first_review_year                                                                          2011\n",
       "first_review_month                                                                            1\n",
       "last_review_year                                                                           2023\n",
       "last_review_month                                                                            12\n",
       "host_from_Edinburgh                                                                           1\n",
       "host_response_time_a few days or more                                                         0\n",
       "host_response_time_within a day                                                               0\n",
       "host_response_time_within a few hours                                                         1\n",
       "host_response_time_within an hour                                                             0\n",
       "host_verifications_email                                                                      1\n",
       "host_verifications_phone                                                                      1\n",
       "host_verifications_work_email                                                                 0\n",
       "room_type_Entire home/apt                                                                     1\n",
       "room_type_Hotel room                                                                          0\n",
       "room_type_Private room                                                                        0\n",
       "comments                                      My wife and I stayed at this beautiful apartme..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4400593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd5fe9",
   "metadata": {},
   "source": [
    "The dependent variable stored as **X** contains all cleaned listing related numerical data as well as a column that contains the guest review data.\n",
    "\n",
    "The independent variable stored as **y** contains the **Overall sentiment score** that was transformed from the listing's average overall rating score:\n",
    "- 1 was denoted by Overall rating score > 4.8\n",
    "- 0 was denoted by Overall rating score < 4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0508cd2e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf140a3",
   "metadata": {},
   "source": [
    "## Target Variable Distribution <a id='a3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d387e87d",
   "metadata": {},
   "source": [
    "In the EDA notebook, we analyzed the distribution of overall sentiments in the listing data and showed that the scores are balanced (**1: 58%, 0: 42%**). Now that we've merged all reviews with their corresponding listings and attached sentiment scores, it's important to recheck the distribution to ensure that the sentiment scores remain balanced after the data merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0dd9cb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABoyElEQVR4nO3de3zP9f//8ft7s4OxzXkH7OAsp0QRsTnMoT4h6eDUFj4S5YOKfJRW+VKU+KQUwupDipBDRDmWFCIqRA0LMzHbnDaz1+8Pv/frs7cdbO/tZZtu18vlfWGv1/P1ej1er71P9z1fr+fLZhiGIQAAAAAAUOhciroAAAAAAABuVYRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4At6wjR47IZrPJZrPpyJEjeZ4Hjk9xs2nTJvP3UVzZ69u0aZPD9JLyXIqOjpbNZlN4eHhRl+KUFStWqH379ipfvrxcXFxks9k0YsSIoi6r0IWHh8tmsyk6Ojpf825VJeG9AQChGyjRLl++rPfff1/333+/goKCVLp0afn6+qp+/foaPHiwNm7cWNQl3tKOHj2qsWPH6s4771T58uXl5uYmPz8/NW7cWA8++KCmTZumn376qajLzCI6OlrR0dHFOgAVpU2bNik6Olrz588v0HrsIS7zw8XFRT4+PqpWrZpatWqlYcOGacmSJUpLSyuc4vPoyJEj5vPgVrdnzx5FR0dr2rRpRV2KZT777DN1795dGzduVHJysipVqiQ/Pz/5+PgUdWm5+uKLL8zXRlBQkDIyMoqslqioqCyvV5vNptKlSysoKEjdu3fXp59+KsMwiqxGACVXqaIuAIBz1q9frwEDBujPP/80p/n4+Cg1NVUHDhzQgQMHNHv2bHXt2lUfffSRKlasWITV3noWLFigwYMH6+LFi+Y0Hx8fXbx4Ufv27dO+ffu0dOlSBQcHF7tw+/LLL0u61isUEhKSbRs3NzfVrVvX/P/fyaZNm/Tyyy8rLCxMUVFRhbJOPz8/8/+XLl3SiRMndPz4cX333Xd69913VbFiRb366qsaMmRItj1WXl5e5u+jMBw5csR8HhRW8LbX5+XlVSjrKyx79uzRyy+/rODg4Fx7fitVqqS6desqKCjo5hVXSKZMmSJJevDBB/Xhhx8Wu99BTubOnWv+Py4uTuvXr1fnzp2LsCLJxcVFlStXNn8+d+6c4uLiFBcXpxUrVigmJkZLly6Vh4dHEVb5P4X93gDAGvR0AyXQp59+qnvvvVd//vmnqlatqjlz5ujs2bNKSkrS5cuXtX//fo0YMUKlSpXSmjVr1LJlSyUkJBR12beMHTt26LHHHtPFixfVuHFjLVmyROfPn1dSUpJSUlKUkJCg5cuXKyoqSmXKlCnqcp1StWpV8483VatWLepySrz4+HjzkZSUpCtXrmjv3r168803FRoaqjNnzmjo0KHq169ftj1pd911l/n7KK7s9d11111FXYpTnnrqKR04cEAffvhhUZeSb/v27ZN0rbe2pATu06dPa8WKFXJ1ddWTTz4pSfrggw+KuCqpevXqDq/XS5cuaf/+/erevbuka73zEyZMKOIq/6ckvDcAIHQDJc6BAwc0YMAApaenq1GjRtq9e7cGDhyo8uXLm23q1aunt956S59//rnc3d11+PBh9enTpwirvrVMmzZNGRkZqlKlirZs2aIHH3zQIVxXrlxZ3bt317x587Rz584irBTFlaurqxo1aqRRo0bp559/1qOPPipJWrhwoV577bUirg4ljf2Mm7JlyxZxJXn30Ucf6cqVK4qIiNDo0aNls9n0+eef68yZM0VdmgObzaZ69erp008/Vb169SQ59tADQF4QuoESZty4cbpw4YI8PDy0ePFih9PgrnfvvffqhRdekCR9/fXXWr16tTlv6tSpstls8vPzU3p6eo7rMAxDwcHBstls2f51/+rVq5o/f746d+4sPz8/ubu7q3LlyurcubMWLVqU4/VvISEhstlsmj9/vs6fP6/x48erUaNG8vb2dhhw6cqVK1q/fr2GDx+u5s2bKyAgQO7u7qpSpYo6d+6sjz/++KZfY7dnzx5J107P9vX1zbVt6dKlc5xXGMcuLS1NU6ZMUZMmTVSmTBn5+vqqffv2Wrt2bZbl7Ncs2rVr187h2sXMp5rnNvjV9QP37N27V71791ZgYKBKly6t+vXr64033nB4Xn377bfq0aOHAgIC5OnpqYYNG+qdd9654e/u999/19NPP6369eurbNmy8vLyUv369TVixAgdO3Ys22Xmz5/vsD+7du3Sww8/rICAAHl4eKhGjRoaNWqUEhMTHZaz77P9tOvNmzdnub6zoNd5Z8fLy0sxMTFq2rSpJOm1117T2bNnHdrcaLCkAwcOaPDgwapTp468vLxUunRpVa9eXS1bttS///1vh16wkJAQtWvXzvz5+n3MfEr99YOLffbZZ+rUqZOqVKkiFxcXh1PTcxpI7XqHDh1SVFSUqlWrJg8PDwUFBWnIkCE6fvx4tu2v/31mJ6fnq81m0+OPPy7p2hgM1+9r5vrzMpDa7t279dhjjyk4OFienp4qX768WrVqpWnTpik1NTVP9ef1+XgjmffZ7vrXtBX1b9y40Xwtu7q6On0Jhj24RkZGKiQkRG3btlVaWpr++9//OrU+q7m7u6t9+/aSpBMnTuT4+0pKStL//d//qUWLFipfvrw8PDxUvXp19e7dW9u3b8/SvqCfxXkZSC2/nzVXr15VuXLlZLPZtGrVqizr+/jjj81tPvvss1nmnzx50pz/xx9/OMzLz3sVcEsxAJQYJ06cMFxcXAxJRlRUVJ6WSUlJMby9vQ1JRteuXc3p8fHxhqurqyHJWLVqVY7Lb9q0yZBk2Gw2IzY21mFefHy80aJFC0OS+fD19XX4uVu3bkZqamqW9QYHBxuSjDfeeMOoU6eOIclwd3c3ypUrZ0gyt7Vx40aH9Xl4eBhly5Z1mPbQQw8ZV69ezbKN2NhYs831tec270Zuu+02Q5LRqlWrfC2XWWEcu7fffttch5ubm8NxsdlsxgcffOCw3PDhww0/Pz+zTfny5Q0/Pz/z0bx5c7Ntbscn8+/kiy++MDw9Pc36bTabOe/RRx81DMMwZs+ebbi6uho2my3LPo4ZMybHYzRr1izDzc3N4XdfunRp82cfHx9j3bp1WZabN2+eIckIDg42FixYYK7D19fXfP1IMho0aGCkpKSYyx07dszw8/MzypQpYx7TzMfHz8/PWLRoUZ5+v4ZhGC+99JK5rbxYvHix2f76313mY369devWGR4eHuZ8Nzc383Vkf7z00ktm++bNmxvly5c3512/j8OHD8+yD2FhYcaoUaPM51b58uUNV1dXh/Xa17dx40aH+jI/lxYtWmS+H5UtW9bh91mhQgVj165dWfYv8+8zJzk9X/38/AwfHx9DkuHi4pJlX6dMmZLtvmbnrbfecnh++/r6Ojw/GzdubJw4cSLX+vPzfLwR+/M1t9d0Ydc/ffp0cx325SMjI/Ncs913331nvoYvXrxoGIZhzJ0715BkNGrUKNdlw8LCsjyn8zLvRiIjI2/4PHvyySfN43X69Oks87dv3+7w+3B1dTWf7/bXzsSJEx2WKehncW7vDfb1O/NZc//99xuSjJEjR2ZZ56BBg8xlmzZtmmX+f//7X0OSERQU5DA9v+9VwK2E0A2UIAsXLjQ/mFauXJnn5R588EHzS+6VK1fM6V27djUkGY888kiOyw4cONCQZLRt29ZhempqqnHnnXcakow77rjDWL16tXHhwgXDMAzj/PnzRkxMjFGlShVDkjFixIgs67UHx7Jlyxr+/v7G0qVLjbS0NMMwDCMuLs5c1/bt240+ffoYq1evNuLj442MjAzDMAzjzJkzxvTp080v1NOnT8+yDatCd1RUlLnsG2+8kW0wzk1hHbvy5csbVatWNZYvX24euwMHDhgtW7Y0j+25c+eyLJ9TOMosr6G7XLlyxiOPPGIcPXrUMAzDSE5ONsaOHWvOnzRpkuHm5mY8/fTTxqlTpwzDMIyzZ8+ax9DFxcU4ePBglu0vW7bM/FL2/PPPG0eOHDEyMjKMjIwM48CBA8ZDDz1kfmm3b9vOHhK8vLwMDw8PY9CgQcaxY8cMwzCMCxcuGDNmzDDDxosvvphl2zcKX3mV39CdkpJifvl+7LHHHObl9sW6Vq1ahiSjU6dOxr59+8zply5dMvbt22dER0cbc+fOzfP6stsH+x90Ro8ebSQkJBiGYRiXL182jhw5YrbNS+j29fU1GjdubHz//feGYRhGRkaG8eWXXxpBQUHml/Tk5GSH5QsSuvO6fOZ9ze73vnLlSnP93bt3N/744w/DMK69lj/88EMzWLVq1cpIT0/PdvvOPh/z4kav6cKo39PT03B1dTWioqLM+tPT043Dhw/nu157aBs4cKA5LTk52fDy8jIkGTt27Mhx2aIK3ampqUa9evXM953rxcbGmgGyV69exq5du8zP21OnThkvvviiUapUKUOSsWzZModlC/JZnNtruSCfNVOnTjUkGU2aNMmy3po1a5rHwcXFxThz5ky2tV7/Bxln3quAWwWhGyhBxo0bZ364/vnnn3le7tVXXzWXy/wF6eOPPza/TGUXzi5dumT+RXzOnDkO82bMmGH2zlz/Jdlu586dhs1mM9zd3c3AZWcPjq6ursaPP/6Y5325nr13sGbNmlnmWRW6Dxw44NB7Ub58eaNHjx7GhAkTjDVr1hiJiYm5Ll9Yx87Dw8PYv39/lmUTEhLM3uf//ve/WeYXZuiOiIgw/xCSWZs2bcw2gwYNyjI/PT3dCAkJMSQZr776qsO81NRUo2rVqoaUtcc3s27duhmSjH/9618O0+0hIbsvfXb2XttatWplmVdUodswDKN27dqGJKN169YO03P6Yn3q1Clzena9lDnJb+iWZIwaNSrXtnkJ3RUrVszyfDYMw/j1118Nd3d3Q5IxefJkh3nFIXTbz2655557soRSwzCMFStWmNtfvHhxttt39vmYFzd6TRdW/T179nSqvszOnz9vvn9u2bLFYV7fvn0NScaQIUNyXP5mh277H/p69OhhHofMZ4PY9erVy5Bk9O/fP8dt5BRkC/JZnNtruSCfNXv27DGkaz3rf/31lzn92LFj5mdunz59DEnGZ5995rDO0NBQQ5Ixf/58c5qz71XArYJruoESJPMAM/m5BVilSpWyXUf37t3l4+Ojy5cva8mSJVmWW7FihZKSkuTp6alevXo5zJszZ44kaejQofL29s52u82aNVODBg2UlpaW4z3Du3TpYl7L6oz77rtP0rVrf0+ePOn0evKjbt262rx5s+68805JUmJiopYvX64XXnhBXbt2VcWKFRUeHq7ly5dnu3xhHbtevXqZA/tkVrlyZd19992Srl1vbaUxY8Zkey1h5tv+jB07Nst8V1dXdezYUVLWGtesWaPjx4/Lz8/PvB43O4899pgk6csvv8yxjX1Mg+vZRyI+fPiww23filqFChUkKcs13Tnx9vaWi8u1j3Irn/8uLi4aM2ZMgdczZMgQValSJcv0+vXrm+8xixYtKvB2CtPevXv166+/SpJefPFFubq6Zmlz//33m6O2f/zxxzmuqyiej4VZf3av5fz69NNPlZKSotDQUN1zzz0O8yIjI80aLl26VOBtOSMuLk7+/v7mo3Tp0qpXr575ft66dWu9+uqrDsucPXtWS5culSQ9//zzOa7b/p71008/6dSpU+b0gnwW56YgnzWNGzdWxYoVZRiGw/QNGzZIktq3b29e426fJl0bOyE2NlaSHMaOuFnvVUBxRegG/gaMHAarKl26tPkB/tFHH2WZb5/WvXt3hwHDUlJSzKD04osvOnxBuf5x8OBBSdc+iLPTunXrG9afkpKiKVOmKCwsTFWqVJG7u7s5SEvm2+PkNBCTFZo2baoffvhBO3bs0Msvv6wuXbrI399fkpSRkaHNmzfrgQce0OOPP+5w/Avz2LVo0SLH+gIDAyXlPbw5K6fbQ9nvS12hQgXVqFEj1zbXD0j0zTffmNMDAgJyPD7//Oc/JeV8fCpUqKBatWplO89+fLLbflHK6bWak9KlS6tDhw6Srv0Ba/z48fr++++VlpZWqHXVqlUr27CcX/Yv6bnN27t3r65cuVLgbRUW+x0ISpUqpbCwsBzbRUREOLS/XlE9Hwur/tKlS+uOO+4ocD3224L1798/yx/sOnTooGrVqikpKUmfffZZgbfljIyMDJ06dcp8ZB5g7t///rc2b94sHx8fh2W+++47ZWRkSLr2PM7pPatBgwbmMpnft5z9LM5NQT9rMg8qmDlUZw7d9lCd3fwaNWo43PP+Zr1XAcUVoRsoQTL3bufntiq59ZDb//K+ZcsWhw/c06dPmyNg29vYxcfHm18wzp496/AF5fqH/ctzTr03N/oi/9tvv+m2227T6NGjtWXLFp0+fVpubm6qXLmy/Pz8zOAmSRcuXMh1XVZo3ry5xo8frzVr1ujkyZOKjY3VG2+8YZ5dMH/+fL3zzjtm+8I8djn1XEjXvmBLsjy85FSDffvO1HjixAlJUlpaWq7Hxx5OcuoRy8u2s9t+UbLvU37OZJkzZ46aNGmi06dP69VXX1XLli3l7e2te+65R1OmTCmUP7wURuCWlOs93+3z0tPTLf9jUX4kJCRIunbGkIeHR47tqlWr5tD+ekX1fCys+itWrGj2VDrr4MGD+vbbbyVl/VyRrp1R0a9fP0lFd8/u4OBgGdcuv1R6erqOHj2qSZMmycPDQ5MnT9bixYuzLGN/z5KU63tW5t7t69/Xnfkszk1hfNZkF6rtvd7t2rVTjRo1FBISov379ys+Pj7L/OvdjPcqoLgidAMlyG233Wb+/8cff8zzcrt375Z07R6uwcHBDvPatm1rfsnIfKuWRYsWKT09XX5+furUqZPDMlevXjX/v337dvMLSm6PzLfmySy7Ux0ze/zxx/Xnn38qJCREixcv1pkzZ3ThwgUlJCQoPj7eoXc7v72EVggJCdEzzzyjzZs3m7cLs5/iJxXusbtV2Y9Rly5d8nR8isPvvTCcP3/evL1OzZo187xcUFCQfvzxR61du1bDhw9Xs2bNlJGRoW+//VajR49WrVq1HL40O+NGr9O8yu22RsVdXmsvrvtY0PoL4zmQ+f7WtWrVynILN5vNZt6nfvPmzfr9998LvM2CcHV1VVBQkJ5//nm9//77Sk9P14ABA7R//36Hdvb3rNKlS+f5Pev6W9M581mcm8L4rLEH54MHD+rEiRM6fPiw4uLi1KBBA/MP3tcHc3vozu6slpvxXgUUV4RuoARp166d2dOQ11Pvzp8/r/Xr10uS2rRp49CjIl37gmXvWch8Wpv9/717986yTObe5X379uVzL/IuLi5O27Ztk3TtGr9evXqZ17za2f+6Xtzcdttt5vWK9lP3pJt37Eoy+2n6f7fjs3btWvOLcm73is6Oi4uLOnfurOnTp2vnzp06e/asFixYoKCgICUmJqpPnz7F4jTOP//8M8d59j+glSpVyuF1bn//uXz5co7LJiUlFVKFWdl7+U+fPp3jvayl/+1b5cqVLavFGcWl/vT0dH344Yd5bm8YhubNm2dJLc6IjIxU27ZtdenSJY0YMcJhnv0969KlSzp8+LBT63fmszg3hfFZc9ttt5n7tmHDBodTy+0yh+7ffvvNfB7l9B5WUt6rgMJG6AZKkICAAHPAnUWLFjmEuZy89dZbSklJkXRtMJXs2E9ZO3jwoHbs2GH+m3leZuXLlzd73a0c9CguLs78f06DrX311VeWbb+gypYtK0kOp3TerGOXG3tPVnHtIbZf53/8+HHz+u6byf6HrZt5fNLS0jRx4kRJkq+vr3r06FGg9Xl7e6tPnz7mKbqnTp1y+OKd+TThm7mfOQ0KmHle48aN5ebmZk4vX768pGunPecUGr///vsc11vQ32fz5s0lXQuNmzdvzrGd/b3IPsBicVFc6l+9erXi4+Pl5uamP//8UykpKTk+3nzzTUnXLs/J3GNb1F5++WVJ0rp16xx6ZFu1amW+rxbkfT2/n8W5KazPmszXdWfXi515MDX7/Lp16zqMU5CbG71XAbcKQjdQwrz66qsqXbq0UlNT9dBDD+mvv/7Kse2aNWs0YcIESdf+Gm0f6ft6derUMQfl+vDDD82/rDds2DDHsDt48GBJ0tdff33DD3Rnr9PKPGDMTz/9lGV+SkqKuX8304YNG2543eXx48fNL7HXDz50M45dbuyDAJ07d67Q110Y7r//fgUEBEiS/vWvf91wNOfCPkY3+/hcunRJUVFR5mUgY8eOVbly5fK07I16hOyXOEiOpwdnHgjqZj4P3nvvvWzfsw4ePGiO2vzII484zGvSpImka6F52bJlWZa9dOmS3nrrrRy3WdDfZ+PGjc3wMmHChGxD4BdffGEG/969ezu1HasUl/rtoapDhw6qWrWqypYtm+Pj0UcflYuLi44fP57r3QlutvDwcLVq1UrStcHJ7KpUqWL+QXzKlCn67bffcl1PTu9ZznwW56YwPmsyh+pNmzbJxcXFYUC+qlWrqnbt2oqNjTXPTMjuem5n36uAWwWhGyhhGjRooDlz5sjV1VX79u1T06ZNNXfuXIcvlL/99ptGjRqlbt26KS0tTTVq1NDChQtzvaavf//+kq79Rdx+PZl9WnaGDBlifjno37+/XnjhBYee6YsXL2rTpk166qmn8nV9ama33XabOfrpgAEDtGvXLnPed999p/Dw8CIZeXr06NGqUaOGnn/+eX3zzTcOA3mdPXtWc+bM0T333GOeYfDMM884LH8zjl1uGjZsKElasGBBsbpdlp2np6feffdd2Ww2/fjjj2rdurW+/PJLhy9tsbGxev/993XXXXfp3XffLdTt24/PL7/8Yl7eUNgyMjL0888/a+rUqWrQoIF5m6b+/ftr9OjReV7Ptm3b1LhxY7311lvav3+/OXCSYRjatm2bnnzySUnXBslq1KiRuVydOnXk7u4u6dqYAzert/vKlSuKiIgwe+8Mw9BXX32lzp07KzU1VdWrV9eQIUMclqlWrZp5qcaoUaP01VdfmcFx165d6tixY46Df0n/+30mJyfr008/daru119/XZK0detW9erVy7wl0pUrV7RgwQIzqLZq1arAZylYoajrP3nypNasWSNJevjhh2/YPjAw0DzjJfN14MXBv//9b0nXXnv2Ac4k6c0331TFihWVnJyse+65R3PnznW47OGvv/7S0qVL1bNnz1z/sJHfz+LcFMZnjT1AHz16VPHx8WratKl59omdPZjb/3CTXeh29r0KuGUU9EbfAIrGmjVrjMDAQEOS+fD19TU8PT0dpnXq1MlISEi44fr++usvw93d3VzOxcXF+PPPP3Nd5vTp00b79u0dtufj42OUK1fOsNls5rRSpUplWTY4ONiQZMybNy/XbaxcudIoVaqUuS4vLy/Dy8vL/P9XX31lztu4caPDsrGxsea82NjYPM+7kZYtWzrss81mM3x9fc267A93d3dj+vTp2a7D6mMXGRlpSDIiIyOzzPvoo4/M9bu5uRlVq1Y1goODjdatW+fp+GzcuNGcl5N58+YZkozg4OAc27z00kuGJCMsLCzb+f/9738djmmpUqWMihUrGh4eHg7HbcKECfnedm77d+XKFaNu3brm/PLlyxvBwcFGcHCwsXjx4hzXmdP+STL8/PzMR7ly5QwXFxeHfahUqZLx3nvv5biunI555un232fFihUdXjM+Pj7Gli1bsqxz4MCBDq+roKAgIzg42HjmmWey7ENOv6PM8vI6XLRokeHt7W1IMsqWLevw+y1XrpyxY8eObNe9e/duczlJhqenp1GmTBnz2K5evTrX13OHDh3M+d7e3ubv86233srzvk6dOtXhtVmuXDmH98xGjRoZx48fz7JcQZ+PeZHTsb9Z9d/IpEmTzOfn2bNn87TMf/7zH3OZzJ9hYWFhhiTjpZdeyrJMbvNuxP6emZf9vP322w1Jxp133ukw/ccffzRCQkIcPhvKly9vlC1b1uF12rFjxxzXnd/P4hu9Hxfks8auevXqZrvnnnsuy/xFixY5rP/UqVO51pnf9yrgVkBPN1BCdenSRYcPH9a7776rrl27qmrVqrp8+bLc3NxUp04dDRw4UF999ZW+/PLLPA2MU7FiRd17773mz/ZTAHNTqVIlffXVV/r888/Vq1cvVa9eXampqbp06ZKqVq2qrl27asaMGTpy5IjT+/mPf/xDW7Zs0X333ady5copPT1dlSpV0uOPP64ff/zRvO/nzbRx40atWrVKo0aNUps2beTn56dLly7pypUrqlSpklq1aqVx48Zp//79Gj58eLbruBnHLif9+vXTRx99pHvuuUdeXl46efKkjh49musgV0Whb9++Onz4sF544QU1b95cZcuW1blz5+Tp6anbb79dTz31lL766iuNGTOmULdbqlQpff311xo0aJBCQkJ04cIFHT16VEePHtX58+edWqf91jwJCQlKT0+Xv7+/WrZsqSeffFJLlizR8ePH9cQTT+R7vXfeeac+/fRTPfnkk2rWrJkqVaqkpKQk8xiNHj1a+/fvV5s2bbIs+8477yg6OtrsCT527JiOHj2a6yUrBdWiRQvt3LlTjz32mHx9fZWenq6qVavqn//8p/bt22def3y922+/XT/88IMeffRRValSRRkZGapUqZKGDRumPXv2ONzZITtLlizRyJEjVadOHV25csX8febnlPORI0dq586d6tevn6pXr66LFy+qdOnSatmypaZOnaoffvghz9exFoWirN/eW92xY8csvaQ56dWrl1xcXHTlypVs711dlOy93Tt27NCKFSvM6U2bNtWvv/6qGTNmqGPHjqpUqZJSUlKUkZGh2rVrq0+fPlq0aJGWLl2a47qd+SzOTWF81mTuuc5uVPJ27dqZZ9I1aNAg21sMFuS9CrgV2AyjmI6kAwAAAABACUdPNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYJFSRV1AUcnIyNCJEyfk7e1t3lsQAAAAAIC8MAxDKSkpCgwMlItLzv3Zf9vQfeLECVWvXr2oywAAAAAAlGBxcXGqVq1ajvP/tqHb29tb0rUD5OPjU8TVAAAAAABKkuTkZFWvXt3Mljn524Zu+ynlPj4+hG4AAAAAgFNudLkyA6kBAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAFBIli1bpoiICFWsWFGlS5dWaGioevfurbi4OEnSlStX9NlnnykqKkr169dXmTJl5O3trRYtWujdd9/V1atX87W9kJAQ2Wy2bB9DhgzJ0j46OjrH9p6enoVyDAA4+tsOpAYAAAAUFsMwNGTIEM2aNUs1a9bUo48+Km9vb504cUKbN2/W0aNHVb16df3+++/q1auXvL291b59e3Xr1k1JSUlauXKlhg0bprVr1+rzzz+/4cBMmfn6+mrEiBFZpjdv3jzHZSIjIxUSEuIwrVQpogFgBV5ZAAAAQAG9/fbbmjVrloYNG6bp06fL1dXVYX56erqka7etfffddxUZGSkvLy9z/ptvvqnw8HCtXLlSS5Ys0UMPPZTnbZcrV07R0dH5qjcqKkrh4eH5WgaAczi9HAAAACiAS5cu6eWXX1aNGjU0bdq0LIFb+l8vctWqVfXkk086BG5JKlOmjEaNGiVJ2rx5s/VFA7hp6OkGAAAACmD9+vU6e/asoqKidPXqVa1YsUK//fabypUrp44dO6pWrVp5Wo+bm5uk/J/mnZqaqpiYGB0/flzly5dXq1at1KRJk1yX2bp1q3744Qe5urqqXr166tixozw8PPK1XQB5Q+gGAAAACmDnzp2SroXlJk2a6ODBg+Y8FxcXjRw5Um+88cYN1zN37lxJUqdOnfK1/fj4eEVFRTlM69Kliz766CNVqlQp22XGjx/v8HNAQIBiYmIUERGRr20DuDFOLwcAAAAKICEhQdK167J9fHz0ww8/KCUlRVu2bFGdOnX05ptvaubMmbmuY9asWVqzZo3at2+ve++9N8/bHjBggDZt2qTTp08rOTlZ27dvV9euXbV27Vp169ZNhmE4tL/99tsVExOjI0eO6NKlSzp06JBeffVVnTt3Tt26ddNPP/2U/wMAIFc24/pX4t9EcnKyfH19lZSUJB8fn6IuBwAAACXU4MGDNXv2bJUuXVqHDx9WYGCgOe+XX35R48aNFRoaqsOHD2e7/OrVq/XAAw8oMDBQ3333nQICAgpUT0ZGhsLCwvTNN99o1apVuu+++264zOzZszV48GD16tVLixcvLtD2gb+LvGZKeroBAACAAvD19ZV07RZdmQO3JDVo0EA1atTQ77//rnPnzmVZ9ssvv9SDDz4oPz8/bdiwocCBW7p2Svvjjz8uSfr222/ztExkZKRKlSqV5/YA8o7QDQAAABRA3bp1JV27dVd27NMvXbrkMH3t2rXq0aOHKlWqpI0bN6pGjRqFVpP9Wu6LFy/mqb27u7u8vb3z3B5A3hG6AQAAgAJo166dJGn//v1Z5l25ckWHDx9WmTJlVLlyZXO6PXCXL19eGzduzPMI53n1/fffS5JCQkLy1P7QoUNKTEzMc3sAeUfoBgAAAAqgZs2a6tSpkw4fPqw5c+Y4zHvttdd07tw5PfDAA+atwK4P3LVr1851/VeuXNGBAwf0+++/O0z/9ddfsz1l/ZtvvtHUqVPl4eGhnj17mtNTUlK0d+/eLO0TExM1cOBASVLv3r3ztM8A8o6B1BhIDQAAAAX0+++/q1WrVkpISNB9992nevXqaffu3dqwYYOCg4O1fft2+fv768CBA7r99tuVmpqqRx991Dw1PbOQkBCHW4AdOXJEoaGhCg4O1pEjR8zp0dHRmjx5sjp06KCQkBB5eHjo559/1rp16+Ti4qL33ntPgwYNyrKe5s2bq1GjRqpSpYqOHz+uNWvW6MyZM4qIiNCqVavk7u5u5aECbhl5zZTcpxsAAAAooJo1a2rnzp0aP3681q5dq3Xr1snf31/Dhg3T+PHjVaVKFUnX7qmdmpoqSVq0aFG26woLC8ty3+3stGvXTvv379ePP/6ozZs36/Lly/Lz89MjjzyikSNH6q677nJoX6FCBQ0bNkzbt2/XypUrde7cOZUpU0aNGjVSv379NGjQILm6uhbsQADIgp5ueroBAAAAAPnELcMAAAAAAChihG4AAAAAACxC6AYAAAAAwCIMpAYAAHCr6xtV1BUAyGzB/KKuADcRPd0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFik2Ibu48ePq1+/fqpYsaK8vLx0++23a9euXeZ8wzAUHR2twMBAlS5dWuHh4frll1+KsGIAAAAAABwVy9CdmJio1q1by83NTWvWrNGvv/6qN998U+XKlTPbTJ48WVOnTtWMGTO0Y8cO+fv7KyIiQikpKUVXOAAAAAAAmZQq6gKy8/rrr6t69eqaN2+eOS0kJMT8v2EYmjZtmsaNG6eePXtKkmJiYuTn56eFCxfqiSeeuNklAwAAAACQRbHs6V6xYoWaN2+uhx56SFWqVFHTpk01e/Zsc35sbKzi4+PVqVMnc5qHh4fCwsK0bdu2oigZAAAAAIAsimXo/uOPPzRz5kzVrl1bX375pYYMGaLhw4frww8/lCTFx8dLkvz8/ByW8/PzM+ddLzU1VcnJyQ4PAAAAAACsVCxPL8/IyFDz5s01ceJESVLTpk31yy+/aObMmXrsscfMdjabzWE5wzCyTLObNGmSXn75ZeuKBgAAAADgOsWypzsgIEC33Xabw7T69evr2LFjkiR/f39JytKrnZCQkKX3227s2LFKSkoyH3FxcRZUDgAAAADA/xTL0N26dWsdPHjQYdpvv/2m4OBgSVJoaKj8/f21fv16c35aWpo2b96sVq1aZbtODw8P+fj4ODwAAAAAALBSsTy9fOTIkWrVqpUmTpyohx9+WD/88INmzZqlWbNmSbp2WvmIESM0ceJE1a5dW7Vr19bEiRPl5eWlPn36FHH1AAAAAABcUyxD95133qlly5Zp7NixeuWVVxQaGqpp06apb9++ZpvRo0fr0qVLGjp0qBITE9WiRQutW7dO3t7eRVg5AAAAAAD/YzMMwyjqIopCcnKyfH19lZSUxKnmAADg1tY3qqgrAJDZgvlFXQEKQV4zZbG8phsAAAAAgFsBoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwSLEM3dHR0bLZbA4Pf39/c75hGIqOjlZgYKBKly6t8PBw/fLLL0VYMQAAAAAAWRXL0C1JDRo00MmTJ83Hvn37zHmTJ0/W1KlTNWPGDO3YsUP+/v6KiIhQSkpKEVYMAAAAAICjYhu6S5UqJX9/f/NRuXJlSdd6uadNm6Zx48apZ8+eatiwoWJiYnTx4kUtXLiwiKsGAAAAAOB/im3oPnTokAIDAxUaGqpHH31Uf/zxhyQpNjZW8fHx6tSpk9nWw8NDYWFh2rZtW47rS01NVXJyssMDAAAAAAArFcvQ3aJFC3344Yf68ssvNXv2bMXHx6tVq1Y6c+aM4uPjJUl+fn4Oy/j5+ZnzsjNp0iT5+vqaj+rVq1u6DwAAAAAAFMvQ3bVrVz344INq1KiROnbsqNWrV0uSYmJizDY2m81hGcMwskzLbOzYsUpKSjIfcXFx1hQPAAAAAMD/VyxD9/XKlCmjRo0a6dChQ+Yo5tf3aickJGTp/c7Mw8NDPj4+Dg8AAAAAAKxUIkJ3amqq9u/fr4CAAIWGhsrf31/r168356elpWnz5s1q1apVEVYJAAAAAICjUkVdQHaeffZZ3X///QoKClJCQoImTJig5ORkRUZGymazacSIEZo4caJq166t2rVra+LEifLy8lKfPn2KunQAAAAAAEzFMnT/+eef6t27t/766y9VrlxZLVu21Pbt2xUcHCxJGj16tC5duqShQ4cqMTFRLVq00Lp16+Tt7V3ElQMAAAAA8D82wzCMoi6iKCQnJ8vX11dJSUlc3w0AAG5tfaOKugIAmS2YX9QVoBDkNVOWiGu6AQAAAAAoiQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARUoVZOErV67o4MGDOn36tJKSkuTr66vKlSurbt26cnNzK6waAQAAAAAokfIduk+fPq358+dr9erV+uGHH5Sampqljaenp+666y7dd999ioyMVOXKlQulWAAAAAAASpI8h+5Dhw5p/PjxWrZsmdLS0iRJlSpVUrNmzVShQgX5+PgoKSlJiYmJOnDggDZv3qzNmzfrhRdeUM+ePfXKK6+oVq1alu0IAAAAAADFTZ5C99NPP61Zs2bp6tWrateunfr06aPw8HCFhobmuMwff/yhjRs3auHChfr000/12WefafDgwXr77bcLrXgAAAAAAIozm2EYxo0aeXl5afDgwRo9erQCAwPzvZHjx49r8uTJmjNnji5cuOBUoYUtOTlZvr6+SkpKko+PT1GXAwAAYJ2+UUVdAYDMFswv6gpQCPKaKfPU0/3HH3/I39/f6WKqVq2q6dOna+zYsU6vAwAAAACAkiZPtwwrSOC2Yj0AAAAAAJQE3KcbAAAAAACLFFro3rt3ryIjI3XnnXfqrrvu0oABA7R///7CWj0AAAAAACVOoYTuxYsXq1mzZlq+fLlcXFx08eJFxcTEqEmTJlq7dm1hbAIAAAAAgBKnUEL36NGj1blzZx0/flzff/+9fv75Z+3cuVNlypRh8DQAAAAAwN9WnkL37Nmzc5x3+fJlHT16VEOGDFHZsmXN6U2bNlX79u05xRwAAAAA8LeVp9A9ZMgQtWjRQjt37swyz9PTU76+vtq0aZPD9AsXLmj37t2MWA4AAAAA+NvKU+j+5ptvlJ6erpYtW2rw4ME6c+aMw/yhQ4dq6tSp6tixo55//nkNHz5cDRo00JEjRzR06FBLCgcAAAAAoLjLU+i+++67tXPnTr399ttaunSp6tSpo5kzZ8owDEnShAkT9MYbb2j//v2aPHmyZsyYoYyMDM2YMUOjR4+2dAcAAAAAACiu8jyQms1m05NPPqnffvtNDz74oJ5++mk1a9ZM27Ztk81m06hRo3T8+HElJSUpKSlJx44dK5Re7kmTJslms2nEiBHmNMMwFB0drcDAQJUuXVrh4eH65ZdfCrwtAAAAAAAKU75HL69QoYJmzZql77//Xu7u7mrTpo2ioqJ0+vRpSZK3t7e8vb0LpbgdO3Zo1qxZaty4scP0yZMna+rUqZoxY4Z27Nghf39/RUREKCUlpVC2CwAAAABAYXD6lmHNmjXT9u3bNXv2bK1Zs0Z16tTR9OnTlZGRUSiFnT9/Xn379tXs2bNVvnx5c7phGJo2bZrGjRunnj17qmHDhoqJidHFixe1cOHCQtk2AAAAAACFIV+h+9SpU9qwYYOWLFmiHTt2KC0tTQMGDNBvv/2mfv366dlnn9Xtt9+uLVu2FLiwYcOG6b777lPHjh0dpsfGxio+Pl6dOnUyp3l4eCgsLEzbtm3LcX2pqalKTk52eAAAAAAAYKU8he7U1FQNGzZMQUFBioiI0MMPP6yWLVuqVq1aWrJkiXx9ffX2229r165dKleunNq1a6e+ffvqxIkTThW1aNEi/fjjj5o0aVKWefHx8ZIkPz8/h+l+fn7mvOxMmjRJvr6+5qN69epO1QYAAAAAQF7lKXQ/99xzmjlzptq1a6cFCxZozZo1euutt+Ti4qJHH33UvH9348aNtWXLFsXExGjTpk2qV6+epkyZkq+C4uLi9K9//Uv//e9/5enpmWM7m83m8LNhGFmmZTZ27FhzkLekpCTFxcXlqy7g7+zcuXMaPny47r77bvn7+8vDw0NVq1ZV+/bt9dlnn5l3MrCz2Ww3fDj7Gpw8ebK5ju3bt2eZHx0dneM2c3tPAQAAAKxQKi+NFi1apDvuuENr1641p3Xu3Fnt2rVTkyZN9Mknn6h58+bmvH79+qlHjx6Kjo7Wiy++qOeeey7PBe3atUsJCQlq1qyZOe3q1avasmWLZsyYoYMHD0q61uMdEBBgtklISMjS+52Zh4eHPDw88lwHgP/566+/NHfuXLVs2VI9evRQhQoVlJCQoJUrV6pXr1765z//qVmzZpntX3rppWzXc/jwYS1YsED169d36myT/fv3a/z48SpTpowuXLiQa9vIyEiFhIQ4TCtVKk9veQAAAEChydM30AsXLmQbaP39/SVJly5dyjKvbNmyeuONNzRo0KB8FdShQwft27fPYdrjjz+uevXqacyYMapRo4b8/f21fv16NW3aVJKUlpamzZs36/XXX8/XtgDkTWhoqM6dO5cltKakpKhly5aaPXu2/vWvf6lBgwaSrvU2Z+fpp5+WpHy/L0jX/vgWGRmpJk2aqE6dOvrvf/+ba/uoqCiFh4fnezsAAABAYcrT6eXt2rXTl19+qSlTpighIUFXrlzRr7/+qgEDBshms+X6xbZevXr5Ksjb21sNGzZ0eJQpU0YVK1ZUw4YNzXt2T5w4UcuWLdPPP/+sqKgoeXl5qU+fPvnaFoC8cXV1zbaX2NvbW507d5Z0rRc7N5cvX9aCBQvk7u6u/v3757uG119/XT/99JPmzp0rV1fXfC8PAAAAFIU89XS/88476tq1q8aMGaPnn3/eYd4///lP9erVy5LicjJ69GhdunRJQ4cOVWJiolq0aKF169YV2v3BAeTN5cuXtWHDBtlsNt122225tl26dKkSExPVq1cvVa5cOV/b+fnnn/Xyyy/rhRdeMHvTb2Tr1q364Ycf5Orqqnr16qljx45cYgIAAICbLk+hOzg4WD///LOWLl2qPXv2KDExUUFBQeratasaN25sdY3atGmTw882m03R0dE5nsIKwBrnzp3TtGnTlJGRoYSEBH3xxReKi4vTSy+9pNq1a+e67AcffCAp/6eWp6enKyoqSvXr18/yR7/cjB8/3uHngIAAxcTEKCIiIl/bBwAAAAoiz6MKubi4qFevXje9VxtA8XHu3Dm9/PLL5s9ubm6aMmWKnnnmmVyXi42N1caNG83bDubHxIkT9dNPP+n777+Xm5vbDdvffvvtiomJUVhYmPz8/PTnn39q0aJFmjhxorp166bt27erSZMm+aoBAAAAcBZD+QLIs5CQEBmGoatXryouLk6LFi3SuHHjtG3bNn366ac5jg4+d+5cGYahxx9/XC4ueRpKQpL0008/acKECXr22Wd1xx135GmZHj16OPxcq1YtvfDCC/Lz89PgwYM1YcIELV68OM81AAAAAAWRp2+/69evL5SNrVu3rlDWA6Boubq6KiQkRM8//7wmTJigZcuWafbs2dm2zcjI0Pz58+Xi4qIBAwbkazuRkZGqWbNmoVxKEhkZqVKlSunbb78t8LoAAACAvMpT6O7cubPuuecerVq1SlevXs3XBtLT07V8+XLdfffd6tq1q1NFAii+OnXqJCnr2At2a9eu1Z9//qmIiAgFBQXla90//fSTDhw4IE9PT9lsNvMRExMjSbr77rtls9m0fPnyG67L3d1d3t7eunjxYr5qAAAAAAoiT6eXz5s3T+PHj1f37t1VqVIlPfzwwwoLC9Odd96p4ODgLO3/+OMP/fDDD9q4caM+++wzJSYmqnr16po/f35h1w+giJ04cUKScjy13NkB1CRp4MCB2U7fsmWLDh06pG7duqly5coKCQm54boOHTqkxMRErucGAADATWUzDMPIS8PU1FS9++67eu+993To0CHZbDZJ1wZSKl++vLy9vZWcnKzExESlp6dLkgzDUJ06dTR06FA98cQTxep2PcnJyfL19VVSUpJ8fHyKuhygWNuzZ49CQ0Pl6+vrMP3s2bPq0KGD9uzZo48++kj9+vVzmH/69GlVrVpVvr6+On78uNzd3bNd/5UrV/T777/Lzc1NNWvWvGE9UVFRiomJ0XfffaeWLVua01NSUhQbG5vlrgqJiYnq3r27tm7dqtdee01jxozJ664DwK2hb1RRVwAgswXzi7oCFIK8Zso8D6Tm4eGhkSNHauTIkdqyZYtWrVqlrVu3au/evTp16pROnTolSSpdurSaNWumNm3a6L777lPbtm0LvjcAitT8+fM1Z84ctWvXTsHBwSpTpoyOHj2q1atX6/z583rwwQfVp0+fLMt9+OGHunLlih577LEcA7ckHT9+XPXr11dwcLCOHDnidJ1nzpxRkyZN1Lx5czVq1EhVqlTR8ePHtWbNGp05c0YREREaOXKk0+sHAAAA8sup0cvbtm3rEKYvXLigpKQk+fr6qkyZMoVWHIDioVevXkpKStL27du1ZcsWXbx4URUqVNA999yjxx57TI8++qh59ktmBTm13BkVKlTQsGHDtH37dq1cuVLnzp1TmTJl1KhRI/Xr10+DBg2Sq6vrTakFAAAAkPJxevmthtPLAQDA3wanlwPFC6eX3xLyminzfsNcAAAAAACQL4RuAAAAAAAsQugGAAAAAMAiTg2kBhQ7XKsGFC9cqwYAACCJnm4AAAAAACxD6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIk4PpJaamqqPP/5YW7Zs0cmTJ5WampptO5vNpq+//trpAgEAAAAAKKmcCt3Hjx9Xhw4ddOjQIRmGkWtbm83mVGEAAAAAAJR0ToXu5557Tr/99ptatWqlZ555RnXq1FHZsmULuzYAAAAAAEo0p0L3l19+qaCgIH311Vfy9PQs7JoAAAAAALglODWQWmpqqu68804CNwAAAAAAuXAqdDdq1Eh//vlnYdcCAAAAAMAtxanQPWbMGO3YsUObN28u7HoAAAAAALhlOHVN9x133KFnnnlG999/v0aNGqWIiAhVq1Ytx5HKg4KCClQkAAAAAAAlkVOhOyQkRDabTYZh6NVXX9Wrr76aY1ubzab09HSnCwQAAAAAoKRyKnS3bduW+28DAAAAAHADToXuTZs2FXIZAAAAAADcepwaSA0AAAAAANyYUz3d1ztz5oxOnDghm82mgIAAVaxYsTBWCwAAAABAiVagnu733ntPt912m6pUqaLbb79dTZo0UZUqVdSgQQO99957hVUjAAAAAAAlklM93RkZGXr44Ye1bNkyGYahcuXKKTg4WJJ07Ngx7d+/X8OGDdNXX32lxYsXM+gaAAAAAOBvyame7lmzZmnp0qWqU6eOVqxYobNnz2r37t3avXu3zpw5o5UrV6pu3bpatmyZZs2aVdg1AwAAAABQIjgVuufNmycfHx9t2rRJ//jHP7LMv++++7RhwwaVLVtWc+fOLXCRAAAAAACURE6F7l9//VXt27eXn59fjm38/f3VoUMH/frrr04XBwAAAABASWbpLcO4lhsAAAAA8HfmVOiuW7euNm7cqDNnzuTY5q+//tKGDRtUt25dp4sDAAAAAKAkcyp0R0ZGKikpSR07dtTmzZuzzN+0aZMiIiKUnJysqKiogtYIAAAAAECJ5NQtw4YOHaq1a9dqzZo1at++vfz9/RUSEiKbzabY2FjFx8fLMAzde++9Gjp0aGHXDAAAAABAieBU6HZ1ddXKlSv11ltv6T//+Y/i4uJ08uRJc35QUJCefvppjRw5Ui4ull42DgAAAABAseVU6JYkFxcXPfPMM3rmmWcUFxenEydOSJICAwNVvXr1QisQAAAAAICSyunQnVn16tUJ2gAAAAAAXIdzvwEAAAAAsEieeroHDBggm82miRMnys/PTwMGDMjzBmw2mz744AOnCwQAAAAAoKTKU+ieP3++bDabxowZIz8/P82fPz/PGyB0AwAAAAD+rvIUujdu3Cjp2qjkmX8GAAAAAAA5y1PoDgsLy/VnAAAAAACQlVMDqW3ZskW//fbbDdsdOnRIW7ZscWYTAAAAAACUeE6F7vDwcL3++us3bDd58mS1a9fOmU0AAAAAAFDiOX3LMMMwCqUNAAAAAAC3Kkvv033ixAmVLVvWyk0AAAAAAFBs5WkgNUn68MMPHX4+fPhwlml26enpOnjwoL766iu1bNmyYBUCAAAAAFBC5Tl0R0VFyWazSbp27+1vv/1W3377bY7tDcOQp6enxo8fX/AqAQAAAAAogfIcusePHy+bzSbDMPTKK6/o9ttvV/fu3bNt6+7ursDAQHXq1EkBAQGFViwAAAAAACVJnkN3dHS0+f+YmBh17NhRL730khU1AQAAAABwS3BqILUePXrI29u7sGsBAAAAAOCW4lTofuedd7R3797CrgUAAAAAgFuKU6G7WrVqysjIKOxaAAAAAAC4pTgVuh944AFt3rxZKSkphV0PAAAAAAC3DKdCd3R0tIKCgnTvvfdq9+7dhV0TAAAAAAC3hDyPXp5Z9+7d5eHhoW+//VbNmzdXQECAgoKC5OnpmaWtzWbT119/XeBCAQAAAAAoaZwK3Zs2bTL/bxiGTpw4oRMnTmTb1mazOVUYAAAAAAAlnVOhOzY2trDrAAAAAADgluNU6A4ODi7sOgAAAAAAuOU4NZCa1WbOnKnGjRvLx8dHPj4+uvvuu7VmzRpzvmEYio6OVmBgoEqXLq3w8HD98ssvRVgxAAAAAABZOdXTbXf69GnNmzdPW7du1YkTJ2Sz2RQQEKC2bdsqMjJSVapUcWq91apV02uvvaZatWpJkmJiYtS9e3ft3r1bDRo00OTJkzV16lTNnz9fderU0YQJExQREaGDBw/K29u7ILsEAAAAAEChsRmGYTiz4GeffaaBAwcqJSVF16/CZrPJ29tbc+fOVc+ePQul0AoVKmjKlCkaMGCAAgMDNWLECI0ZM0aSlJqaKj8/P73++ut64okn8rS+5ORk+fr6KikpST4+PoVSI4pQ36iirgBAZgvmF3UFADLjcxIoXvicvCXkNVM6dXr5zp071bt3b50/f14PPPCAli1bpt27d2v37t1avny5evbsqfPnz6t3797auXOn0zshSVevXtWiRYt04cIF3X333YqNjVV8fLw6depktvHw8FBYWJi2bduW43pSU1OVnJzs8AAAAAAAwEpOnV4+adIkXb16VYsXL87Sk92kSRN169bNDN+vvfaalixZku9t7Nu3T3fffbcuX76ssmXLatmyZbrtttvMYO3n5+fQ3s/PT0ePHs215pdffjnfdQAAAAAA4Cynerq/+eYbtWrVKtdTx3v06KHWrVtr69atThVWt25d7dmzR9u3b9eTTz6pyMhI/frrr+b86+//bRhGrvcEHzt2rJKSksxHXFycU3UBAAAAAJBXTvV0JyUlKSgo6IbtgoKCtGPHDmc2IXd3d3MgtebNm2vHjh2aPn26eR13fHy8AgICzPYJCQlZer8z8/DwkIeHh1O1AAAAAADgDKd6uv39/bVnz54bttuzZ4/8/f2d2UQWhmEoNTVVoaGh8vf31/r16815aWlp2rx5s1q1alUo2wIAAAAAoDA4Fbo7d+6sAwcO6MUXX8wycrl0LSC/8MILOnDggLp06ZLv9f/73//W1q1bdeTIEe3bt0/jxo3Tpk2b1LdvX9lsNo0YMUITJ07UsmXL9PPPPysqKkpeXl7q06ePM7sDAAAAAIAlnDq9/MUXX9TSpUs1ceJELVq0SA8//LBCQkJks9kUGxurTz75RLGxsapYsaJeeOGFfK//1KlT6t+/v06ePClfX181btxYa9euVUREhCRp9OjRunTpkoYOHarExES1aNFC69at4x7dAAAAAIBixen7dO/bt099+/bVzz//fG1F/38QM/vqGjVqpAULFqhhw4aFVGrh4j7dtxjuPwoUL9x/FChe+JwEihc+J28Jec2UTvV0S9dC9d69e7Vp0yZt3bpVJ06ckCQFBgaqTZs2Cg8Pd3bVAAAAAADcEpwO3Xbh4eEEbAAAAAAAsuHUQGrZSUlJUUpKSmGtDgAAAACAEq9AoXvVqlXq2rWrfH19Va5cOZUrV04+Pj7q2rWrVq5cWVg1AgAAAABQIjkVug3D0MCBA9W9e3d9+eWXSklJka+vr3x8fHT+/Hl9+eWX6tGjh6KiorK9pRgAAAAAAH8HToXu6dOna968eQoICNDMmTOVlJSks2fPKjExUUlJSZo5c6YCAgL00Ucfafr06YVdMwAAAAAAJYJToXvWrFny8vLS1q1b9cQTTzjcH9vb21tPPPGEtm7dqtKlS2vWrFmFViwAAAAAACWJU6E7NjZWHTp0UGhoaI5tQkND1aFDB8XGxjpdHAAAAAAAJZlTobty5cpyd3e/YTt3d3dVqlTJmU0AAAAAAFDiORW6H3jgAW3YsEGJiYk5tjl79qw2bNigHj16OFsbAAAAAAAlmlOhe8KECapRo4bat2+vDRs2ZJm/YcMGRUREqEaNGpo4cWKBiwQAAAAAoCQq5cxC3bt3l7u7u3bt2qWIiAhVqFBBwcHBkqRjx47pzJkzkqSWLVuqe/fuDsvabDZ9/fXXBSwbAAAAAIDiz6nQvWnTJvP/hmHozJkzZtDO7LvvvssyzWazObNJAAAAAABKHKdCNyOSAwAAAABwY06Fbvup5AAAAAAAIGdODaQGAAAAAABuzKmebrvTp09r3rx52rp1q06cOCGbzaaAgAC1bdtWkZGRqlKlSmHVCQAAAABAieN06P7ss880cOBApaSkyDAMh3lffPGF/u///k9z585Vz549C1wkAAAAAAAlkVOnl+/cuVO9e/fW+fPn9cADD2jZsmXavXu3du/ereXLl6tnz546f/68evfurZ07dxZ2zQAAAAAAlAhO9XRPmjRJV69e1eLFi7P0ZDdp0kTdunUzw/drr72mJUuWFEqxAAAAAACUJE71dH/zzTdq1apVrqeO9+jRQ61bt9bWrVudLg4AAAAAgJLMqdCdlJSkoKCgG7YLCgpSUlKSM5sAAAAAAKDEcyp0+/v7a8+ePTdst2fPHvn7+zuzCQAAAAAASjynQnfnzp114MABvfjii1lGLpckwzD0wgsv6MCBA+rSpUuBiwQAAAAAoCRyaiC1F198UUuXLtXEiRO1aNEiPfzwwwoJCZHNZlNsbKw++eQTxcbGqmLFinrhhRcKu2YAAAAAAEoEp0J3tWrVtGHDBvXt21c///yzJk2aJJvNJklmz3ejRo20YMECVatWrfCqBQAAAACgBHEqdEvXQvXevXu1adMmbd26VSdOnJAkBQYGqk2bNgoPDy+sGgEAAAAAKJGcCt09e/ZUQECA3nnnHYWHhxOwAQAAAADIhlMDqX3xxRc6c+ZMYdcCAAAAAMAtxanQHRoaqgsXLhR2LQAAAAAA3FKcCt29e/fW5s2bFR8fX9j1AAAAAABwy3AqdI8dO1Zt2rRRWFiYli1bpitXrhR2XQAAAAAAlHhODaRWt25dZWRkKC4uTr169ZLNZlOVKlXk6emZpa3NZtPvv/9e4EIBAAAAAChpnArdR44ccfjZMAxONQcAAAAA4DpOhe6MjIzCrgMAAAAAgFuOU9d0AwAAAACAG8tXT/cXX3yh5cuXKy4uTh4eHmrcuLEef/xxhYaGWlUfAAAAAAAlVp5Dd9++fbVo0SJJ167hlqSVK1fqjTfe0KJFi9StWzdrKgQAAAAAoITKU+j+4IMP9PHHH6tUqVLq37+/mjZtqpSUFK1atUrfffedHnvsMR09elS+vr5W1wsAAAAAQImRp9AdExMjFxcXrVmzRh06dDCnjx07Vo8//rg+/PBDLV26VI8//rhlhQIAAAAAUNLkaSC1ffv2qWXLlg6B2+7f//63DMPQvn37Cr04AAAAAABKsjyF7uTkZNWsWTPbefbpycnJhVcVAAAAAAC3gDyFbsMw5Orqmv0KXK6tgnt3AwAAAADgiPt0AwAAAABgkTyH7piYGLm6umb7sNlsOc4vVSpftwIHAAAAAOCWkedEbL83d345uxwAAAAAACVdnkI312sDAAAAAJB/XNMNAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARYpl6J40aZLuvPNOeXt7q0qVKurRo4cOHjzo0MYwDEVHRyswMFClS5dWeHi4fvnllyKqGAAAAACArIpl6N68ebOGDRum7du3a/369UpPT1enTp104cIFs83kyZM1depUzZgxQzt27JC/v78iIiKUkpJShJUDAAAAAPA/pYq6gOysXbvW4ed58+apSpUq2rVrl9q2bSvDMDRt2jSNGzdOPXv2lCTFxMTIz89PCxcu1BNPPFEUZQMAAAAA4KBY9nRfLykpSZJUoUIFSVJsbKzi4+PVqVMns42Hh4fCwsK0bdu2bNeRmpqq5ORkhwcAAAAAAFYq9qHbMAyNGjVK99xzjxo2bChJio+PlyT5+fk5tPXz8zPnXW/SpEny9fU1H9WrV7e2cAAAAADA316xD91PPfWU9u7dq48//jjLPJvN5vCzYRhZptmNHTtWSUlJ5iMuLs6SegEAAAAAsCuW13TbPf3001qxYoW2bNmiatWqmdP9/f0lXevxDggIMKcnJCRk6f228/DwkIeHh7UFAwAAAACQSbHs6TYMQ0899ZSWLl2qDRs2KDQ01GF+aGio/P39tX79enNaWlqaNm/erFatWt3scgEAAAAAyFax7OkeNmyYFi5cqM8//1ze3t7mddq+vr4qXbq0bDabRowYoYkTJ6p27dqqXbu2Jk6cKC8vL/Xp06eIqwcAAAAA4JpiGbpnzpwpSQoPD3eYPm/ePEVFRUmSRo8erUuXLmno0KFKTExUixYttG7dOnl7e9/kagEAAAAAyF6xDN2GYdywjc1mU3R0tKKjo60vCAAAAAAAJxTLa7oBAAAAALgVELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsEixDN1btmzR/fffr8DAQNlsNi1fvtxhvmEYio6OVmBgoEqXLq3w8HD98ssvRVMsAAAAAAA5KJah+8KFC2rSpIlmzJiR7fzJkydr6tSpmjFjhnbs2CF/f39FREQoJSXlJlcKAAAAAEDOShV1Adnp2rWrunbtmu08wzA0bdo0jRs3Tj179pQkxcTEyM/PTwsXLtQTTzxxM0sFAAAAACBHxbKnOzexsbGKj49Xp06dzGkeHh4KCwvTtm3birAyAAAAAAAcFcue7tzEx8dLkvz8/Bym+/n56ejRozkul5qaqtTUVPPn5ORkawoEAAAAAOD/K3E93XY2m83hZ8MwskzLbNKkSfL19TUf1atXt7pEAAAAAMDfXIkL3f7+/pL+1+Ntl5CQkKX3O7OxY8cqKSnJfMTFxVlaJwAAAAAAJS50h4aGyt/fX+vXrzenpaWlafPmzWrVqlWOy3l4eMjHx8fhAQAAAACAlYrlNd3nz5/X4cOHzZ9jY2O1Z88eVahQQUFBQRoxYoQmTpyo2rVrq3bt2po4caK8vLzUp0+fIqwaAAAAAABHxTJ079y5U+3atTN/HjVqlCQpMjJS8+fP1+jRo3Xp0iUNHTpUiYmJatGihdatWydvb++iKhkAAAAAgCyKZegODw+XYRg5zrfZbIqOjlZ0dPTNKwoAAAAAgHwqcdd0AwAAAABQUhC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALBIiQ7d7777rkJDQ+Xp6almzZpp69atRV0SAAAAAACmEhu6P/nkE40YMULjxo3T7t271aZNG3Xt2lXHjh0r6tIAAAAAAJBUgkP31KlTNXDgQA0aNEj169fXtGnTVL16dc2cObOoSwMAAAAAQFIJDd1paWnatWuXOnXq5DC9U6dO2rZtWxFVBQAAAACAo1JFXYAz/vrrL129elV+fn4O0/38/BQfH5/tMqmpqUpNTTV/TkpKkiQlJydbVyhunitpRV0BgMx4bwWKFz4ngeKFz8lbgj1LGoaRa7sSGbrtbDabw8+GYWSZZjdp0iS9/PLLWaZXr17dktoA4G9t8cdFXQEAAMUXn5O3lJSUFPn6+uY4v0SG7kqVKsnV1TVLr3ZCQkKW3m+7sWPHatSoUebPGRkZOnv2rCpWrJhjUAdw8yQnJ6t69eqKi4uTj49PUZcDAECxw2clULwYhqGUlBQFBgbm2q5Ehm53d3c1a9ZM69ev1wMPPGBOX79+vbp3757tMh4eHvLw8HCYVq5cOSvLBOAEHx8fvkgAAJALPiuB4iO3Hm67Ehm6JWnUqFHq37+/mjdvrrvvvluzZs3SsWPHNGTIkKIuDQAAAAAASSU4dD/yyCM6c+aMXnnlFZ08eVINGzbUF198oeDg4KIuDQAAAAAASSU4dEvS0KFDNXTo0KIuA0Ah8PDw0EsvvZTlMhAAAHANn5VAyWQzbjS+OQAAAAAAcIpLURcAAAAAAMCtitANAAAAAIBFCN0AAAAAAFiE0A2gWHj33XcVGhoqT09PNWvWTFu3bi3qkgAAKBa2bNmi+++/X4GBgbLZbFq+fHlRlwQgHwjdAIrcJ598ohEjRmjcuHHavXu32rRpo65du+rYsWNFXRoAAEXuwoULatKkiWbMmFHUpQBwAqOXAyhyLVq00B133KGZM2ea0+rXr68ePXpo0qRJRVgZAADFi81m07Jly9SjR4+iLgVAHtHTDaBIpaWladeuXerUqZPD9E6dOmnbtm1FVBUAAABQOAjdAIrUX3/9patXr8rPz89hup+fn+Lj44uoKgAAAKBwELoBFAs2m83hZ8MwskwDAAAAShpCN4AiValSJbm6umbp1U5ISMjS+w0AAACUNIRuAEXK3d1dzZo10/r16x2mr1+/Xq1atSqiqgAAAIDCUaqoCwCAUaNGqX///mrevLnuvvtuzZo1S8eOHdOQIUOKujQAAIrc+fPndfjwYfPn2NhY7dmzRxUqVFBQUFARVgYgL7hlGIBi4d1339XkyZN18uRJNWzYUG+99Zbatm1b1GUBAFDkNm3apHbt2mWZHhkZqfnz59/8ggDkC6EbAAAAAACLcE03AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAoMT566+/9OKLL6pp06YqV66cvLy8VKtWLQ0ePFg///xzUZdX6DZt2iSbzaaoqCiH6fPnz5fNZlN0dHS+1rdjxw716dNH1atXl7u7u8qVK6e6devqwQcf1Ntvv62kpKTCK74QhYeHy2az6ciRI0VdCgAAeUboBgCUKF999ZVq166tCRMm6Pjx4woLC9M//vEPubm5afbs2br99tv12muvFXWZxdYHH3ygli1b6uOPP5anp6e6du2qLl26yNfXVytWrNDw4cO1f//+IqnNZrMpJCSkSLZdFEJCQmSz2Yq6DACAxUoVdQEAAOTVjh07dN999+nKlSuaNGmSnn32WZUq9b+Psi+++EL9+vXT2LFj5eXlpeHDhxdhtcXP8ePHNWzYMBmGoTlz5mjAgAEOoe+vv/7SRx99pHLlyhVdkbn48MMPdfHiRVWtWrWoSwEAIM/o6QYAlAiGYSgyMlJpaWl65ZVX9PzzzzsEbkm69957tXz5ctlsNo0ZM0ZHjx4tomqLpy+++EKpqalq3bq1Bg4cmKWXtVKlSho5cqTq1atXRBXmLigoSPXq1ZObm1tRlwIAQJ4RugEAJcKaNWu0f/9+Va1aVWPGjMmxXdu2bfXQQw/p8uXLeueddyRJV65cUcWKFeXp6alz585lu9wPP/wgm82m1q1bZ5m3cuVKde7c2VxHnTp19OKLL+r8+fNZ2ma+7njhwoVq2bKlvL29HXqPV69erQEDBqh+/fry8fFRmTJl1KRJE02cOFGpqan5OzD5cPr0aUlS5cqV873s+fPn9corr6hRo0by8vKSj4+PwsLCtHz58ixtjxw5IpvNpvDwcF26dEnPP/+8goOD5eHhoVq1aun111+XYRhme/u16ZJ09OhR2Ww28xEeHm62y+mabvtp6enp6Xr11VdVq1YtlS5dWvXr19e8efPMdhs2bFC7du3k4+Oj8uXL67HHHtOZM2ey3d+0tDRNnz5dd955p7y9vVWmTBnddddd+uCDDxxqv76Gq1evavLkyapTp448PDxUvXp1jRkzxuH3ar9G3/5Hocz7+3c6vR4A/i4I3QCAEuGLL76QJD300EM37Ons06ePpGtBXZLc3Nz00EMPKTU1VZ999lm2yyxcuFCS1LdvX4fpzzzzjLp166YtW7aoYcOGuu+++5SWlqYJEyYoPDxcFy5cyHZ9kyZNUv/+/eXu7q5//OMfatiwoTlv4MCBWrx4sXx9fdWlSxe1adNGcXFxGjdunO69915dvXo1D0ck/6pVqyZJ+vrrr3Xo0KE8L3fq1Cm1aNFCL730khITExUREaEWLVpo165deuCBB3K8hj4tLU2dOnXSrFmzVL9+fbVr107Hjx/X888/rxdffNFsV6tWLUVGRkqSypQpo8jISPPRpUuXPNf58MMPa8qUKapZs6batm2r2NhYDRgwQPPmzdOSJUvUuXNnpaSkKCIiQmXKlNFHH32kHj16ZAnRFy5cUMeOHTVixAgdOXJE99xzj8LDw3X48GENGjRITz75ZI419O3bV6+88oqqVaumTp06KSUlRZMnT9bAgQPNNv7+/oqMjFSZMmUkyWF/e/Xqlef9BQCUEAYAACVA69atDUnGRx99dMO2cXFxhiTDxcXFSEtLMwzDMLZs2WJIMtq3b5+l/dWrV42AgACjVKlSxunTp83pn3zyiSHJaNq0qREbG2tOT0tLMwYPHmxIMp599lmHdYWFhRmSDE9PT2PTpk3Z1rds2TLj/PnzDtOSk5ONf/zjH4YkIyYmxmHexo0bDUlGZGSkw/R58+YZkoyXXnrpRofEMAzDOHfunFG5cmWzvl69ehkzZswwdu3aZaSnp+e4XNeuXQ1JxujRo83jaRiG8fvvvxs1a9Y0XF1djZ9++smcHhsba0gyJBlt2rRxOKY7duwwSpUqZXh5eRkpKSkO25FkBAcH51iH/dhm/l3Yl5NkNGzY0IiLizOnb9iwwZBkBAQEGBUrVjSWLFlizktKSjIaNGhgSDI2bNjgsL4nn3zSkGT079/focaEhASjRYsWhiRj1apV2dZQv359h/r++OMPo3z58oYk4/Dhww7LBAcHG3wVA4BbHz3dAIASwX4acJUqVW7Y1n76dEZGhs6ePStJuueeexQcHKxNmzbpxIkTDu03bNigkydPqnPnzqpUqZI5feLEiZKkjz/+2OG0Xzc3N02fPl3+/v6aM2eOMjIystQwcOBAhYWFZVtfjx49zF5OO29vb7311luSpM8///yG++gMX19frV27VnXr1tXly5e1ZMkSPfXUU2rWrJkqVqyoIUOGZDk2e/bs0Zo1a9SqVSu99tprDmcZ1KhRQ2+++aauXr2qOXPmZNmei4uL5syZ43BMmzdvrq5du+rixYvauXNnoe7ff/7zH7M3X5LatWunO+64QydPntR9992nBx980Jzn4+OjwYMHS5I2b95sTk9ISNCcOXMUGhqq2bNnq2zZsua8ypUr6/3335ck89/rvf322w7PldDQUPXr10+StHXr1oLvJACgxCF0AwBKBOP/nwJsZHM9bU5tJZnXCttsNvXu3VsZGRlatGiRQ/vsTi1PSEjQTz/9pPr166tu3bpZtuHp6anmzZvr3Llz2Z6q3a1bt1xrPHTokKZPn66nn35aAwYMUFRUlF599VVznlXuuOMO/fLLL1q9erWeeuopNW/eXG5ubkpKStL777+vpk2b6uDBg2b79evXS5K6d++e7e2t7rnnHknXRpa/XkhIiOrUqZNlun3ayZMnC2WfJMnd3T3bP3LUqFFDkhQREZFlXs2aNbPUsXnzZl25ckVdunSRh4dHlmWaNGkib2/vbPfXzc3N4Rp0Oyv2FwBQchC6AQAlgr23NCEh4YZt7QOG2Ww2lS9f3pxuD9ULFiwwp6Wmpmrp0qUqU6aMunfvbk63D3K1f/9+h4GuMj9WrVol6dqttq4XFBSUbW2GYeiZZ55R3bp1NWLECM2YMUPz5s1TTEyMPvzwQ0lSSkrKDfexIFxdXXXvvffq7bff1o4dO/TXX39p9uzZqlixohISEvTUU0+Zbe2Dlo0ZMybbY2D/vWR3DDL3Omdm7z0uzEHj/P395eKS9WuN/YyC7G4zZp+XuQ77/s6cOTPH33tKSkq2+xsQECBXV9cs063YXwBAycF9ugEAJUKTJk307bffateuXerfv3+ubXft2iVJatCggcPp0A0bNlTjxo31448/6sCBA6pXr55Wr16tpKQk9evXT15eXmZb+2BmAQEB6tSpU67bq1ixYpZpnp6e2bb95JNPNHXqVFWrVk3Tpk3T3XffrcqVK8vNzU1paWny8PDIU29+YfLx8dGgQYPk7++v+++/Xxs3btTFixfl5eVlHoc2bdqYvcbZyXwKuV12PeNWudG28lqLfX+bNm2qxo0bF2oNAIC/J0I3AKBE6Nq1q959910tWbJEU6ZMyXUEc/vp4tmNfN23b1/t3btXCxcu1CuvvJLjqOX2Xlp/f3/Nnz+/kPZCWrZsmaRrPan/+Mc/HOb98ccfhbYdZ9hPjb569arOnTsnLy8v8zj06tVLw4cPL8Lqbg77/oaHh2vq1KlFXA0A4FbA6eUAgBLh3nvvVd26dXX8+HG9/vrrObbbsmWLlixZInd3dw0bNizL/D59+shms2nhwoVKTk7W6tWrVaVKFXXs2NGhXbVq1VS3bl3t3btXsbGxhbYfiYmJkqTq1atnmffpp58W2nayc6Me9N9//13Steuj7T3X9uOS3f24C5ubm5vS09Mt305u2rVrJ1dXV61atcqyW7fZubu7S1KR7zMAwFqEbgBAieDi4qL58+fLzc1N48eP1+uvv54lFK1Zs8a87/Jrr73mMIq0XbVq1dS2bVv9/vvvGjNmjC5fvqxHHnlEpUplPfnrhRde0NWrV/Xggw/q559/zjL/999/19y5c/O1H/ZBtWbNmuUQgrdu3aopU6bka135NXPmTD3xxBPZ7suJEyc0ZMgQSdJ9991nBsKWLVuqQ4cO2rhxo0aOHKnz5887LJeRkaF169bpm2++KXB9gYGBOnXqlM6dO1fgdTmratWqioqK0qFDh9S/f/9sr93etm2bed/4gggMDJQkh4HrAAC3HkI3AKDEaNmypVasWCEfHx89//zzCgwMVI8ePfTII4/otttu07333qukpCS9+uqrGjlyZI7rsZ9K/t577zn8fL1+/fpp9OjR2r17t26//Xbdeeedevjhh9WlSxfVr19ftWrV0n/+85987cPw4cNVpkwZvfvuu2rYsKF69+6ttm3bKiwszAy9VklLS9OsWbPUqFEj1ahRQ927dze3Hxoaqu3btys0NFTTp093WG7BggVq3Lixpk2bpuDgYHXo0EGPPvqo2rRpI39/f3Xu3LlQbv/VrVs3paen64477lC/fv00aNAgy/8QkZ3//Oc/ateunT7++GPVqFFDbdu21aOPPqrw8HBVq1ZNrVu31rp16wq8HfsI9x06dFDv3r01aNAgPf/88wVeLwCgeOGabgBAidKlSxfzdlurVq3Shg0bdOXKFQUEBGjQoEF6+umnbzgA1kMPPaSnn35aqampqlmzplq0aJFj29dff12dO3fWjBkz9N133+mnn35S+fLlVa1aNT333HN69NFH81V/nTp1tGPHDo0ZM0bff/+9VqxYobp16+r999/XP//5T73xxhv5Wl9+DBgwQNWqVdPatWu1a9cufffdd0pMTJS3t7eaNWumbt26adiwYfL29nZYzs/PT9u3b9d7772nTz75RDt27FBaWpoCAgLUtGlTde/eXQ8//HCB65s0aZIMw9Dnn3+uTz75ROnp6QoLC9Nzzz1X4HXnh5eXl9atW6eYmBh99NFH2rt3r77//ntVqVJFNWvW1L/+9S/17t27wNsZPny4EhMT9fHHH+uzzz7TlStXFBwcrNdee60Q9gIAUFzYjJs9RCoAAAAAAH8TnF4OAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBF/h+2OkydSGmpHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create distribution results for our target variable\n",
    "overall_sentiment_distribution=round(df_reviews_by_listing['Overall_sentiment'].value_counts(normalize=True).sort_index()*100, 2)\n",
    "\n",
    "# Determine figure size\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create barplot\n",
    "ax = overall_sentiment_distribution.plot.bar(color='#FF5A5F')\n",
    "\n",
    "# Add labels\n",
    "plt.title('Overall Sentiment Distribution for All Reviews', fontsize=18)\n",
    "plt.xlabel('Overall Sentiment', fontsize=15)\n",
    "plt.ylabel('Proportion (%)', fontsize=15)\n",
    "plt.bar_label(ax.containers[0], size=14)\n",
    "plt.xticks(rotation = 360)\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "# plt.savefig('Overall_Sentiment_Distribution.jpg', dpi =300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665cc3f",
   "metadata": {},
   "source": [
    "The current sentiment score distribution (37:63) is not as balanced as it was analysed in the listing level. This imbalance indicates a potential bias in the dataset, with a disproportionate number of reviews having positive sentiments compared to negative sentiments.\n",
    "\n",
    "To address this issue, we plan to **downsample** reviews with positive sentiments in the next sampling stage. This approach aims to create a more even distribution of the target variable, enhancing the model's ability to generalize across different sentiment categories. However, to avoid potential **data leakage**, we will only perform sampling on the **training** dataset after **Train Test Split**.\n",
    "\n",
    "We also conclude that this imbalance may be attributed to positive review bias, where guests are more inclined to leave positive reviews. Additionally, the reinforcement effect further amplifies this bias, as the presence of positive reviews may influence subsequent guests to also leave positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d16187",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdb760",
   "metadata": {},
   "source": [
    "## Train Test Split <a id='a3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0134dd9d",
   "metadata": {},
   "source": [
    "The modelling process starts by splitting our dataset into training and testing sets. This procedure is fundamental for the effective evaluation of our model performance.\n",
    "\n",
    "The training data is implemented upon which our model is built and refined, and the testing data provides the benchmark for assessing the model's predictive performance on unseen data. This ensures us to mitigate the risk of **overfitting**, as our model will not just memorize the data pattern but rather learns to generalize on new, unseen data.\n",
    "\n",
    "Additionally, it is important that this splitting process must precede any data transformation steps including random sampling, text vectorization and scaling to prevent potential **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2c1d4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows obtained in the training data is 329486, with 38 feature columns.\n",
      "The number of rows obtained in the testing data is 141209, with 38 feature columns.\n"
     ]
    }
   ],
   "source": [
    "# Split test data as 30% of all data, determine random state to make sure every split is the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "\n",
    "# Show the number of rows for training and testing dataset\n",
    "print(f'The number of rows obtained in the training data is {X_train.shape[0]}, with {X_train.shape[1]} feature columns.')\n",
    "print(f'The number of rows obtained in the testing data is {X_test.shape[0]}, with {X_train.shape[1]} feature columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa0a28",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a654b52",
   "metadata": {},
   "source": [
    "## Sampling <a id='a3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83efc19d",
   "metadata": {},
   "source": [
    "Since we have a large training dataset with nearly 330k rows and an imbalanced target variable, we will perform **downsampling** on the training dataset by randomly select a balanced number of rows for both positive labelled rows and negative labelled rows.\n",
    "\n",
    "We will eventually select 3% of the original training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f366a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that can perform downsampling on training data and make it perfectly balanced\n",
    "def downsample_train(X_train, y_train, target, proportion):\n",
    "    '''\n",
    "    Function only works on target variable as binary column. \n",
    "    \n",
    "    Returns downsampled X_train and y_train which\n",
    "    has downsampled to specified proportion of original\n",
    "    data, also makes sure y_train is balanced\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - X_train: dataframe, splitted feature training data\n",
    "    - y_train: dataframe, splitted farget training data\n",
    "    - target: str, target variable name\n",
    "    - proportion: float, specified downsample proportion of total training data\n",
    "    \n",
    "    RETURNS:\n",
    "    - X_train_sample: Downsampled X_train\n",
    "    - y_train_sample: Downsampled y_train\n",
    "    \n",
    "    '''\n",
    "    # Specify number of rows for each class \n",
    "    num_rows_each = round(proportion*X_train.shape[0]/2)\n",
    "    \n",
    "    # Temporarily concatenate X_train and y_train back to dataframe format\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # Split classes\n",
    "    df_pos = df_train[df_train[target] == 1]\n",
    "    df_neg = df_train[df_train[target] == 0]\n",
    "    \n",
    "    # Resplit X and y for both two classes\n",
    "    X_pos, y_pos = df_pos.drop(target, axis=1), df_pos[target]\n",
    "    X_neg, y_neg = df_neg.drop(target, axis=1), df_neg[target]\n",
    "    \n",
    "    # Select randomized samples from each class\n",
    "    X_pos_sample, y_pos_sample = resample(X_pos, y_pos, random_state=123, n_samples = num_rows_each, replace=False, stratify=y_pos)\n",
    "    X_neg_sample, y_neg_sample = resample(X_neg, y_neg, random_state=123, n_samples = num_rows_each, replace=False, stratify=y_neg)\n",
    "    \n",
    "    # Concatenate back downsampled data\n",
    "    X_train_sample = pd.concat([X_pos_sample, X_neg_sample], axis=0)\n",
    "    y_train_sample = pd.concat([y_pos_sample, y_neg_sample], axis=0)\n",
    "    \n",
    "    return X_train_sample, y_train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0160c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return downsampled training data\n",
    "X_train_sample, y_train_sample = downsample_train(X_train, y_train, 'Overall_sentiment', 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1505646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current proportion of each sentiment score class is (%)\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: Overall_sentiment, dtype: float64\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "The current number of rows in the training data is 9884\n"
     ]
    }
   ],
   "source": [
    "# Check for current target variable distribution\n",
    "print('The current proportion of each sentiment score class is (%)')\n",
    "print((y_train_sample.value_counts(normalize=True))*100)\n",
    "print('\\n--------------------------------------------\\n')\n",
    "print(f'The current number of rows in the training data is {X_train_sample.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4563a",
   "metadata": {},
   "source": [
    "Thus we have downsampled our training data from nearly 330k (329486) rows to nearly 10k (9884), and we also obtained a balanced training data. We will hope that this will potentially improve our model performance and also help the models to generalize well in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a416e95",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342b1bd",
   "metadata": {},
   "source": [
    "## Helper Function <a id='a3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dc5e5",
   "metadata": {},
   "source": [
    "Our dataset includes multiple non-review features, in the later text vectorization stage, it is not necessary for these columns to be processed by the vectorizers. Hence, we require a helper function to handle these numerical columns separately, and generate a column transformer based on our selection on different text vectorizers including `CountVectorizer` and `TfidfVectorizer`. \n",
    "\n",
    "Additionally, the numerical features in our dataset vary across different ranges, necessitating the scaling of data during the modeling stage. However, the text vectorizers will return a sparse matrix after transformation, while scalers like `StandardScaler` and `MinMaxScaler` require a dense array as input. Hence, we'll also need a function to convert the sparse matrix into a dense array.\n",
    "\n",
    "This code is borrowed from [Allistair Cota](https://github.com/allistaircota/rate_my_restaurant/blob/main/notebooks/NB3-Modelling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb460db",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "| Vectorizer  | Scaler| \n",
    "|:-------:|:--------:|\n",
    "|[TF-IDF Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) |  [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  |\n",
    "|[Count-Vectorizer](https://en.wikipedia.org/wiki/Bag-of-words_model)  |[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0926d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical column names\n",
    "numeric_columns = X.select_dtypes(exclude='object').columns.to_list()\n",
    "\n",
    "def define_col_trans(input_text, vectorizer):\n",
    "    '''\n",
    "    Returns a ColumnTransformer which first performs a \n",
    "    passthrough on the numeric columns, then applies\n",
    "    a vectorizer on the `text` column\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - input_text: str, to name the vectorizer tuple\n",
    "    - vectorizer: Sklearn text vectorizer\n",
    "    \n",
    "    RETURNS:\n",
    "    - col_trans: sklearn ColumnTransformer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_trans = ColumnTransformer([\n",
    "        ('numeric', 'passthrough', numeric_columns), # numerical_columns defined above\n",
    "        (input_text, vectorizer, 'comments') # 'comments' as review text feature column\n",
    "    ])\n",
    "    \n",
    "    return col_trans\n",
    "\n",
    "def convert_to_array(sparse_matrix):\n",
    "    '''\n",
    "    Converts sparse matrix to dense array\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - sparse_matrix: scipy.sparse.csr_matrix or numpy array\n",
    "    \n",
    "    RETURNS:\n",
    "    - If sparse_matrix is not a scipy.sparse.csr_matrix,\n",
    "      sparse_matrix is returned. Else, returns the dense array\n",
    "      form of sparse_matrix.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if type(sparse_matrix) == csr_matrix:\n",
    "    \n",
    "        return sparse_matrix.toarray()\n",
    "    \n",
    "    else:\n",
    "        return sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8abc66",
   "metadata": {},
   "source": [
    "#### Text vectorizer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db199847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformers\n",
    "ct_bow = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))\n",
    "ct_tfidf = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7114081d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3cfef3",
   "metadata": {},
   "source": [
    "# Baseline Model <a id='a4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434d87c",
   "metadata": {},
   "source": [
    "As we are developing the best performed models for predicting the class of guest sentiments, it is crucial to establish a baseline model for comparison. We will utilise a **Dummy Classifier** model, which makes predictions without accessing dataset features, essentially performing random guessing. By establishing this baseline, we can decide that any model performing worse than the baseline model will not proceed to further analysis.\n",
    "\n",
    "**Run Time**: 3mins 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f98cdde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transfomed_dummy : (9884, 537)\n",
      "CPU times: total: 4min 20s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Vectorize data using Bag of Words Vectorizer\n",
    "bow_vec = CountVectorizer(max_features = 500, # Only obtain top 500 features based on vectorizer results\n",
    "                            min_df=5, # Feature occurency should be bigger than 5 in the corpus\n",
    "                            tokenizer=customized_tokenizer)\n",
    "\n",
    "# Fit and transform on the vectorizer to training data\n",
    "X_train_tfidf_d = bow_vec.fit_transform(X_train_sample['comments']).toarray()\n",
    "\n",
    "# Transform on both training data and testing data\n",
    "X_test_tfidf_d = bow_vec.transform(X_test['comments']).toarray()\n",
    "\n",
    "# Reset Index before concatenating\n",
    "X_train_sample_reset_index = X_train_sample.reset_index(drop=True)\n",
    "X_test_reset_index = X_test.reset_index(drop=True)\n",
    "\n",
    "# Merge the resulting arrays with the original numeric features\n",
    "X_train_tfidf_d_transformed = pd.concat([X_train_sample_reset_index.drop(['comments'], axis=1),\n",
    "                                         pd.DataFrame(X_train_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis=1)\n",
    "\n",
    "X_test_tfidf_d_transformed = pd.concat([X_test_reset_index.drop(['comments'], axis=1), \n",
    "                                        pd.DataFrame(X_test_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis = 1)\n",
    "\n",
    "# Print shape of the vectorized training feature data\n",
    "print(f'X_train_transfomed_dummy : {X_train_tfidf_d_transformed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1b11365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score (%) for the Baseline Model is: 37.42 %\n"
     ]
    }
   ],
   "source": [
    "# # Dummy Classifier - Baseline Model\n",
    "# Instantiate Dummy Classifier\n",
    "dummy_classifier = DummyClassifier()\n",
    "\n",
    "# Fit the Dummy Classifier on Training data\n",
    "dummy_classifier.fit(X_train_tfidf_d_transformed, y_train_sample)\n",
    "\n",
    "# Predict the fitted model on Testing Data\n",
    "y_predict_d = dummy_classifier.predict(X_test_tfidf_d_transformed)\n",
    "\n",
    "# Print F1 score\n",
    "print(f'The Accuracy Score (%) for the Baseline Model is: {round(accuracy_score(y_test, y_predict_d)*100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5838e7e",
   "metadata": {},
   "source": [
    "#### Classification report <a id='a4.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a83404bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54     52835\n",
      "           1       0.00      0.00      0.00     88374\n",
      "\n",
      "    accuracy                           0.37    141209\n",
      "   macro avg       0.19      0.50      0.27    141209\n",
      "weighted avg       0.14      0.37      0.20    141209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report to see specific classification evaluation metrics scores\n",
    "baseline_report = classification_report(y_test, y_predict_d)\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a65f74",
   "metadata": {},
   "source": [
    "Based on the findings from the classification report, the model classification accuracy score achieved by the dummy classifier is **37.42%**. This baseline performance indicates that future models should aim to surpass this threshold to be considered effective. Therefore, our goal for future models is to achieve an accuracy score higher than 38%, indicating improved predictive capability and accuracy in classifying sentiments. \n",
    "\n",
    "**Note**: This result is reflected by the actual proportion of negative sentiments in the testing dataset as Dummy Classifier takes random guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a846797",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5017ccb",
   "metadata": {},
   "source": [
    "# Modelling <a id='a5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24562de3",
   "metadata": {},
   "source": [
    "After completing data cleaning, pre-processing, and model setup stages, we are ready to train models and make predictions. To determine the best-performing model, we will utilize **GridSearchCV** to find the optimal model with the best hyperparameters. Machine learning metrics and models to be used in our modeling process include:\n",
    "\n",
    "- Text Vectorizer: Bag of Words, TF-IDF\n",
    "- Scaler: StandardScaler\n",
    "- Models: Logistic Regression, Decision Tree Classifier, Random Forest Classifier.\n",
    "\n",
    "Note that for performance purposes, we will be vectorizing the datasets outside of grid search. We will then fit combinations of models to the training data that has been transformed by two types of text vectorizations. During the fitting process, **5-fold cross-validation** will be performed to improve model performance and interpretability. Finally, the model with the highest average validation F1 score will be selected and evaluated at the end of each GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c3c1",
   "metadata": {},
   "source": [
    "## GridSearch_1: General Sweep <a id='a5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368eae4",
   "metadata": {},
   "source": [
    "During the first GridSearch, we will be searching for optimal hyperparameters over wide range implementing on the **Logistic Regresion** and **Decision Tree Classifier**. This GridSearch will be run and fitted on two vectorized training sets defined above and we will evaluate the model performances with a brief summary. The selections of models and parameters are summarized below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005cfc5",
   "metadata": {},
   "source": [
    "|    Models   |    Hyperparameters   |   Ranges/Options  |\n",
    "|:-------------:|:-------------:|:-------------:|\n",
    "|    **TfidfVectorizer**     |     max_df   |    0.95     |\n",
    "|                  |     min_df  |    5       |\n",
    "|       **CountVectorizer**           |     max_df  |    0.95       |\n",
    "|                  |     min_df  |    5       |\n",
    "|    **Logistic Regression**     |    C     |    0.001, 0.01, 0.1, 1, 10    |\n",
    "|         |    penalty     |    'none', 'l2'     | \n",
    "|    **Decision Tree Classifier**     |     max_depth    |     2, 8, 32, 64, 128    |\n",
    "|                 |    min_samples_leaf     |     2, 4, 8    |\n",
    "|                 |     min_samples_split    |     2, 4, 8    |\n",
    "|                 |     criterion    |     'gini', 'entropy'    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583a21c",
   "metadata": {},
   "source": [
    "To save long execution times for future references, we will use a loading flag to prevent re-training models when it is already saved and can be loaded as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3dee142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming training sample data .....\n",
      "Training sample data transformed.\n",
      "Loaded pre-trained models\n",
      "CPU times: total: 41 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# # First GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Fit and transform on training data using two types of vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow = ct_bow.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf= ct_tfidf.fit_transform(X_train_sample)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_1 = True\n",
    "\n",
    "if loaded_flag_1:\n",
    "    print('Loaded pre-trained models (Gridsearch_1)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_1_bow=joblib.load('data/fittedgrid_1_bow.pkl')\n",
    "    fittedgrid_1_tfidf=joblib.load('data/fittedgrid_1_tfidf.pkl')\n",
    "else:\n",
    "    # Define base pipeline\n",
    "    pipeline_1 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_1 = [\n",
    "\n",
    "        # Logistic Regression\n",
    "        {\n",
    "            'model'              : [LogisticRegression()],\n",
    "            'model__C'           : [0.001, 0.01, 0.1, 1, 10], # C parameter to control penalty weights\n",
    "            'model__penalty'     : ['none', 'l2'], # Control penalty types, l1: Lasso, l2: Ridge\n",
    "            'model__random_state': [123], # Control gradient descent starting point\n",
    "            'model__max_iter'    : [10000] # Make sure model iterates\n",
    "        },\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     :[123] # Control randomness of the estimator\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_1 = GridSearchCV(estimator=pipeline_1, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_1, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') \n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_1_bow = grid_1.fit(X_train_ct_bow, y_train_sample)\n",
    "    fittedgrid_1_tfidf = grid_1.fit(X_train_ct_tfidf, y_train_sample)\n",
    "    \n",
    "    # Save fittedgrid as pickle file\n",
    "    joblib.dump(fittedgrid_1_bow, 'data/fittedgrid_1_bow.pkl')\n",
    "    joblib.dump(fittedgrid_1_tfidf, 'data/fittedgrid_1_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40779eb0",
   "metadata": {},
   "source": [
    "#### Selected model results with Bag of Words transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "485d4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x000001900A481A80>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 DecisionTreeClassifier(criterion='entropy', max_depth=32,\n",
      "                                        min_samples_leaf=2, min_samples_split=8,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 2721 features, but StandardScaler is expecting 2674 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print Crossvalidated Score\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Model Train Score (%): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(fittedgrid_1_bow\u001b[38;5;241m.\u001b[39mscore(X_train_ct_bow,\u001b[38;5;250m \u001b[39my_train_sample)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100.00\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print Testing Score\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:471\u001b[0m, in \u001b[0;36mBaseSearchCV.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# callable\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_, X, y)\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultimetric_:\n\u001b[0;32m    473\u001b[0m     score \u001b[38;5;241m=\u001b[39m score[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m method_caller(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, X)\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py:85\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     pos_label \u001b[38;5;241m=\u001b[39m pos_label \u001b[38;5;28;01mif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 85\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m prediction_method(X)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    505\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 507\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1005\u001b[0m     X,\n\u001b[0;32m   1006\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1007\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1008\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1009\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1010\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1011\u001b[0m )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2721 features, but StandardScaler is expecting 2674 features as input."
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_bow.score(X_train_ct_bow, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow = ct_bow.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_bow.score(X_test_ct_bow, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef59db",
   "metadata": {},
   "source": [
    "#### Selected model results with TF-IDF transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5397a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_tfidf.score(X_train_ct_tfidf, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf = ct_tfidf.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_tfidf.score(X_test_ct_tfidf, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a50e8",
   "metadata": {},
   "source": [
    "#### Top 20 models with best F1 scores resulted with TF-IDF transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeca04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand column width to see full results\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Store results in a dataframe by sorting mean_test_score in descending order\n",
    "fittedgrid1_results_df = pd.DataFrame(fittedgrid_1_tfidf.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "# Extract ranking number, models with tuned hyperparameters, and corresponding test scores\n",
    "fittedgrid1_results = fittedgrid1_results_df[['rank_test_score', 'params', 'mean_test_score']].sort_values('mean_test_score', ascending=False)\n",
    "print('GridSearch 1 Cross Validation Results')\n",
    "\n",
    "# Show top 10 cross validation results\n",
    "fittedgrid1_results.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe6f2c",
   "metadata": {},
   "source": [
    "Next, we will study the currently selected best model in more detail by examining if there are patterns in its misclassified reviews. We will first obtain the more specific evaluation results by looking at the classification report and plotting a corresponding confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe0f2e",
   "metadata": {},
   "source": [
    "#### GridSearch_1 Result Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0d4af",
   "metadata": {},
   "source": [
    "From the first gridsearch, we successfully selected our current best model: Decision Tree Classifier with \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ead0a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279cfff",
   "metadata": {},
   "source": [
    "## GridSearch_2 : Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b673a",
   "metadata": {},
   "source": [
    "After the first grid search, we obtained more focused parameter ranges and a currently best performed DT model. Our next step is to aim for better interpretability and hopefully further enhance our model performance by adding n-grams to the vectorizer. N-grams are essentially pairs of consecutive words that help maintain the sequence and interpretability of the tokens. In our second grid search, we will use bigrams (2 words), trigrams (3 words), and remove single words for both the bag-of-words vectorizer and the TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ece3190c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 32.8 s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# # Second GridSearch\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# Define column transformers with ngrams added\n",
    "ct_bow_ngrams = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "ct_tfidf_ngrams = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "\n",
    "# Fit and transform on training data using new vectorizers\n",
    "print('Transforming training sample data .....')\n",
    "X_train_ct_bow_ngrams = ct_bow_ngrams.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf_ngrams= ct_tfidf_ngrams.fit_transform(X_train_sample)\n",
    "print('Training sample data transformed.')\n",
    "#-----------------------------------------------------------------------------------------------------------------#\n",
    "# If one needs to retrain the model, set loading flag as False\n",
    "loaded_flag_2 = True\n",
    "\n",
    "if loaded_flag_2:\n",
    "    print('Loaded pre-trained models (Gridsearch_2)')\n",
    "    # Load saved fittedgrid\n",
    "    fittedgrid_2_bow=joblib.load('data/fittedgrid_2_bow.pkl')\n",
    "    fittedgrid_2_tfidf=joblib.load('data/fittedgrid_2_tfidf.pkl')\n",
    "else:\n",
    "\n",
    "    # Define base pipeline\n",
    "    pipeline_2 = Pipeline([\n",
    "        ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Instantiate Pipeline with grid of parameters\n",
    "    grid_param_2 = [\n",
    "\n",
    "        # Decision Tree Classifier\n",
    "        {\n",
    "            'model'                   : [DecisionTreeClassifier()],\n",
    "            'model__max_depth'        : [32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4], # Control minimum number of samples at a leaf node\n",
    "            'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "            'model__criterion'        : ['entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator\n",
    "        },\n",
    "\n",
    "        # Random Forest\n",
    "        {\n",
    "            'model'                   : [RandomForestClassifier()],\n",
    "            'model__n_estimators'     : [20,30,40,50], # Control number of trees in the forest\n",
    "            'model__max_depth'        : [8, 32, 64, 128], # Control number of tree splits/depth\n",
    "            'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "            'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "            'model__random_state'     : [123] # Control randomness of the estimator  \n",
    "        }  \n",
    "    ]\n",
    "\n",
    "    # Use GridSearch\n",
    "    grid_2 = GridSearchCV(estimator=pipeline_2, # Define GridSearch estimator pipeline\n",
    "                         param_grid=grid_param_2, # Define parameter grid\n",
    "                         cv=5, # Define 5-fold cross-validation\n",
    "                         n_jobs=-2,\n",
    "                         scoring='f1') # Define GridSearch evaluation metric to be f1 score\n",
    "\n",
    "    # Fit the grid on training data\n",
    "    fittedgrid_2_bow = grid_2.fit(X_train_ct_bow_ngrams, y_train_sample)\n",
    "    fittedgrid_2_tfidf = grid_2.fit(X_train_ct_tfidf_ngrams, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccb9ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.64\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Test Score (%): 84.74\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_bow.score(X_train_ct_bow_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_bow_ngrams = ct_bow_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_bow.score(X_test_ct_bow_ngrams, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32de69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      "\n",
      "Pipeline(steps=[('sparse_to_dense',\n",
      "                 FunctionTransformer(accept_sparse=True,\n",
      "                                     func=<function convert_to_array at 0x0000023A8D118CC0>)),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('model',\n",
      "                 RandomForestClassifier(max_depth=32, min_samples_leaf=2,\n",
      "                                        min_samples_split=8, n_estimators=50,\n",
      "                                        random_state=123))])\n",
      "\n",
      "--------------------\n",
      "\n",
      "Best Model Train Score (%): 92.94\n",
      "\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_2_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_2_tfidf.score(X_train_ct_tfidf_ngrams, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on testing data to evaluate model actual performance\n",
    "X_test_ct_tfidf_ngrams = ct_tfidf_ngrams.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_2_tfidf.score(X_test_ct_tfidf_ngrams, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ab74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot graphs for bow fitted grid with bow transformed data \n",
    "extract_key_words_plot(fittedgrid_2_tfidf, ct_tfidf_ngrams, 20, 'ct_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f4b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3e05a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clcapstone",
   "language": "python",
   "name": "clcapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
