{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787923b4",
   "metadata": {},
   "source": [
    "# Predicting Star Ratings of Edinburgh Airbnbs through Review Texts Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a2bb0",
   "metadata": {},
   "source": [
    "# Notebook 4: Modelling_Review_Uncollapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f247c3",
   "metadata": {},
   "source": [
    "In this notebook, we will further process our Airbnb reviews using natural language processing (NLP) and machine learning techniques. We will first define a customized tokenizer to remove any irrelevant contents from the text and separate the review texts into individual words. Next, we will set up for modelling stage including define the Baseline Score for future model evaluation.  After that, we will utilize different machine learning models and attempt to find the best-performing models by tuning hyperparameters using GridSearch. Finally, we will use evaluation metrics to assess our results.\n",
    "\n",
    "**Note**: The review data used in this notebook is the cleaned and processed review dataset with listing information aggregated to each review. The reviews are **not collapsed** to each Airbnb Listing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d621c2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505f46e",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f590c6e3",
   "metadata": {},
   "source": [
    "1. [**Import Libraries**](#a1)<br>\n",
    "\n",
    "2. [**Customized Tokenizer**](#a2)<br>\n",
    "    \n",
    "3. [**Modelling Set Up**](#a3)<br>\n",
    "    3.1.[Split Variables](#a3.1)<br>\n",
    "    3.2.[Target Varaible Distribution](#a3.2)<br>\n",
    "    3.3.[Train Test Split](#a3.3)<br>\n",
    "    3.4.[Sampling](#a3.4)<br>\n",
    "    3.5.[Helper Function](#a3.5)<br>\n",
    "        \n",
    "4. [**Baseline Model**](#a4)<br>\n",
    "    4.1.[Baseline Model Evaluation](#a4.1)<br>\n",
    "5. [**Modelling**](#a5)<br>\n",
    "    5.1.[GridSearch_1: General Sweep](#a5.1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f0775",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497aff3",
   "metadata": {},
   "source": [
    "## Import Libraries <a id='a1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eff6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\12276\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Main Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scipy Library for sparse  matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import html\n",
    "import contractions\n",
    "import langid\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from langid.langid import LanguageIdentifier\n",
    "\n",
    "# Download from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Feature Extraction Libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Dummy Classifer \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Modelling Libraries\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation Libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db98bf",
   "metadata": {},
   "source": [
    "#### Loading Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae965a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load uncollapsed review data\n",
    "df_reviews_by_listing= joblib.load('data/df_reviews_by_listing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834226c",
   "metadata": {},
   "source": [
    "#### Ignore userwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b6a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore UserWarning\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6581506",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962fa654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathroom_num</th>\n",
       "      <th>beds</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>...</th>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <th>host_verifications_email</th>\n",
       "      <th>host_verifications_phone</th>\n",
       "      <th>host_verifications_work_email</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.957590</td>\n",
       "      <td>-3.188050</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My wife and I stayed at this beautiful apartme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.957590</td>\n",
       "      <td>-3.188050</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte couldn't have been a more thoughtful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.957590</td>\n",
       "      <td>-3.188050</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I went to Edinburgh for the second time on Apr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.957590</td>\n",
       "      <td>-3.188050</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This flat was incredible. As other guests have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15420</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.957590</td>\n",
       "      <td>-3.188050</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fantastic host and the apartment was perfect. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470700</th>\n",
       "      <td>1019511603156105862</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.966645</td>\n",
       "      <td>-3.242519</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I had an amazing stay at Luka's Airbnb! The pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470701</th>\n",
       "      <td>1019511603156105862</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.966645</td>\n",
       "      <td>-3.242519</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>The place felt like home. Amazing facilities a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470702</th>\n",
       "      <td>1019517614597169568</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.966060</td>\n",
       "      <td>-3.243009</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Loved it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470703</th>\n",
       "      <td>1019517614597169568</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.966060</td>\n",
       "      <td>-3.243009</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I must admit my own faults: 1) booked same nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470704</th>\n",
       "      <td>1019517614597169568</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.966060</td>\n",
       "      <td>-3.243009</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nice place and very clean n tidy all room, Kit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470705 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 listing_id  host_response_rate  host_acceptance_rate  \\\n",
       "0                     15420               100.0                  92.0   \n",
       "1                     15420               100.0                  92.0   \n",
       "2                     15420               100.0                  92.0   \n",
       "3                     15420               100.0                  92.0   \n",
       "4                     15420               100.0                  92.0   \n",
       "...                     ...                 ...                   ...   \n",
       "470700  1019511603156105862               100.0                  97.0   \n",
       "470701  1019511603156105862               100.0                  97.0   \n",
       "470702  1019517614597169568               100.0                  97.0   \n",
       "470703  1019517614597169568               100.0                  97.0   \n",
       "470704  1019517614597169568               100.0                  97.0   \n",
       "\n",
       "        host_is_superhost   latitude  longitude  accommodates  bathroom_num  \\\n",
       "0                       0  55.957590  -3.188050             2           1.0   \n",
       "1                       0  55.957590  -3.188050             2           1.0   \n",
       "2                       0  55.957590  -3.188050             2           1.0   \n",
       "3                       0  55.957590  -3.188050             2           1.0   \n",
       "4                       0  55.957590  -3.188050             2           1.0   \n",
       "...                   ...        ...        ...           ...           ...   \n",
       "470700                  0  55.966645  -3.242519             2           1.0   \n",
       "470701                  0  55.966645  -3.242519             2           1.0   \n",
       "470702                  0  55.966060  -3.243009             2           1.0   \n",
       "470703                  0  55.966060  -3.243009             2           1.0   \n",
       "470704                  0  55.966060  -3.243009             2           1.0   \n",
       "\n",
       "        beds  minimum_nights  ...  host_response_time_within a day  \\\n",
       "0        1.0               3  ...                                0   \n",
       "1        1.0               3  ...                                0   \n",
       "2        1.0               3  ...                                0   \n",
       "3        1.0               3  ...                                0   \n",
       "4        1.0               3  ...                                0   \n",
       "...      ...             ...  ...                              ...   \n",
       "470700   2.0               1  ...                                0   \n",
       "470701   2.0               1  ...                                0   \n",
       "470702   2.0               1  ...                                0   \n",
       "470703   2.0               1  ...                                0   \n",
       "470704   2.0               1  ...                                0   \n",
       "\n",
       "        host_response_time_within a few hours  \\\n",
       "0                                           1   \n",
       "1                                           1   \n",
       "2                                           1   \n",
       "3                                           1   \n",
       "4                                           1   \n",
       "...                                       ...   \n",
       "470700                                      0   \n",
       "470701                                      0   \n",
       "470702                                      0   \n",
       "470703                                      0   \n",
       "470704                                      0   \n",
       "\n",
       "        host_response_time_within an hour  host_verifications_email  \\\n",
       "0                                       0                         1   \n",
       "1                                       0                         1   \n",
       "2                                       0                         1   \n",
       "3                                       0                         1   \n",
       "4                                       0                         1   \n",
       "...                                   ...                       ...   \n",
       "470700                                  1                         1   \n",
       "470701                                  1                         1   \n",
       "470702                                  1                         1   \n",
       "470703                                  1                         1   \n",
       "470704                                  1                         1   \n",
       "\n",
       "        host_verifications_phone  host_verifications_work_email  \\\n",
       "0                              1                              0   \n",
       "1                              1                              0   \n",
       "2                              1                              0   \n",
       "3                              1                              0   \n",
       "4                              1                              0   \n",
       "...                          ...                            ...   \n",
       "470700                         1                              0   \n",
       "470701                         1                              0   \n",
       "470702                         1                              0   \n",
       "470703                         1                              0   \n",
       "470704                         1                              0   \n",
       "\n",
       "        room_type_Entire home/apt  room_type_Hotel room  \\\n",
       "0                               1                     0   \n",
       "1                               1                     0   \n",
       "2                               1                     0   \n",
       "3                               1                     0   \n",
       "4                               1                     0   \n",
       "...                           ...                   ...   \n",
       "470700                          0                     0   \n",
       "470701                          0                     0   \n",
       "470702                          0                     0   \n",
       "470703                          0                     0   \n",
       "470704                          0                     0   \n",
       "\n",
       "        room_type_Private room  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                            0   \n",
       "3                            0   \n",
       "4                            0   \n",
       "...                        ...   \n",
       "470700                       1   \n",
       "470701                       1   \n",
       "470702                       1   \n",
       "470703                       1   \n",
       "470704                       1   \n",
       "\n",
       "                                                 comments  \n",
       "0       My wife and I stayed at this beautiful apartme...  \n",
       "1       Charlotte couldn't have been a more thoughtful...  \n",
       "2       I went to Edinburgh for the second time on Apr...  \n",
       "3       This flat was incredible. As other guests have...  \n",
       "4       Fantastic host and the apartment was perfect. ...  \n",
       "...                                                   ...  \n",
       "470700  I had an amazing stay at Luka's Airbnb! The pl...  \n",
       "470701  The place felt like home. Amazing facilities a...  \n",
       "470702                                           Loved it  \n",
       "470703  I must admit my own faults: 1) booked same nig...  \n",
       "470704  Nice place and very clean n tidy all room, Kit...  \n",
       "\n",
       "[470705 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_by_listing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd4865",
   "metadata": {},
   "source": [
    "# Customized Text Tokenizer <a id='a2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5d316",
   "metadata": {},
   "source": [
    "Our ultimate goal is to use machine learning models to accurately predict guests' sentiment scores, determining whether they will give a rating of over 4.8 or not. To enable the models to comprehend the review texts, we must first separate the documents into individual tokens. This task requires defining various tokenizing requirements to remove irrelevant text components from the data. Therefore, our customized text tokenizer should be able to:\n",
    "- Lowercase text\n",
    "- Remove punctuations\n",
    "- Remove Whitespaces\n",
    "- Remove HTML white spaces of format <br/>\n",
    "- Remove emails\n",
    "- Remove emojis\n",
    "- Remove English Stop words\n",
    "- Remove special characters\n",
    "- Remove numbers\n",
    "- Remove weblinks\n",
    "- Expand contractions\n",
    "- Remove Non-English Text Characters (Mixed with English review that was not detected and filtered in the pre-processing stage)\n",
    "- Perfome Texts Lemmatization (each word is mapped to a fixed, meaningful common root form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d7baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_tokenizer(sentence):\n",
    "    \n",
    "    # Remove HTML tags and entities\n",
    "    sentence = html.unescape(sentence)\n",
    "    sentence = re.sub(r'<[^>]+>', '', sentence)\n",
    "    \n",
    "    # Remove HTML white spaces \\r<br/> and <br/>\n",
    "    sentence = re.sub(r'(\\r<br/>)|(<br/>)', ' ', sentence)\n",
    "    \n",
    "    # Remove punctuations\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    \n",
    "    # Lowercase text\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # Remove emails\n",
    "    sentence = re.sub(r'\\S*@\\S*\\s?', '', sentence)\n",
    "    \n",
    "    # Remove emojis\n",
    "    sentence = sentence.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove special characters\n",
    "    sentence = re.sub(r'[^A-Za-z\\s]', '', sentence)\n",
    "    \n",
    "    # Remove numbers\n",
    "    sentence = re.sub(r'[0-9]+', '', sentence)\n",
    "    \n",
    "    # Remove weblinks\n",
    "    sentence = re.sub(r'http\\S+', '', sentence)\n",
    "    \n",
    "    # Expand contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Remove non-English text characters\n",
    "    if langid.classify(sentence)[0] != 'en':\n",
    "        sentence = ''\n",
    "    \n",
    "    # Remove English stopwords\n",
    "    eng_stop_words=stopwords.words('english')\n",
    "    eng_stop_words.extend(['apartment','flat','edinburgh','could', 'would', 'x']) # Append EDA insights driven stop words\n",
    "    stop_words = set(eng_stop_words)\n",
    "    tokens = sentence.split()\n",
    "    sentence = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "    \n",
    "    # Perform text stemming\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = ' '.join([lemmatizer.lemmatize(word, pos = 'v') for word in sentence.split()])\n",
    "    \n",
    "    # Tokenize cleaned sentence\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aec368",
   "metadata": {},
   "source": [
    "#### Save function as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b789d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/customized_tokenizer.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(customized_tokenizer, 'data/customized_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a4f60",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0b859",
   "metadata": {},
   "source": [
    "#### Check the uncollapsed review data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a881930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains all reviews listed individually is of dimension (470705, 46)\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset contains all reviews listed individually is of dimension {df_reviews_by_listing.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9cb17f",
   "metadata": {},
   "source": [
    "# Modelling Set up <a id='a3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a4d59",
   "metadata": {},
   "source": [
    "## Split the variables <a id='a3.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669293d",
   "metadata": {},
   "source": [
    "We need to split the variables into dependent and independent variables before we start fitting the model. The target variable will be the sentiment scores. We will focus on the overall sentiment score and attempt to further analyse the reviews with the other sub-rating transformed sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c43258f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y for the future model\n",
    "X = df_reviews_by_listing.drop(['listing_id',\n",
    "                               'Overall_sentiment',\n",
    "                               'accuracy_sentiment',\n",
    "                               'cleanliness_sentiment',\n",
    "                               'checkin_sentiment',\n",
    "                               'communication_sentiment',\n",
    "                               'location_sentiment',\n",
    "                               'value_sentiment'], axis=1)\n",
    "y = df_reviews_by_listing['Overall_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36fc6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (470705, 38)\n",
      "y Shape: (470705,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X Shape: {X.shape}\")\n",
    "print(f\"y Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ce381f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>55.95759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-3.18805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom_num</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_availability</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_bath</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_year</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_year</th>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_month</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_year</th>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_month</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_from_Edinburgh</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_a few days or more</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_email</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_phone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_verifications_work_email</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <td>My wife and I stayed at this beautiful apartme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              0\n",
       "host_response_rate                                                                        100.0\n",
       "host_acceptance_rate                                                                       92.0\n",
       "host_is_superhost                                                                             0\n",
       "latitude                                                                               55.95759\n",
       "longitude                                                                              -3.18805\n",
       "accommodates                                                                                  2\n",
       "bathroom_num                                                                                1.0\n",
       "beds                                                                                        1.0\n",
       "minimum_nights                                                                                3\n",
       "maximum_nights                                                                               30\n",
       "has_availability                                                                              0\n",
       "number_of_reviews                                                                           532\n",
       "number_of_reviews_ltm                                                                        82\n",
       "instant_bookable                                                                              1\n",
       "calculated_host_listings_count                                                                1\n",
       "calculated_host_listings_count_entire_homes                                                   1\n",
       "calculated_host_listings_count_private_rooms                                                  0\n",
       "calculated_host_listings_count_shared_rooms                                                   0\n",
       "reviews_per_month                                                                          3.38\n",
       "private_bath                                                                                  1\n",
       "host_since_year                                                                            2009\n",
       "host_since_month                                                                             12\n",
       "first_review_year                                                                          2011\n",
       "first_review_month                                                                            1\n",
       "last_review_year                                                                           2023\n",
       "last_review_month                                                                            12\n",
       "host_from_Edinburgh                                                                           1\n",
       "host_response_time_a few days or more                                                         0\n",
       "host_response_time_within a day                                                               0\n",
       "host_response_time_within a few hours                                                         1\n",
       "host_response_time_within an hour                                                             0\n",
       "host_verifications_email                                                                      1\n",
       "host_verifications_phone                                                                      1\n",
       "host_verifications_work_email                                                                 0\n",
       "room_type_Entire home/apt                                                                     1\n",
       "room_type_Hotel room                                                                          0\n",
       "room_type_Private room                                                                        0\n",
       "comments                                      My wife and I stayed at this beautiful apartme..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74f58e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b4732",
   "metadata": {},
   "source": [
    "The dependent variable stored as **X** contains all cleaned listing related numerical data as well as a column that contains the guest review data.\n",
    "\n",
    "The independent variable stored as **y** contains the **Overall sentiment score** that was transformed from the listing's average overall rating score:\n",
    "- 1 was denoted by Overall rating score > 4.8\n",
    "- 0 was denoted by Overall rating score < 4.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17428dc3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c2127",
   "metadata": {},
   "source": [
    "## Target Variable Distribution <a id='a3.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcfd84",
   "metadata": {},
   "source": [
    "In the EDA notebook, we analyzed the distribution of overall sentiments in the listing data and showed that the scores are balanced (**1: 58%, 0: 42%**). Now that we've merged all reviews with their corresponding listings and attached sentiment scores, it's important to recheck the distribution to ensure that the sentiment scores remain balanced after the data merging process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f062eb07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABpB0lEQVR4nO3de3zP9f//8ft7syPbnDfDDs5yShQ5bc50QKiPY1t0kErS50M+OqzypShRopBTkUpIOYTYKClEVCg1LKzJYZvTZvb6/eH3fn32toPtvffLNt2ul8v7wl7P1+Hxeu299/t9fz9fr+fLZhiGIQAAAAAA4HJuRV0AAAAAAAA3KkI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjeAG9ahQ4dks9lks9l06NChfLeB41PcxMbGmr+P4speX2xsrMP0kvJciomJkc1mU2RkZFGX4pSVK1eqQ4cOKleunNzc3GSz2TRy5MiiLsvlIiMjZbPZFBMTU6C2G1VJeG0AQOgGSrSLFy/q3Xff1d13362QkBD5+PgoICBA9evX18MPP6xNmzYVdYk3tMOHD2vs2LG69dZbVa5cOXl4eCgwMFCNGzdWnz59NHXqVP34449FXWY2MTExiomJKdYBqCjFxsYqJiZG8+fPL9R67CEu68PNzU3+/v6qVq2aWrVqpccee0xLly5Venq6a4rPp0OHDpnPgxvd7t27FRMTo6lTpxZ1KZb59NNP1bNnT23atEkpKSmqWLGiAgMD5e/vX9Sl5Wn16tXm30ZISIgyMzOLrJbo6Ohsf682m00+Pj4KCQlRz5499fHHH8swjCKrEUDJVaqoCwDgnPXr12vIkCH6888/zWn+/v5KS0vT/v37tX//fs2ePVvdu3fX+++/rwoVKhRhtTeeRYsW6eGHH9b58+fNaf7+/jp//rz27t2rvXv3atmyZQoNDS124fbFF1+UdKVXKCwsLMd5PDw8VLduXfP//ySxsbF68cUXFRERoejoaJesMzAw0Pz/hQsXdOzYMR09elTffvutZsyYoQoVKujll1/WsGHDcuyx8vX1NX8frnDo0CHzeeCq4G2vz9fX1yXrc5Xdu3frxRdfVGhoaJ49vxUrVlTdunUVEhJy/YpzkcmTJ0uS+vTpo4ULFxa730Fu5s6da/4/ISFB69evV9euXYuwIsnNzU2VKlUyfz5z5owSEhKUkJCglStXasGCBVq2bJm8vLyKsMr/cfVrAwBr0NMNlEAff/yx7rjjDv3555+qWrWq5syZo1OnTik5OVkXL17Uvn37NHLkSJUqVUpr1qxRy5YtlZSUVNRl3zC2b9+u+++/X+fPn1fjxo21dOlSnT17VsnJyUpNTVVSUpJWrFih6OholS5duqjLdUrVqlXNL2+qVq1a1OWUeImJieYjOTlZly5d0p49e/T6668rPDxcJ0+e1PDhwzVo0KAce9Juu+028/dRXNnru+2224q6FKc8/vjj2r9/vxYuXFjUpRTY3r17JV3prS0pgfvEiRNauXKl3N3d9eijj0qS3nvvvSKuSqpevbrD3+uFCxe0b98+9ezZU9KV3vnx48cXcZX/UxJeGwAQuoESZ//+/RoyZIgyMjLUqFEj7dq1S0OHDlW5cuXMeerVq6c33nhDn332mTw9PXXw4EENGDCgCKu+sUydOlWZmZmqXLmyNm/erD59+jiE60qVKqlnz56aN2+eduzYUYSVorhyd3dXo0aNNGrUKP3000/q16+fJGnx4sV65ZVXirg6lDT2M27KlClTxJXk3/vvv69Lly6pc+fOGj16tGw2mz777DOdPHmyqEtzYLPZVK9ePX388ceqV6+eJMceegDID0I3UMKMGzdO586dk5eXlz755BOH0+Cudscdd+jZZ5+VJH311VdatWqV2TZlyhTZbDYFBgYqIyMj13UYhqHQ0FDZbLYcv92/fPmy5s+fr65duyowMFCenp6qVKmSunbtqiVLluR6/VtYWJhsNpvmz5+vs2fP6vnnn1ejRo3k5+fnMODSpUuXtH79eo0YMULNmzdXlSpV5OnpqcqVK6tr16768MMPr/s1drt375Z05fTsgICAPOf18fHJtc0Vxy49PV2TJ09WkyZNVLp0aQUEBKhDhw5au3ZttuXs1yzatW/f3uHaxaynmuc1+NXVA/fs2bNH/fv3V3BwsHx8fFS/fn299tprDs+rb775Rr169VKVKlXk7e2thg0b6u23377m7+7333/XE088ofr166tMmTLy9fVV/fr1NXLkSB05ciTHZebPn++wPzt37tR9992nKlWqyMvLSzVq1NCoUaN0+vRph+Xs+2w/7TouLi7b9Z2Fvc47J76+vlqwYIGaNm0qSXrllVd06tQph3muNVjS/v379fDDD6tOnTry9fWVj4+PqlevrpYtW+q///2vQy9YWFiY2rdvb/589T5mPaX+6sHFPv30U3Xp0kWVK1eWm5ubw6npuQ2kdrXffvtN0dHRqlatmry8vBQSEqJhw4bp6NGjOc5/9e8zJ7k9X202mx544AFJV8ZguHpfs9afn4HUdu3apfvvv1+hoaHy9vZWuXLl1KpVK02dOlVpaWn5qj+/z8drybrPdlf/TVtR/6ZNm8y/ZXd3d6cvwbAH16ioKIWFhaldu3ZKT0/XBx984NT6rObp6akOHTpIko4dO5br7ys5OVn/93//pxYtWqhcuXLy8vJS9erV1b9/f23bti3b/IV9L87PQGoFfa+5fPmyypYtK5vNpi+++CLb+j788ENzm//+97+ztR8/ftxs/+OPPxzaCvJaBdxQDAAlxrFjxww3NzdDkhEdHZ2vZVJTUw0/Pz9DktG9e3dzemJiouHu7m5IMr744otcl4+NjTUkGTabzYiPj3doS0xMNFq0aGFIMh8BAQEOP/fo0cNIS0vLtt7Q0FBDkvHaa68ZderUMSQZnp6eRtmyZQ1J5rY2bdrksD4vLy+jTJkyDtPuvfde4/Lly9m2ER8fb85zde15tV3LTTfdZEgyWrVqVaDlsnLFsXvrrbfMdXh4eDgcF5vNZrz33nsOy40YMcIIDAw05ylXrpwRGBhoPpo3b27Om9fxyfo7Wb16teHt7W3Wb7PZzLZ+/foZhmEYs2fPNtzd3Q2bzZZtH8eMGZPrMZo1a5bh4eHh8Lv38fExf/b39zfWrVuXbbl58+YZkozQ0FBj0aJF5joCAgLMvx9JRoMGDYzU1FRzuSNHjhiBgYFG6dKlzWOa9fgEBgYaS5Ysydfv1zAM44UXXjC3lR+ffPKJOf/Vv7usx/xq69atM7y8vMx2Dw8P8+/I/njhhRfM+Zs3b26UK1fObLt6H0eMGJFtHyIiIoxRo0aZz61y5coZ7u7uDuu1r2/Tpk0O9WV9Li1ZssR8PSpTpozD77N8+fLGzp07s+1f1t9nbnJ7vgYGBhr+/v6GJMPNzS3bvk6ePDnHfc3JG2+84fD8DggIcHh+Nm7c2Dh27Fie9Rfk+Xgt9udrXn/Trq5/2rRp5jrsy0dFReW7Zrtvv/3W/Bs+f/68YRiGMXfuXEOS0ahRozyXjYiIyPaczk/btURFRV3zefboo4+ax+vEiRPZ2rdt2+bw+3B3dzef7/a/nQkTJjgsU9j34rxeG+zrd+a95u677zYkGU899VS2dT744IPmsk2bNs3W/sEHHxiSjJCQEIfpBX2tAm4khG6gBFm8eLH5xvT555/ne7k+ffqYH3IvXbpkTu/evbshyfjXv/6V67JDhw41JBnt2rVzmJ6WlmbceuuthiTjlltuMVatWmWcO3fOMAzDOHv2rLFgwQKjcuXKhiRj5MiR2dZrD45lypQxgoKCjGXLlhnp6emGYRhGQkKCua5t27YZAwYMMFatWmUkJiYamZmZhmEYxsmTJ41p06aZH6inTZuWbRtWhe7o6Ghz2ddeey3HYJwXVx27cuXKGVWrVjVWrFhhHrv9+/cbLVu2NI/tmTNnsi2fWzjKKr+hu2zZssa//vUv4/Dhw4ZhGEZKSooxduxYs33ixImGh4eH8cQTTxh//fWXYRiGcerUKfMYurm5GQcOHMi2/eXLl5sfyp555hnj0KFDRmZmppGZmWns37/fuPfee80P7fZt29lDgq+vr+Hl5WU8+OCDxpEjRwzDMIxz584Z06dPN8PGc889l23b1wpf+VXQ0J2ammp++L7//vsd2vL6YF2rVi1DktGlSxdj79695vQLFy4Ye/fuNWJiYoy5c+fme3057YP9C53Ro0cbSUlJhmEYxsWLF41Dhw6Z8+YndAcEBBiNGzc2vvvuO8MwDCMzM9P48ssvjZCQEPNDekpKisPyhQnd+V0+677m9Hv//PPPzfX37NnT+OOPPwzDuPK3vHDhQjNYtWrVysjIyMhx+84+H/PjWn/Trqjf29vbcHd3N6Kjo836MzIyjIMHDxa4XntoGzp0qDktJSXF8PX1NSQZ27dvz3XZogrdaWlpRr169czXnavFx8ebAbJv377Gzp07zffbv/76y3juueeMUqVKGZKM5cuXOyxbmPfivP6WC/NeM2XKFEOS0aRJk2zrrVmzpnkc3NzcjJMnT+ZY69VfyDjzWgXcKAjdQAkybtw48831zz//zPdyL7/8srlc1g9IH374oflhKqdwduHCBfMb8Tlz5ji0TZ8+3eydufpDst2OHTsMm81meHp6moHLzh4c3d3djR9++CHf+3I1e+9gzZo1s7VZFbr379/v0HtRrlw5o1evXsb48eONNWvWGKdPn85zeVcdOy8vL2Pfvn3Zlk1KSjJ7nz/44INs7a4M3Z07dza/CMmqbdu25jwPPvhgtvaMjAwjLCzMkGS8/PLLDm1paWlG1apVDSl7j29WPXr0MCQZTz75pMN0e0jI6UOfnb3XtlatWtnaiip0G4Zh1K5d25BktG7d2mF6bh+s//rrL3N6Tr2UuSlo6JZkjBo1Ks958xO6K1SokO35bBiG8csvvxienp6GJGPSpEkObcUhdNvPbmnTpk22UGoYhrFy5Upz+5988kmO23f2+Zgf1/qbdlX9vXv3dqq+rM6ePWu+fm7evNmhbeDAgYYkY9iwYbkuf71Dt/2Lvl69epnHIevZIHZ9+/Y1JBmDBw/OdRu5BdnCvBfn9bdcmPea3bt3G9KVnvW///7bnH7kyBHzPXfAgAGGJOPTTz91WGd4eLghyZg/f745zdnXKuBGwTXdQAmSdYCZgtwCrGLFijmuo2fPnvL399fFixe1dOnSbMutXLlSycnJ8vb2Vt++fR3a5syZI0kaPny4/Pz8ctxus2bN1KBBA6Wnp+d6z/Bu3bqZ17I6484775R05drf48ePO72egqhbt67i4uJ06623SpJOnz6tFStW6Nlnn1X37t1VoUIFRUZGasWKFTku76pj17dvX3Ngn6wqVaqk22+/XdKV662tNGbMmByvJcx625+xY8dma3d3d1enTp0kZa9xzZo1Onr0qAIDA83rcXNy//33S5K+/PLLXOexj2lwNftIxAcPHnS47VtRK1++vCRlu6Y7N35+fnJzu/JWbuXz383NTWPGjCn0eoYNG6bKlStnm16/fn3zNWbJkiWF3o4r7dmzR7/88osk6bnnnpO7u3u2ee6++25z1PYPP/ww13UVxfPRlfXn9LdcUB9//LFSU1MVHh6uNm3aOLRFRUWZNVy4cKHQ23JGQkKCgoKCzIePj4/q1atnvp63bt1aL7/8ssMyp06d0rJlyyRJzzzzTK7rtr9m/fjjj/rrr7/M6YV5L85LYd5rGjdurAoVKsgwDIfpGzdulCR16NDBvMbdPk26MnZCfHy8JDmMHXG9XquA4orQDfwDGLkMVuXj42O+gb///vvZ2u3Tevbs6TBgWGpqqhmUnnvuOYcPKFc/Dhw4IOnKG3FOWrdufc36U1NTNXnyZEVERKhy5cry9PQ0B2nJenuc3AZiskLTpk31/fffa/v27XrxxRfVrVs3BQUFSZIyMzMVFxene+65Rw888IDD8XflsWvRokWu9QUHB0vKf3hzVm63h7Lfl7p8+fKqUaNGnvNcPSDR119/bU6vUqVKrsfnoYcekpT78Slfvrxq1aqVY5v9+OS0/aKU299qbnx8fNSxY0dJV77Aev755/Xdd98pPT3dpXXVqlUrx7BcUPYP6Xm17dmzR5cuXSr0tlzFfgeCUqVKKSIiItf5Onfu7DD/1Yrq+eiq+n18fHTLLbcUuh77bcEGDx6c7Qu7jh07qlq1akpOTtann35a6G05IzMzU3/99Zf5yDrA3H//+1/FxcXJ39/fYZlvv/1WmZmZkq48j3N7zWrQoIG5TNbXLWffi/NS2PearIMKZg3VWUO3PVTn1F6jRg2He95fr9cqoLgidAMlSNbe7YLcViWvHnL7N++bN292eMM9ceKEOQK2fR67xMRE8wPGqVOnHD6gXP2wf3jOrffmWh/kf/31V910000aPXq0Nm/erBMnTsjDw0OVKlVSYGCgGdwk6dy5c3muywrNmzfX888/rzVr1uj48eOKj4/Xa6+9Zp5dMH/+fL399tvm/K48drn1XEhXPmBLsjy85FaDffvO1Hjs2DFJUnp6ep7Hxx5OcusRy8+2c9p+UbLvU0HOZJkzZ46aNGmiEydO6OWXX1bLli3l5+enNm3aaPLkyS754sUVgVtSnvd8t7dlZGRY/mVRQSQlJUm6csaQl5dXrvNVq1bNYf6rFdXz0VX1V6hQweypdNaBAwf0zTffSMr+viJdOaNi0KBBkorunt2hoaEyrlx+qYyMDB0+fFgTJ06Ul5eXJk2apE8++STbMvbXLEl5vmZl7d2++nXdmffivLjivSanUG3v9W7fvr1q1KihsLAw7du3T4mJidnar3Y9XquA4orQDZQgN910k/n/H374Id/L7dq1S9KVe7iGhoY6tLVr1878kJH1Vi1LlixRRkaGAgMD1aVLF4dlLl++bP5/27Zt5geUvB5Zb82TVU6nOmb1wAMP6M8//1RYWJg++eQTnTx5UufOnVNSUpISExMdercL2ktohbCwMD399NOKi4szbxdmP8VPcu2xu1HZj1G3bt3ydXyKw+/dFc6ePWveXqdmzZr5Xi4kJEQ//PCD1q5dqxEjRqhZs2bKzMzUN998o9GjR6tWrVoOH5qdca2/0/zK67ZGxV1+ay+u+1jY+l3xHMh6f+tatWplu4WbzWYz71MfFxen33//vdDbLAx3d3eFhITomWee0bvvvquMjAwNGTJE+/btc5jP/prl4+OT79esq29N58x7cV5c8V5jD84HDhzQsWPHdPDgQSUkJKhBgwbmF95XB3N76M7prJbr8VoFFFeEbqAEad++vdnTkN9T786ePav169dLktq2bevQoyJd+YBl71nIelqb/f/9+/fPtkzW3uW9e/cWcC/yLyEhQVu3bpV05Rq/vn37mte82tm/XS9ubrrpJvN6Rfupe9L1O3Ylmf00/X/a8Vm7dq35QTmve0XnxM3NTV27dtW0adO0Y8cOnTp1SosWLVJISIhOnz6tAQMGFIvTOP/8889c2+xfoJUqVcrh79z++nPx4sVcl01OTnZRhdnZe/lPnDiR672spf/tW6VKlSyrxRnFpf6MjAwtXLgw3/MbhqF58+ZZUoszoqKi1K5dO124cEEjR450aLO/Zl24cEEHDx50av3OvBfnxRXvNTfddJO5bxs3bnQ4tdwua+j+9ddfzedRbq9hJeW1CnA1QjdQglSpUsUccGfJkiUOYS43b7zxhlJTUyVdGUwlJ/ZT1g4cOKDt27eb/2Zty6pcuXJmr7uVgx4lJCSY/89tsLUNGzZYtv3CKlOmjCQ5nNJ5vY5dXuw9WcW1h9h+nf/Ro0fN67uvJ/sXW9fz+KSnp2vChAmSpICAAPXq1atQ6/Pz89OAAQPMU3T/+usvhw/eWU8Tvp77mduggFnbGjduLA8PD3N6uXLlJF057Tm30Pjdd9/lut7C/j6bN28u6UpojIuLy3U++2uRfYDF4qK41L9q1SolJibKw8NDf/75p1JTU3N9vP7665KuXJ6Ttce2qL344ouSpHXr1jn0yLZq1cp8XS3M63pB34vz4qr3mqzXdefUi511MDV7e926dR3GKcjLtV6rgBsFoRsoYV5++WX5+PgoLS1N9957r/7+++9c512zZo3Gjx8v6cq30faRvq9Wp04dc1CuhQsXmt+sN2zYMNew+/DDD0uSvvrqq2u+oTt7nVbWAWN+/PHHbO2pqanm/l1PGzduvOZ1l0ePHjU/xF49+ND1OHZ5sQ8CdObMGZev2xXuvvtuValSRZL05JNPXnM0Z1cfo+t9fC5cuKDo6GjzMpCxY8eqbNmy+Vr2Wj1C9kscJMfTg7MOBHU9nwfvvPNOjq9ZBw4cMEdt/te//uXQ1qRJE0lXQvPy5cuzLXvhwgW98cYbuW6zsL/Pxo0bm+Fl/PjxOYbA1atXm8G/f//+Tm3HKsWlfnuo6tixo6pWraoyZcrk+ujXr5/c3Nx09OjRPO9OcL1FRkaqVatWkq4MTmZXuXJl8wvxyZMn69dff81zPbm9ZjnzXpwXV7zXZA3VsbGxcnNzcxiQr2rVqqpdu7bi4+PNMxNyup7b2dcq4EZB6AZKmAYNGmjOnDlyd3fX3r171bRpU82dO9fhA+Wvv/6qUaNGqUePHkpPT1eNGjW0ePHiPK/pGzx4sKQr34jbryezT8vJsGHDzA8HgwcP1rPPPuvQM33+/HnFxsbq8ccfL9D1qVnddNNN5uinQ4YM0c6dO822b7/9VpGRkUUy8vTo0aNVo0YNPfPMM/r6668dBvI6deqU5syZozZt2phnGDz99NMOy1+PY5eXhg0bSpIWLVpUrG6XZeft7a0ZM2bIZrPphx9+UOvWrfXll186fGiLj4/Xu+++q9tuu00zZsxw6fbtx+fnn382L29wtczMTP3000+aMmWKGjRoYN6mafDgwRo9enS+17N161Y1btxYb7zxhvbt22cOnGQYhrZu3apHH31U0pVBsho1amQuV6dOHXl6ekq6MubA9ertvnTpkjp37mz23hmGoQ0bNqhr165KS0tT9erVNWzYMIdlqlWrZl6qMWrUKG3YsMEMjjt37lSnTp1yHfxL+t/vMyUlRR9//LFTdb/66quSpC1btqhv377mLZEuXbqkRYsWmUG1VatWhT5LwQpFXf/x48e1Zs0aSdJ99913zfmDg4PNM16yXgdeHPz3v/+VdOVvzz7AmSS9/vrrqlChglJSUtSmTRvNnTvX4bKHv//+W8uWLVPv3r3z/GKjoO/FeXHFe409QB8+fFiJiYlq2rSpefaJnT2Y27+4ySl0O/taBdwwCnujbwBFY82aNUZwcLAhyXwEBAQY3t7eDtO6dOliJCUlXXN9f//9t+Hp6Wku5+bmZvz55595LnPixAmjQ4cODtvz9/c3ypYta9hsNnNaqVKlsi0bGhpqSDLmzZuX5zY+//xzo1SpUua6fH19DV9fX/P/GzZsMNs2bdrksGx8fLzZFh8fn++2a2nZsqXDPttsNiMgIMCsy/7w9PQ0pk2bluM6rD52UVFRhiQjKioqW9v7779vrt/Dw8OoWrWqERoaarRu3Tpfx2fTpk1mW27mzZtnSDJCQ0NzneeFF14wJBkRERE5tn/wwQcOx7RUqVJGhQoVDC8vL4fjNn78+AJvO6/9u3TpklG3bl2zvVy5ckZoaKgRGhpqfPLJJ7muM7f9k2QEBgaaj7Jlyxpubm4O+1CxYkXjnXfeyXVduR3zrNPtv88KFSo4/M34+/sbmzdvzrbOoUOHOvxdhYSEGKGhocbTTz+dbR9y+x1llZ+/wyVLlhh+fn6GJKNMmTIOv9+yZcsa27dvz3Hdu3btMpeTZHh7exulS5c2j+2qVavy/Hvu2LGj2e7n52f+Pt9444187+uUKVMc/jbLli3r8JrZqFEj4+jRo9mWK+zzMT9yO/bXq/5rmThxovn8PHXqVL6WefPNN81lsr6HRUREGJKMF154IdsyebVdi/01Mz/7efPNNxuSjFtvvdVh+g8//GCEhYU5vDeUK1fOKFOmjMPfaadOnXJdd0Hfi6/1elyY9xq76tWrm/P95z//yda+ZMkSh/X/9ddfedZZ0Ncq4EZATzdQQnXr1k0HDx7UjBkz1L17d1WtWlUXL16Uh4eH6tSpo6FDh2rDhg368ssv8zUwToUKFXTHHXeYP9tPAcxLxYoVtWHDBn322Wfq27evqlevrrS0NF24cEFVq1ZV9+7dNX36dB06dMjp/bzrrru0efNm3XnnnSpbtqwyMjJUsWJFPfDAA/rhhx/M+35eT5s2bdIXX3yhUaNGqW3btgoMDNSFCxd06dIlVaxYUa1atdK4ceO0b98+jRgxIsd1XI9jl5tBgwbp/fffV5s2beTr66vjx4/r8OHDeQ5yVRQGDhyogwcP6tlnn1Xz5s1VpkwZnTlzRt7e3rr55pv1+OOPa8OGDRozZoxLt1uqVCl99dVXevDBBxUWFqZz587p8OHDOnz4sM6ePevUOu235klKSlJGRoaCgoLUsmVLPfroo1q6dKmOHj2qRx55pMDrvfXWW/Xxxx/r0UcfVbNmzVSxYkUlJyebx2j06NHat2+f2rZtm23Zt99+WzExMWZP8JEjR3T48OE8L1kprBYtWmjHjh26//77FRAQoIyMDFWtWlUPPfSQ9u7da15/fLWbb75Z33//vfr166fKlSsrMzNTFStW1GOPPabdu3c73NkhJ0uXLtVTTz2lOnXq6NKlS+bvsyCnnD/11FPasWOHBg0apOrVq+v8+fPy8fFRy5YtNWXKFH3//ff5vo61KBRl/fbe6k6dOmXrJc1N37595ebmpkuXLuV47+qiZO/t3r59u1auXGlOb9q0qX755RdNnz5dnTp1UsWKFZWamqrMzEzVrl1bAwYM0JIlS7Rs2bJc1+3Me3FeXPFek7XnOqdRydu3b2+eSdegQYMcbzFYmNcq4EZgM4xiOpIOAAAAAAAlHD3dAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARUoVdQFFJTMzU8eOHZOfn595b0EAAAAAAPLDMAylpqYqODhYbm6592f/Y0P3sWPHVL169aIuAwAAAABQgiUkJKhatWq5tv9jQ7efn5+kKwfI39+/iKsBAAAAAJQkKSkpql69upktc/OPDd32U8r9/f0J3QAAAAAAp1zrcmUGUgMAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAwEWWL1+uzp07q0KFCvLx8VF4eLj69++vhIQESdKlS5f06aefKjo6WvXr11fp0qXl5+enFi1aaMaMGbp8+XKBthcWFiabzZbjY9iwYbkuFx8fr4ceekihoaHy8vJSYGCg2rdvr08++aRQ+w8gu3/sQGoAAACAqxiGoWHDhmnWrFmqWbOm+vXrJz8/Px07dkxxcXE6fPiwqlevrt9//119+/aVn5+fOnTooB49eig5OVmff/65HnvsMa1du1afffbZNQdmyiogIEAjR47MNr158+Y5zr9+/Xr16tVLknT33XerRo0aOn36tPbs2aMNGzbo3nvvdeYQAMiFzTAMo6iLKAopKSkKCAhQcnIyo5cDAACgUN588009+eSTeuyxxzRt2jS5u7s7tGdkZKhUqVI6evSoVq5cqaioKPn6+prt586dU2RkpHbs2KGPP/4438E3LCxMknTo0KF8zZ+QkKCGDRsqMDBQGzZsUEhISI51Ari2/GZKTi8HAAAACuHChQt68cUXVaNGDU2dOjVb4JZkBtmqVavq0UcfdQjcklS6dGmNGjVKkhQXF2dZrRMmTFBKSoreeeedbIE7a50AXIe/KgAAAKAQ1q9fr1OnTik6OlqXL1/WypUr9euvv6ps2bLq1KmTatWqla/1eHh4SCp48E1LS9OCBQt09OhRlStXTq1atVKTJk2yzWcYhj7++GNVqFBBHTp00M6dOxUXF6fMzEzdfPPN6tChg9zc6JMDXI3QDQAAABTCjh07JF0Jy02aNNGBAwfMNjc3Nz311FN67bXXrrmeuXPnSpK6dOlSoO0nJiYqOjraYVq3bt30/vvvq2LFiua0+Ph4nTp1SrfeeqseffRRvfPOOw7LNG3aVCtXrlS1atUKtH0AeeOrLAAAAKAQkpKSJEmvv/66/P399f333ys1NVWbN29WnTp19Prrr2vmzJl5rmPWrFlas2aNOnTooDvuuCPf2x4yZIhiY2N14sQJpaSkaNu2berevbvWrl2rHj16KOvwTfY6f/jhB33wwQeaN2+eTp06ZY5kvmvXLvXt29eJIwAgLwykxkBqAAAAKISHH35Ys2fPlo+Pjw4ePKjg4GCz7eeff1bjxo0VHh6ugwcP5rj8qlWrdM899yg4OFjffvutqlSpUqh6MjMzFRERoa+//lpffPGF7rzzTknS1q1b1bp1a0nSG2+8kW3E85YtW+q7777Tli1b1KZNm0LVAPwTMJAaAAAAcB0EBARIunKLrqyBW5IaNGigGjVq6Pfff9eZM2eyLfvll1+qT58+CgwM1MaNGwsduKUrp7Q/8MADkqRvvvkmW52S1KNHj2zL3X333ZL+d7o8ANcgdAMAAACFULduXUlS2bJlc2y3T79w4YLD9LVr16pXr16qWLGiNm3apBo1arisJvu13OfPnzen1apVyxxZPadac6sTQOEQugEAAIBCaN++vSRp37592douXbqkgwcPqnTp0qpUqZI53R64y5Urp02bNuV7hPP8+u677yT97z7ekuTl5aVWrVpJkn755Zdsy9inZV0GQOERugEAAIBCqFmzprp06aKDBw9qzpw5Dm2vvPKKzpw5o3vuuce8FdjVgbt27dp5rv/SpUvav3+/fv/9d4fpv/zyS46nrH/99deaMmWKvLy81Lt3b4e2Rx99VJIUExOjtLQ0c/r+/fs1f/58+fn5qVu3bvnedwDXxkBqDKQGAACAQvr999/VqlUrJSUl6c4771S9evW0a9cubdy4UaGhodq2bZuCgoK0f/9+3XzzzUpLS1O/fv3MU9OzCgsLc7gF2KFDhxQeHq7Q0FAdOnTInB4TE6NJkyapY8eOCgsLk5eXl3766SetW7dObm5ueuedd/Tggw86rNswDN13331aunSp6tatq65duyo5OVmffvqpzp8/r4ULF2rgwIFWHSbghpLfTEnoJnQDAADABRISEvT8889r7dq1OnnypIKCgtSjRw89//zzqly5siQpNjbWPB09NxEREYqNjTV/zi10x8XFacaMGfrhhx/0119/6eLFiwoMDFSbNm301FNP6bbbbstx/RkZGXrrrbf03nvv6eDBg/Ly8lLLli313//+VxEREYU+DsA/BaH7GgjdAAAAAABnccswAAAAAACKGKEbAAAAAACLELoBAAAAALBIqaIuAAAAABYbGF3UFQDIatH8oq4A1xE93QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARYpt6D569KgGDRqkChUqyNfXVzfffLN27txpthuGoZiYGAUHB8vHx0eRkZH6+eefi7BiAAAAAAAcFcvQffr0abVu3VoeHh5as2aNfvnlF73++usqW7asOc+kSZM0ZcoUTZ8+Xdu3b1dQUJA6d+6s1NTUoiscAAAAAIAsShV1ATl59dVXVb16dc2bN8+cFhYWZv7fMAxNnTpV48aNU+/evSVJCxYsUGBgoBYvXqxHHnnkepcMAAAAAEA2xbKne+XKlWrevLnuvfdeVa5cWU2bNtXs2bPN9vj4eCUmJqpLly7mNC8vL0VERGjr1q05rjMtLU0pKSkODwAAAAAArFQsQ/cff/yhmTNnqnbt2vryyy81bNgwjRgxQgsXLpQkJSYmSpICAwMdlgsMDDTbrjZx4kQFBASYj+rVq1u7EwAAAACAf7xiGbozMzN1yy23aMKECWratKkeeeQRPfTQQ5o5c6bDfDabzeFnwzCyTbMbO3askpOTzUdCQoJl9QMAAAAAIBXT0F2lShXddNNNDtPq16+vI0eOSJKCgoIkKVuvdlJSUrbebzsvLy/5+/s7PAAAAAAAsFKxDN2tW7fWgQMHHKb9+uuvCg0NlSSFh4crKChI69evN9vT09MVFxenVq1aXddaAQAAAADITbEcvfypp55Sq1atNGHCBN133336/vvvNWvWLM2aNUvSldPKR44cqQkTJqh27dqqXbu2JkyYIF9fXw0YMKCIqwcAAAAA4IpiGbpvvfVWLV++XGPHjtVLL72k8PBwTZ06VQMHDjTnGT16tC5cuKDhw4fr9OnTatGihdatWyc/P78irBwAAAAAgP+xGYZhFHURRSElJUUBAQFKTk7m+m4AAHBjGxhd1BUAyGrR/KKuAC6Q30xZLK/pBgAAAADgRkDoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAixTJ0x8TEyGazOTyCgoLMdsMwFBMTo+DgYPn4+CgyMlI///xzEVYMAAAAAEB2xTJ0S1KDBg10/Phx87F3716zbdKkSZoyZYqmT5+u7du3KygoSJ07d1ZqamoRVgwAAAAAgKNiG7pLlSqloKAg81GpUiVJV3q5p06dqnHjxql3795q2LChFixYoPPnz2vx4sVFXDUAAAAAAP9TbEP3b7/9puDgYIWHh6tfv376448/JEnx8fFKTExUly5dzHm9vLwUERGhrVu35rq+tLQ0paSkODwAAAAAALBSsQzdLVq00MKFC/Xll19q9uzZSkxMVKtWrXTy5EklJiZKkgIDAx2WCQwMNNtyMnHiRAUEBJiP6tWrW7oPAAAAAAAUy9DdvXt39enTR40aNVKnTp20atUqSdKCBQvMeWw2m8MyhmFkm5bV2LFjlZycbD4SEhKsKR4AAAAAgP+vWIbuq5UuXVqNGjXSb7/9Zo5ifnWvdlJSUrbe76y8vLzk7+/v8AAAAAAAwEolInSnpaVp3759qlKlisLDwxUUFKT169eb7enp6YqLi1OrVq2KsEoAAAAAAByVKuoCcvLvf/9bd999t0JCQpSUlKTx48crJSVFUVFRstlsGjlypCZMmKDatWurdu3amjBhgnx9fTVgwICiLh0AAAAAAFOxDN1//vmn+vfvr7///luVKlVSy5YttW3bNoWGhkqSRo8erQsXLmj48OE6ffq0WrRooXXr1snPz6+IKwcAAAAA4H9shmEYRV1EUUhJSVFAQICSk5O5vhsAANzYBkYXdQUAslo0v6grgAvkN1OWiGu6AQAAAAAoiQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARUoVZuFLly7pwIEDOnHihJKTkxUQEKBKlSqpbt268vDwcFWNAAAAAACUSAUO3SdOnND8+fO1atUqff/990pLS8s2j7e3t2677TbdeeedioqKUqVKlVxSLAAAAAAAJUm+Q/dvv/2m559/XsuXL1d6erokqWLFimrWrJnKly8vf39/JScn6/Tp09q/f7/i4uIUFxenZ599Vr1799ZLL72kWrVqWbYjAAAAAAAUN/kK3U888YRmzZqly5cvq3379howYIAiIyMVHh6e6zJ//PGHNm3apMWLF+vjjz/Wp59+qocfflhvvfWWy4oHAAAAAKA4sxmGYVxrJl9fXz388MMaPXq0goODC7yRo0ePatKkSZozZ47OnTvnVKGulpKSooCAACUnJ8vf37+oywEAALDOwOiirgBAVovmF3UFcIH8Zsp89XT/8ccfCgoKcrqYqlWratq0aRo7dqzT6wAAAAAAoKTJ1y3DChO4rVgPAAAAAAAlAffpBgAAAADAIi4L3Xv27FFUVJRuvfVW3XbbbRoyZIj27dvnqtUDAAAAAFDiuCR0f/LJJ2rWrJlWrFghNzc3nT9/XgsWLFCTJk20du1aV2wCAAAAAIASxyWhe/To0eratauOHj2q7777Tj/99JN27Nih0qVLM3gaAAAAAOAfK1+he/bs2bm2Xbx4UYcPH9awYcNUpkwZc3rTpk3VoUMHTjEHAAAAAPxj5St0Dxs2TC1atNCOHTuytXl7eysgIECxsbEO08+dO6ddu3YxYjkAAAAA4B8rX6H766+/VkZGhlq2bKmHH35YJ0+edGgfPny4pkyZok6dOumZZ57RiBEj1KBBAx06dEjDhw+3pHAAAAAAAIq7fIXu22+/XTt27NBbb72lZcuWqU6dOpo5c6YMw5AkjR8/Xq+99pr27dunSZMmafr06crMzNT06dM1evRoS3cAAAAAAIDiKt8DqdlsNj366KP69ddf1adPHz3xxBNq1qyZtm7dKpvNplGjRuno0aNKTk5WcnKyjhw54pJe7okTJ8pms2nkyJHmNMMwFBMTo+DgYPn4+CgyMlI///xzobcFAAAAAIArFXj08vLly2vWrFn67rvv5OnpqbZt2yo6OlonTpyQJPn5+cnPz88lxW3fvl2zZs1S48aNHaZPmjRJU6ZM0fTp07V9+3YFBQWpc+fOSk1Ndcl2AQAAAABwBadvGdasWTNt27ZNs2fP1po1a1SnTh1NmzZNmZmZLins7NmzGjhwoGbPnq1y5cqZ0w3D0NSpUzVu3Dj17t1bDRs21IIFC3T+/HktXrzYJdsGAAAAAMAVChS6//rrL23cuFFLly7V9u3blZ6eriFDhujXX3/VoEGD9O9//1s333yzNm/eXOjCHnvsMd15553q1KmTw/T4+HglJiaqS5cu5jQvLy9FRERo69atua4vLS1NKSkpDg8AAAAAAKyUr9Cdlpamxx57TCEhIercubPuu+8+tWzZUrVq1dLSpUsVEBCgt956Szt37lTZsmXVvn17DRw4UMeOHXOqqCVLluiHH37QxIkTs7UlJiZKkgIDAx2mBwYGmm05mThxogICAsxH9erVnaoNAAAAAID8ylfo/s9//qOZM2eqffv2WrRokdasWaM33nhDbm5u6tevn3n/7saNG2vz5s1asGCBYmNjVa9ePU2ePLlABSUkJOjJJ5/UBx98IG9v71zns9lsDj8bhpFtWlZjx441B3lLTk5WQkJCgeoCAAAAAKCg8hW6lyxZoltuuUVr165Vv3791LVrV40YMUKff/65MjMz9dFHHznMP2jQIB04cEAPP/ywnnvuuQIVtHPnTiUlJalZs2YqVaqUSpUqpbi4OL355psqVaqU2cN9da92UlJStt7vrLy8vOTv7+/wAJA/Z86c0YgRI3T77bcrKChIXl5eqlq1qjp06KBPP/3UvH2gnc1mu+bD2S++Jk2aZK5j27Zt15w/Pj5eZcqUkc1m07Bhw5zaJgAAAOCsUvmZ6dy5czkG2qCgIEnShQsXsrWVKVNGr732mh588MECFdSxY0ft3bvXYdoDDzygevXqacyYMapRo4aCgoK0fv16NW3aVJKUnp6uuLg4vfrqqwXaFoD8+fvvvzV37ly1bNlSvXr1Uvny5ZWUlKTPP/9cffv21UMPPaRZs2aZ87/wwgs5rufgwYNatGiR6tev79QlHvv27dPzzz+v0qVL69y5c9ec3zAMPfDAAwXeDgAAAOAq+Qrd7du319q1azV58mRFRUWpXLly+u233zRmzBjZbDZFRkbmumy9evUKVJCfn58aNmzoMK106dKqUKGCOX3kyJGaMGGCateurdq1a2vChAny9fXVgAEDCrQtAPkTHh6uM2fOqFQpx5eM1NRUtWzZUrNnz9aTTz6pBg0aSJJiYmJyXM8TTzwhSQX+Mk6SLl++rKioKDVp0kR16tTRBx98cM1l3nrrLX3zzTeaNGmSRo0aVeBtAgAAAIWVr9PL3377bdWpU0djxoxRlSpV5O3trUaNGmn16tV66KGH1LdvX6vrdDB69GiNHDlSw4cPV/PmzXX06FGtW7fOZfcHB+DI3d09W+CWrnxJ1rVrV0lXerHzcvHiRS1atEienp4aPHhwgWt49dVX9eOPP2ru3Llyd3e/5vwHDx7U2LFjNXr0aPOsGAAAAOB6y1dPd2hoqH766SctW7ZMu3fv1unTpxUSEqLu3burcePGVteo2NhYh59tNptiYmJy7U0DcH1cvHhRGzdulM1m00033ZTnvMuWLdPp06fVt29fVapUqUDb+emnn/Tiiy/q2WefNXvT85KZmakHHnhAoaGhev755/Xtt98WaHsAAACAq+QrdEuSm5ub+vbte917tQEUH2fOnNHUqVOVmZmppKQkrV69WgkJCXrhhRdUu3btPJd97733JBX81PKMjAxFR0erfv36euaZZ/K1zNSpU7V161Z9/fXX8vLyKtD2AAAAAFfKd+gGgDNnzujFF180f/bw8NDkyZP19NNP57lcfHy8Nm3apJCQEHXu3LlA25wwYYJ+/PFHfffdd/Lw8Ljm/L/++queffZZPfnkk7r99tsLtC0AAADA1fJ1Tff69etdsrF169a5ZD0AikZYWJgMw1BGRobi4+P10ksvady4cerTp48yMjJyXW7u3LnmSOJubvl62ZEk/fjjjxo/frz+/e9/65Zbbrnm/JmZmYqOjlZwcLDGjx+f7+0AAAAAVsnXp9+uXbuqTZs2+uKLL3T58uUCbSAjI0MrVqzQ7bffru7duztVJIDixd3dXWFhYXrmmWc0fvx4LV++XLNnz85x3szMTM2fP19ubm4aMmRIgbYTFRWlmjVr5nv8hjfffFPbtm3TnDlz5OvrW6BtAQAAAFbIV+ieN2+eEhIS1LNnTwUHB+uJJ57Q0qVLdfjw4Rzn/+OPP7RkyRI98sgjCgoKUp8+fXT8+HHNnz/flbUDKAa6dOkiKfuAh3Zr167Vn3/+qc6dOyskJKRA6/7xxx+1f/9+eXt7y2azmY8FCxZIkm6//XbZbDatWLFCkrR7924ZhqH27ds7zN++fXtJ0rvvviubzaZevXo5ta8AAABAQeXrmu6oqCj169dPM2bM0DvvvKO3335bM2bMkHTlms5y5crJz89PKSkpOn36tHmaqWEYqlOnjp5//nk98sgjDGgE3ICOHTsmSTneUkxyfgA1SRo6dGiO0zdv3qzffvtNPXr0UKVKlRQWFiZJioiIyLGO48ePa/Xq1apXr55at27NLcQAAABw3dgMwzAKutDmzZv1xRdfaMuWLdqzZ48uXLhgtvn4+KhJkyZq27at7rzzTrVr186lBbtKSkqKAgIClJycLH9//6IuByjWdu/erfDwcAUEBDhMP3XqlDp27Kjdu3fr/fff16BBgxzaT5w4oapVqyogIEBHjx6Vp6dnjuu/dOmSfv/9d3l4eKhmzZrXrCc6OloLFizQt99+q5YtW15z/tjYWLVv316PPPKI3nnnnWvODwA3nIHRRV0BgKwWzS/qCuAC+c2UTo1e3q5dO4cwfe7cOSUnJysgIEClS5d2ZpUAirH58+drzpw5at++vUJDQ1W6dGkdPnxYq1at0tmzZ9WnTx8NGDAg23ILFy7UpUuXdP/99+cauCXp6NGjql+/vkJDQ3Xo0CEL9wQAAAC4vlxyy7DSpUsTtoEbWN++fZWcnKxt27Zp8+bNOn/+vMqXL682bdro/vvvV79+/WSz2bItV5hTywEAAIAbgVOnl98IOL0cAAD8Y3B6OVC8cHr5DSG/mTL/N8wFAAAAAAAFQugGAAAAAMAihG4AAAAAACzikoHUgCLHtWpA8cK1agAAAJLo6QYAAAAAwDKEbgAAAAAALELoBgAAAADAIk5f052WlqYPP/xQmzdv1vHjx5WWlpbjfDabTV999ZXTBQIAAAAAUFI5FbqPHj2qjh076rfffpNhGHnOa7PZnCoMAAAAAICSzqnQ/Z///Ee//vqrWrVqpaefflp16tRRmTJlXF0bAAAAAAAlmlOh+8svv1RISIg2bNggb29vV9cEAAAAAMANwamB1NLS0nTrrbcSuAEAAAAAyINTobtRo0b6888/XV0LAAAAAAA3FKdC95gxY7R9+3bFxcW5uh4AAAAAAG4YTl3Tfcstt+jpp5/W3XffrVGjRqlz586qVq1ariOVh4SEFKpIAAAAAABKIqdCd1hYmGw2mwzD0Msvv6yXX34513ltNpsyMjKcLhAAAAAAgJLKqdDdrl077r8NAAAAAMA1OBW6Y2NjXVwGAAAAAAA3HqcGUgMAAAAAANfmVE/31U6ePKljx47JZrOpSpUqqlChgitWCwAAAABAiVaonu533nlHN910kypXrqybb75ZTZo0UeXKldWgQQO98847rqoRAAAAAIASyame7szMTN13331avny5DMNQ2bJlFRoaKkk6cuSI9u3bp8cee0wbNmzQJ598wqBrAAAAAIB/JKd6umfNmqVly5apTp06WrlypU6dOqVdu3Zp165dOnnypD7//HPVrVtXy5cv16xZs1xdMwAAAAAAJYJToXvevHny9/dXbGys7rrrrmztd955pzZu3KgyZcpo7ty5hS4SAAAAAICSyKnQ/csvv6hDhw4KDAzMdZ6goCB17NhRv/zyi9PFAQAAAABQkll6yzCu5QYAAAAA/JM5Fbrr1q2rTZs26eTJk7nO8/fff2vjxo2qW7eu08UBAAAAAFCSORW6o6KilJycrE6dOikuLi5be2xsrDp37qyUlBRFR0cXtkYAAAAAAEokp24ZNnz4cK1du1Zr1qxRhw4dFBQUpLCwMNlsNsXHxysxMVGGYeiOO+7Q8OHDXV0zAAAAAAAlglOh293dXZ9//rneeOMNvfnmm0pISNDx48fN9pCQED3xxBN66qmn5OZm6WXjAAAAAAAUW06Fbklyc3PT008/raeffloJCQk6duyYJCk4OFjVq1d3WYEAAAAAAJRUTofurKpXr07QBgAAAADgKpz7DQAAAACARfLV0z1kyBDZbDZNmDBBgYGBGjJkSL43YLPZ9N577zldIAAAAAAAJVW+Qvf8+fNls9k0ZswYBQYGav78+fneAKEbAAAAAPBPla/QvWnTJklXRiXP+jMAAAAAAMhdvkJ3REREnj8DAAAAAIDsnBpIbfPmzfr111+vOd9vv/2mzZs3O7MJAAAAAABKPKdCd2RkpF599dVrzjdp0iS1b9/emU0AAAAAAFDiOX3LMMMwXDIPAAAAAAA3Kkvv033s2DGVKVPGyk0AAAAAAFBs5WsgNUlauHChw88HDx7MNs0uIyNDBw4c0IYNG9SyZcvCVQgAAAAAQAmV79AdHR0tm80m6cq9t7/55ht98803uc5vGIa8vb31/PPPF75KAAAAAABKoHyH7ueff142m02GYeill17SzTffrJ49e+Y4r6enp4KDg9WlSxdVqVLFZcUCAAAAAFCS5Dt0x8TEmP9fsGCBOnXqpBdeeMGKmgAAAAAAuCE4NZBar1695Ofn5+paAAAAAAC4oTgVut9++23t2bPH1bUAAAAAAHBDcSp0V6tWTZmZma6uBQAAAACAG4pTofuee+5RXFycUlNTXV0PAAAAAAA3DKdCd0xMjEJCQnTHHXdo165drq4JAAAAAIAbQr5HL8+qZ8+e8vLy0jfffKPmzZurSpUqCgkJkbe3d7Z5bTabvvrqq0IXCgAAAABASeNU6I6NjTX/bxiGjh07pmPHjuU4r81mc6owAAAAAABKOqdCd3x8vKvrAAAAAADghuNU6A4NDXV1HQAAAAAA3HCcGkjNajNnzlTjxo3l7+8vf39/3X777VqzZo3ZbhiGYmJiFBwcLB8fH0VGRurnn38uwooBAAAAAMjOqZ5uuxMnTmjevHnasmWLjh07JpvNpipVqqhdu3aKiopS5cqVnVpvtWrV9Morr6hWrVqSpAULFqhnz57atWuXGjRooEmTJmnKlCmaP3++6tSpo/Hjx6tz5846cOCA/Pz8CrNLAAAAAAC4jM0wDMOZBT/99FMNHTpUqampunoVNptNfn5+mjt3rnr37u2SQsuXL6/JkydryJAhCg4O1siRIzVmzBhJUlpamgIDA/Xqq6/qkUceydf6UlJSFBAQoOTkZPn7+7ukRhShgdFFXQGArBbNL+oKAGTF+yRQvPA+eUPIb6Z06vTyHTt2qH///jp79qzuueceLV++XLt27dKuXbu0YsUK9e7dW2fPnlX//v21Y8cOp3dCki5fvqwlS5bo3Llzuv322xUfH6/ExER16dLFnMfLy0sRERHaunVrrutJS0tTSkqKwwMAAAAAACs5dXr5xIkTdfnyZX3yySfZerKbNGmiHj16mOH7lVde0dKlSwu8jb179+r222/XxYsXVaZMGS1fvlw33XSTGawDAwMd5g8MDNThw4fzrPnFF18scB0AAAAAADjLqZ7ur7/+Wq1atcrz1PFevXqpdevW2rJli1OF1a1bV7t379a2bdv06KOPKioqSr/88ovZfvX9vw3DyPOe4GPHjlVycrL5SEhIcKouAAAAAADyy6me7uTkZIWEhFxzvpCQEG3fvt2ZTcjT09McSK158+bavn27pk2bZl7HnZiYqCpVqpjzJyUlZev9zsrLy0teXl5O1QIAAAAAgDOc6ukOCgrS7t27rznf7t27FRQU5MwmsjEMQ2lpaQoPD1dQUJDWr19vtqWnpysuLk6tWrVyybYAAAAAAHAFp0J3165dtX//fj333HPZRi6XrgTkZ599Vvv371e3bt0KvP7//ve/2rJliw4dOqS9e/dq3Lhxio2N1cCBA2Wz2TRy5EhNmDBBy5cv108//aTo6Gj5+vpqwIABzuwOAAAAAACWcOr08ueee07Lli3ThAkTtGTJEt13330KCwuTzWZTfHy8PvroI8XHx6tChQp69tlnC7z+v/76S4MHD9bx48cVEBCgxo0ba+3atercubMkafTo0bpw4YKGDx+u06dPq0WLFlq3bh336AYAAAAAFCtO36d77969GjhwoH766acrK/r/g5jZV9eoUSMtWrRIDRs2dFGprsV9um8w3H8UKF64/yhQvPA+CRQvvE/eEPKbKZ3q6ZauhOo9e/YoNjZWW7Zs0bFjxyRJwcHBatu2rSIjI51dNQAAAAAANwSnQ7ddZGQkARsAAAAAgBw4NZBaTlJTU5Wamuqq1QEAAAAAUOIVKnR/8cUX6t69uwICAlS2bFmVLVtW/v7+6t69uz7//HNX1QgAAAAAQInkVOg2DENDhw5Vz5499eWXXyo1NVUBAQHy9/fX2bNn9eWXX6pXr16Kjo7O8ZZiAAAAAAD8EzgVuqdNm6Z58+apSpUqmjlzppKTk3Xq1CmdPn1aycnJmjlzpqpUqaL3339f06ZNc3XNAAAAAACUCE6F7lmzZsnX11dbtmzRI4884nB/bD8/Pz3yyCPasmWLfHx8NGvWLJcVCwAAAABASeJU6I6Pj1fHjh0VHh6e6zzh4eHq2LGj4uPjnS4OAAAAAICSzKnQXalSJXl6el5zPk9PT1WsWNGZTQAAAAAAUOI5Fbrvuecebdy4UadPn851nlOnTmnjxo3q1auXs7UBAAAAAFCiORW6x48frxo1aqhDhw7auHFjtvaNGzeqc+fOqlGjhiZMmFDoIgEAAAAAKIlKObNQz5495enpqZ07d6pz584qX768QkNDJUlHjhzRyZMnJUktW7ZUz549HZa12Wz66quvClk2AAAAAADFn1OhOzY21vy/YRg6efKkGbSz+vbbb7NNs9lszmwSAAAAAIASx6nQzYjkAAAAAABcm1Oh234qOQAAAAAAyJ1TA6kBAAAAAIBrc6qn2+7EiROaN2+etmzZomPHjslms6lKlSpq166doqKiVLlyZVfVCQAAAABAieN06P700081dOhQpaamyjAMh7bVq1fr//7v/zR37lz17t270EUCAAAAAFASOXV6+Y4dO9S/f3+dPXtW99xzj5YvX65du3Zp165dWrFihXr37q2zZ8+qf//+2rFjh6trBgAAAACgRHCqp3vixIm6fPmyPvnkk2w92U2aNFGPHj3M8P3KK69o6dKlLikWAAAAAICSxKme7q+//lqtWrXK89TxXr16qXXr1tqyZYvTxQEAAAAAUJI5FbqTk5MVEhJyzflCQkKUnJzszCYAAAAAACjxnArdQUFB2r179zXn2717t4KCgpzZBAAAAAAAJZ5Tobtr167av3+/nnvuuWwjl0uSYRh69tlntX//fnXr1q3QRQIAAAAAUBI5NZDac889p2XLlmnChAlasmSJ7rvvPoWFhclmsyk+Pl4fffSR4uPjVaFCBT377LOurhkAAAAAgBLBqdBdrVo1bdy4UQMHDtRPP/2kiRMnymazSZLZ892oUSMtWrRI1apVc121AAAAAACUIE6FbulKqN6zZ49iY2O1ZcsWHTt2TJIUHBystm3bKjIy0lU1AgAAAABQIjkVunv37q0qVaro7bffVmRkJAEbAAAAAIAcODWQ2urVq3Xy5ElX1wIAAAAAwA3FqdAdHh6uc+fOuboWAAAAAABuKE6F7v79+ysuLk6JiYmurgcAAAAAgBuGU6F77Nixatu2rSIiIrR8+XJdunTJ1XUBAAAAAFDiOTWQWt26dZWZmamEhAT17dtXNptNlStXlre3d7Z5bTabfv/990IXCgAAAABASeNU6D506JDDz4ZhcKo5AAAAAABXcSp0Z2ZmuroOAAAAAABuOE5d0w0AAAAAAK6tQD3dq1ev1ooVK5SQkCAvLy81btxYDzzwgMLDw62qDwAAAACAEivfoXvgwIFasmSJpCvXcEvS559/rtdee01LlixRjx49rKkQAAAAAIASKl+h+7333tOHH36oUqVKafDgwWratKlSU1P1xRdf6Ntvv9X999+vw4cPKyAgwOp6AQAAAAAoMfIVuhcsWCA3NzetWbNGHTt2NKePHTtWDzzwgBYuXKhly5bpgQcesKxQAAAAAABKmnwNpLZ37161bNnSIXDb/fe//5VhGNq7d6/LiwMAAAAAoCTLV+hOSUlRzZo1c2yzT09JSXFdVQAAAAAA3ADyFboNw5C7u3vOK3C7sgru3Q0AAAAAgCPu0w0AAAAAgEXyHboXLFggd3f3HB82my3X9lKlCnQrcAAAAAAAbhj5TsT2e3MXlLPLAQAAAABQ0uUrdHO9NgAAAAAABcc13QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFikWIbuiRMn6tZbb5Wfn58qV66sXr166cCBAw7zGIahmJgYBQcHy8fHR5GRkfr555+LqGIAAAAAALIrlqE7Li5Ojz32mLZt26b169crIyNDXbp00blz58x5Jk2apClTpmj69Onavn27goKC1LlzZ6WmphZh5QAAAAAA/E+poi4gJ2vXrnX4ed68eapcubJ27typdu3ayTAMTZ06VePGjVPv3r0lSQsWLFBgYKAWL16sRx55pCjKBgAAAADAQbHs6b5acnKyJKl8+fKSpPj4eCUmJqpLly7mPF5eXoqIiNDWrVuLpEYAAAAAAK5WLHu6szIMQ6NGjVKbNm3UsGFDSVJiYqIkKTAw0GHewMBAHT58OMf1pKWlKS0tzfw5JSXFoooBAAAAALii2Pd0P/7449qzZ48+/PDDbG02m83hZ8Mwsk2zmzhxogICAsxH9erVLakXAAAAAAC7Yh26n3jiCa1cuVKbNm1StWrVzOlBQUGS/tfjbZeUlJSt99tu7NixSk5ONh8JCQnWFQ4AAAAAgIpp6DYMQ48//riWLVumjRs3Kjw83KE9PDxcQUFBWr9+vTktPT1dcXFxatWqVY7r9PLykr+/v8MDAAAAAAArFctruh977DEtXrxYn332mfz8/Mwe7YCAAPn4+Mhms2nkyJGaMGGCateurdq1a2vChAny9fXVgAEDirh6AAAAAACuKJahe+bMmZKkyMhIh+nz5s1TdHS0JGn06NG6cOGChg8frtOnT6tFixZat26d/Pz8rnO1AAAAAADkrFiGbsMwrjmPzWZTTEyMYmJirC8IAAAAAAAnFMtrugEAAAAAuBEQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwSLEM3Zs3b9bdd9+t4OBg2Ww2rVixwqHdMAzFxMQoODhYPj4+ioyM1M8//1w0xQIAAAAAkItiGbrPnTunJk2aaPr06Tm2T5o0SVOmTNH06dO1fft2BQUFqXPnzkpNTb3OlQIAAAAAkLtSRV1ATrp3767u3bvn2GYYhqZOnapx48apd+/ekqQFCxYoMDBQixcv1iOPPHI9SwUAAAAAIFfFsqc7L/Hx8UpMTFSXLl3MaV5eXoqIiNDWrVuLsDIAAAAAABwVy57uvCQmJkqSAgMDHaYHBgbq8OHDuS6XlpamtLQ08+eUlBRrCgQAAAAA4P8rcT3ddjabzeFnwzCyTctq4sSJCggIMB/Vq1e3ukQAAAAAwD9ciQvdQUFBkv7X422XlJSUrfc7q7Fjxyo5Odl8JCQkWFonAAAAAAAlLnSHh4crKChI69evN6elp6crLi5OrVq1ynU5Ly8v+fv7OzwAAAAAALBSsbym++zZszp48KD5c3x8vHbv3q3y5csrJCREI0eO1IQJE1S7dm3Vrl1bEyZMkK+vrwYMGFCEVQMAAAAA4KhYhu4dO3aoffv25s+jRo2SJEVFRWn+/PkaPXq0Lly4oOHDh+v06dNq0aKF1q1bJz8/v6IqGQAAAACAbIpl6I6MjJRhGLm222w2xcTEKCYm5voVBQAAAABAAZW4a7oBAAAAACgpCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWKREh+4ZM2YoPDxc3t7eatasmbZs2VLUJQEAAAAAYCqxofujjz7SyJEjNW7cOO3atUtt27ZV9+7ddeTIkaIuDQAAAAAASSU4dE+ZMkVDhw7Vgw8+qPr162vq1KmqXr26Zs6cWdSlAQAAAAAgqYSG7vT0dO3cuVNdunRxmN6lSxdt3bq1iKoCAAAAAMBRqaIuwBl///23Ll++rMDAQIfpgYGBSkxMzHGZtLQ0paWlmT8nJydLklJSUqwrFNfPpfSirgBAVry2AsUL75NA8cL75A3BniUNw8hzvhIZuu1sNpvDz4ZhZJtmN3HiRL344ovZplevXt2S2gDgH+2TD4u6AgAAii/eJ28oqampCggIyLW9RIbuihUryt3dPVuvdlJSUrbeb7uxY8dq1KhR5s+ZmZk6deqUKlSokGtQB3D9pKSkqHr16kpISJC/v39RlwMAQLHDeyVQvBiGodTUVAUHB+c5X4kM3Z6enmrWrJnWr1+ve+65x5y+fv169ezZM8dlvLy85OXl5TCtbNmyVpYJwAn+/v58kAAAIA+8VwLFR1493HYlMnRL0qhRozR48GA1b95ct99+u2bNmqUjR45o2LBhRV0aAAAAAACSSnDo/te//qWTJ0/qpZde0vHjx9WwYUOtXr1aoaGhRV0aAAAAAACSSnDolqThw4dr+PDhRV0GABfw8vLSCy+8kO0yEAAAcAXvlUDJZDOuNb45AAAAAABwiltRFwAAAAAAwI2K0A0AAAAAgEUI3QAAAAAAWITQDaBYmDFjhsLDw+Xt7a1mzZppy5YtRV0SAADFwubNm3X33XcrODhYNptNK1asKOqSABQAoRtAkfvoo480cuRIjRs3Trt27VLbtm3VvXt3HTlypKhLAwCgyJ07d05NmjTR9OnTi7oUAE5g9HIARa5Fixa65ZZbNHPmTHNa/fr11atXL02cOLEIKwMAoHix2Wxavny5evXqVdSlAMgneroBFKn09HTt3LlTXbp0cZjepUsXbd26tYiqAgAAAFyD0A2gSP3999+6fPmyAgMDHaYHBgYqMTGxiKoCAAAAXIPQDaBYsNlsDj8bhpFtGgAAAFDSELoBFKmKFSvK3d09W692UlJStt5vAAAAoKQhdAMoUp6enmrWrJnWr1/vMH39+vVq1apVEVUFAAAAuEapoi4AAEaNGqXBgwerefPmuv322zVr1iwdOXJEw4YNK+rSAAAocmfPntXBgwfNn+Pj47V7926VL19eISEhRVgZgPzglmEAioUZM2Zo0qRJOn78uBo2bKg33nhD7dq1K+qyAAAocrGxsWrfvn226VFRUZo/f/71LwhAgRC6AQAAAACwCNd0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAEqcv//+W88995yaNm2qsmXLytfXV7Vq1dLDDz+sn376qajLc7nY2FjZbDZFR0c7TJ8/f75sNptiYmIKtL7t27drwIABql69ujw9PVW2bFnVrVtXffr00VtvvaXk5GTXFe9CkZGRstlsOnToUFGXAgBAvhG6AQAlyoYNG1S7dm2NHz9eR48eVUREhO666y55eHho9uzZuvnmm/XKK68UdZnF1nvvvaeWLVvqww8/lLe3t7p3765u3bopICBAK1eu1IgRI7Rv374iqc1msyksLKxItl0UwsLCZLPZiroMAIDFShV1AQAA5Nf27dt155136tKlS5o4caL+/e9/q1Sp/72VrV69WoMGDdLYsWPl6+urESNGFGG1xc/Ro0f12GOPyTAMzZkzR0OGDHEIfX///bfef/99lS1btuiKzMPChQt1/vx5Va1atahLAQAg3+jpBgCUCIZhKCoqSunp6XrppZf0zDPPOARuSbrjjju0YsUK2Ww2jRkzRocPHy6iaoun1atXKy0tTa1bt9bQoUOz9bJWrFhRTz31lOrVq1dEFeYtJCRE9erVk4eHR1GXAgBAvhG6AQAlwpo1a7Rv3z5VrVpVY8aMyXW+du3a6d5779XFixf19ttvS5IuXbqkChUqyNvbW2fOnMlxue+//142m02tW7fO1vb555+ra9eu5jrq1Kmj5557TmfPns02b9brjhcvXqyWLVvKz8/Pofd41apVGjJkiOrXry9/f3+VLl1aTZo00YQJE5SWllawA1MAJ06ckCRVqlSpwMuePXtWL730kho1aiRfX1/5+/srIiJCK1asyDbvoUOHZLPZFBkZqQsXLuiZZ55RaGiovLy8VKtWLb366qsyDMOc335tuiQdPnxYNpvNfERGRprz5XZNt/209IyMDL388suqVauWfHx8VL9+fc2bN8+cb+PGjWrfvr38/f1Vrlw53X///Tp58mSO+5uenq5p06bp1ltvlZ+fn0qXLq3bbrtN7733nkPtV9dw+fJlTZo0SXXq1JGXl5eqV6+uMWPGOPxe7dfo278Uyrq//6TT6wHgn4LQDQAoEVavXi1Juvfee6/Z0zlgwABJV4K6JHl4eOjee+9VWlqaPv300xyXWbx4sSRp4MCBDtOffvpp9ejRQ5s3b1bDhg115513Kj09XePHj1dkZKTOnTuX4/omTpyowYMHy9PTU3fddZcaNmxotg0dOlSffPKJAgIC1K1bN7Vt21YJCQkaN26c7rjjDl2+fDkfR6TgqlWrJkn66quv9Ntvv+V7ub/++kstWrTQCy+8oNOnT6tz585q0aKFdu7cqXvuuSfXa+jT09PVpUsXzZo1S/Xr11f79u119OhRPfPMM3ruuefM+WrVqqWoqChJUunSpRUVFWU+unXrlu8677vvPk2ePFk1a9ZUu3btFB8fryFDhmjevHlaunSpunbtqtTUVHXu3FmlS5fW+++/r169emUL0efOnVOnTp00cuRIHTp0SG3atFFkZKQOHjyoBx98UI8++miuNQwcOFAvvfSSqlWrpi5duig1NVWTJk3S0KFDzXmCgoIUFRWl0qVLS5LD/vbt2zff+wsAKCEMAABKgNatWxuSjPfff/+a8yYkJBiSDDc3NyM9Pd0wDMPYvHmzIcno0KFDtvkvX75sVKlSxShVqpRx4sQJc/pHH31kSDKaNm1qxMfHm9PT09ONhx9+2JBk/Pvf/3ZYV0REhCHJ8Pb2NmJjY3Osb/ny5cbZs2cdpqWkpBh33XWXIclYsGCBQ9umTZsMSUZUVJTD9Hnz5hmSjBdeeOFah8QwDMM4c+aMUalSJbO+vn37GtOnTzd27txpZGRk5Lpc9+7dDUnG6NGjzeNpGIbx+++/GzVr1jTc3d2NH3/80ZweHx9vSDIkGW3btnU4ptu3bzdKlSpl+Pr6GqmpqQ7bkWSEhobmWof92Gb9XdiXk2Q0bNjQSEhIMKdv3LjRkGRUqVLFqFChgrF06VKzLTk52WjQoIEhydi4caPD+h599FFDkjF48GCHGpOSkowWLVoYkowvvvgixxrq16/vUN8ff/xhlCtXzpBkHDx40GGZ0NBQg49iAHDjo6cbAFAi2E8Drly58jXntZ8+nZmZqVOnTkmS2rRpo9DQUMXGxurYsWMO82/cuFHHjx9X165dVbFiRXP6hAkTJEkffvihw2m/Hh4emjZtmoKCgjRnzhxlZmZmq2Ho0KGKiIjIsb5evXqZvZx2fn5+euONNyRJn3322TX30RkBAQFau3at6tatq4sXL2rp0qV6/PHH1axZM1WoUEHDhg3Ldmx2796tNWvWqFWrVnrllVcczjKoUaOGXn/9dV2+fFlz5szJtj03NzfNmTPH4Zg2b95c3bt31/nz57Vjxw6X7t+bb75p9uZLUvv27XXLLbfo+PHjuvPOO9WnTx+zzd/fXw8//LAkKS4uzpyelJSkOXPmKDw8XLNnz1aZMmXMtkqVKundd9+VJPPfq7311lsOz5Xw8HANGjRIkrRly5bC7yQAoMQhdAMASgTj/58CbORwPW1u80oyrxW22Wzq37+/MjMztWTJEof5czq1PCkpST/++KPq16+vunXrZtuGt7e3mjdvrjNnzuR4qnaPHj3yrPG3337TtGnT9MQTT2jIkCGKjo7Wyy+/bLZZ5ZZbbtHPP/+sVatW6fHHH1fz5s3l4eGh5ORkvfvuu2ratKkOHDhgzr9+/XpJUs+ePXO8vVWbNm0kXRlZ/mphYWGqU6dOtun2acePH3fJPkmSp6dnjl9y1KhRQ5LUuXPnbG01a9bMVkdcXJwuXbqkbt26ycvLK9syTZo0kZ+fX4776+Hh4XANup0V+wsAKDkI3QCAEsHeW5qUlHTNee0DhtlsNpUrV86cbg/VixYtMqelpaVp2bJlKl26tHr27GlOtw9ytW/fPoeBrrI+vvjiC0lXbrV1tZCQkBxrMwxDTz/9tOrWrauRI0dq+vTpmjdvnhYsWKCFCxdKklJTU6+5j4Xh7u6uO+64Q2+99Za2b9+uv//+W7Nnz1aFChWUlJSkxx9/3JzXPmjZmDFjcjwG9t9LTscga69zVvbeY1cOGhcUFCQ3t+wfa+xnFOR0mzF7W9Y67Ps7c+bMXH/vqampOe5vlSpV5O7unm26FfsLACg5uE83AKBEaNKkib755hvt3LlTgwcPznPenTt3SpIaNGjgcDp0w4YN1bhxY/3www/av3+/6tWrp1WrVik5OVmDBg2Sr6+vOa99MLMqVaqoS5cueW6vQoUK2aZ5e3vnOO9HH32kKVOmqFq1apo6dapuv/12VapUSR4eHkpPT5eXl1e+evNdyd/fXw8++KCCgoJ09913a9OmTTp//rx8fX3N49C2bVuz1zgnWU8ht8upZ9wq19pWfmux72/Tpk3VuHFjl9YAAPhnInQDAEqE7t27a8aMGVq6dKkmT56c5wjm9tPFcxr5euDAgdqzZ48WL16sl156KddRy+29tEFBQZo/f76L9kJavny5pCs9qXfddZdD2x9//OGy7TjDfmr05cuXdebMGfn6+prHoW/fvhoxYkQRVnd92Pc3MjJSU6ZMKeJqAAA3Ak4vBwCUCHfccYfq1q2ro0eP6tVXX811vs2bN2vp0qXy9PTUY489lq19wIABstlsWrx4sVJSUrRq1SpVrlxZnTp1cpivWrVqqlu3rvbs2aP4+HiX7cfp06clSdWrV8/W9vHHH7tsOzm5Vg/677//LunK9dH2nmv7ccnpftyu5uHhoYyMDMu3k5f27dvL3d1dX3zxhWW3brPz9PSUpCLfZwCAtQjdAIASwc3NTfPnz5eHh4eef/55vfrqq9lC0Zo1a8z7Lr/yyisOo0jbVatWTe3atdPvv/+uMWPG6OLFi/rXv/6lUqWyn/z17LPP6vLly+rTp49++umnbO2///675s6dW6D9sA+qNWvWLIcQvGXLFk2ePLlA6yqomTNn6pFHHslxX44dO6Zhw4ZJku68804zELZs2VIdO3bUpk2b9NRTT+ns2bMOy2VmZmrdunX6+uuvC11fcHCw/vrrL505c6bQ63JW1apVFR0drd9++02DBw/O8drtrVu3mveNL4zg4GBJchi4DgBw4yF0AwBKjJYtW2rlypXy9/fXM888o+DgYPXq1Uv/+te/dNNNN+mOO+5QcnKyXn75ZT311FO5rsd+Kvk777zj8PPVBg0apNGjR2vXrl26+eabdeutt+q+++5Tt27dVL9+fdWqVUtvvvlmgfZhxIgRKl26tGbMmKGGDRuqf//+ateunSIiIszQa5X09HTNmjVLjRo1Uo0aNdSzZ09z++Hh4dq2bZvCw8M1bdo0h+UWLVqkxo0ba+rUqQoNDVXHjh3Vr18/tW3bVkFBQeratatLbv/Vo0cPZWRk6JZbbtGgQYP04IMPWv5FRE7efPNNtW/fXh9++KFq1Kihdu3aqV+/foqMjFS1atXUunVrrVu3rtDbsY9w37FjR/Xv318PPvignnnmmUKvFwBQvHBNNwCgROnWrZt5u60vvvhCGzdu1KVLl1SlShU9+OCDeuKJJ645ANa9996rJ554QmlpaapZs6ZatGiR67yvvvqqunbtqunTp+vbb7/Vjz/+qHLlyqlatWr6z3/+o379+hWo/jp16mj79u0aM2aMvvvuO61cuVJ169bVu+++q4ceekivvfZagdZXEEOGDFG1atW0du1a7dy5U99++61Onz4tPz8/NWvWTD169NBjjz0mPz8/h+UCAwO1bds2vfPOO/roo4+0fft2paenq0qVKmratKl69uyp++67r9D1TZw4UYZh6LPPPtNHH32kjIwMRURE6D//+U+h110Qvr6+WrdunRYsWKD3339fe/bs0XfffafKlSurZs2aevLJJ9W/f/9Cb2fEiBE6ffq0PvzwQ3366ae6dOmSQkND9corr7hgLwAAxYXNuN5DpAIAAAAA8A/B6eUAAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFjk/wF6FY96jHle2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create distribution results for our target variable\n",
    "overall_sentiment_distribution=round(df_reviews_by_listing['Overall_sentiment'].value_counts(normalize=True).sort_index()*100, 2)\n",
    "\n",
    "# Determine figure size\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create barplot\n",
    "ax = overall_sentiment_distribution.plot.bar(color='#FF5A5F')\n",
    "\n",
    "# Add labels\n",
    "plt.title('Overall Sentiment Distribution for All Reviews', fontsize=18)\n",
    "plt.xlabel('Overall Sentiment', fontsize=15)\n",
    "plt.ylabel('Proportion (%)', fontsize=15)\n",
    "plt.bar_label(ax.containers[0], size=14)\n",
    "plt.xticks(rotation = 360)\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "plt.savefig('Overall_Sentiment_Distribution.jpg', dpi =300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad260a",
   "metadata": {},
   "source": [
    "The current sentiment score distribution (37:63) is not as balanced as it was analysed in the listing level. This imbalance indicates a potential bias in the dataset, with a disproportionate number of reviews having positive sentiments compared to negative sentiments.\n",
    "\n",
    "To address this issue, we plan to **downsample** reviews with positive sentiments in the next sampling stage. This approach aims to create a more even distribution of the target variable, enhancing the model's ability to generalize across different sentiment categories. However, to avoid potential **data leakage**, we will only perform sampling on the **training** dataset after **Train Test Split**.\n",
    "\n",
    "We also conclude that this imbalance may be attributed to positive review bias, where guests are more inclined to leave positive reviews. Additionally, the reinforcement effect further amplifies this bias, as the presence of positive reviews may influence subsequent guests to also leave positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7486abc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f94cdd",
   "metadata": {},
   "source": [
    "## Train Test Split <a id='a3.4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f9bcf",
   "metadata": {},
   "source": [
    "The modelling process starts by splitting our dataset into training and testing sets. This procedure is fundamental for the effective evaluation of our model performance.\n",
    "\n",
    "The training data is implemented upon which our model is built and refined, and the testing data provides the benchmark for assessing the model's predictive performance on unseen data. This ensures us to mitigate the risk of **overfitting**, as our model will not just memorize the data pattern but rather learns to generalize on new, unseen data.\n",
    "\n",
    "Additionally, it is important that this splitting process must precede any data transformation steps including random sampling, text vectorization and scaling to prevent potential **data leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c631f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows obtained in the training data is 376564, with 38 feature columns.\n",
      "The number of rows obtained in the testing data is 94141, with 38 feature columns.\n"
     ]
    }
   ],
   "source": [
    "# Split test data as 30% of all data, determine random state to make sure every split is the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Show the number of rows for training and testing dataset\n",
    "print(f'The number of rows obtained in the training data is {X_train.shape[0]}, with {X_train.shape[1]} feature columns.')\n",
    "print(f'The number of rows obtained in the testing data is {X_test.shape[0]}, with {X_train.shape[1]} feature columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d789bf1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317e2c8a",
   "metadata": {},
   "source": [
    "## Sampling <a id='a3.3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0b998",
   "metadata": {},
   "source": [
    "Since we have a large training dataset with nearly 330k rows and an imbalanced target variable, we will perform **downsampling** on the training dataset by randomly select a balanced number of rows for both positive labelled rows and negative labelled rows.\n",
    "\n",
    "We will eventually select 3% of the original training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b797218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that can perform downsampling on training data and make it perfectly balanced\n",
    "def downsample_train(X_train, y_train, target, proportion, rn):\n",
    "    '''\n",
    "    Function only works on target variable as binary column. \n",
    "    \n",
    "    Returns downsampled X_train and y_train which\n",
    "    has downsampled to specified proportion of original\n",
    "    data, also makes sure y_train is balanced\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - X_train: dataframe, splitted feature training data\n",
    "    - y_train: dataframe, splitted farget training data\n",
    "    - target: str, target variable name\n",
    "    - proportion: float, specified downsample proportion of total training data\n",
    "    - rn: int, random_state number\n",
    "    \n",
    "    RETURNS:\n",
    "    - X_train_sample: Downsampled X_train\n",
    "    - y_train_sample: Downsampled y_train\n",
    "    \n",
    "    '''\n",
    "    # Specify number of rows for each class \n",
    "    num_rows_each = round(proportion*X_train.shape[0]/2)\n",
    "    \n",
    "    # Temporarily concatenate X_train and y_train back to dataframe format\n",
    "    df_train = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    # Split classes\n",
    "    df_pos = df_train[df_train[target] == 1]\n",
    "    df_neg = df_train[df_train[target] == 0]\n",
    "    \n",
    "    # Resplit X and y for both two classes\n",
    "    X_pos, y_pos = df_pos.drop(target, axis=1), df_pos[target]\n",
    "    X_neg, y_neg = df_neg.drop(target, axis=1), df_neg[target]\n",
    "    \n",
    "    # Select randomized samples from each class\n",
    "    X_pos_sample, y_pos_sample = resample(X_pos, y_pos, random_state=rn, n_samples = num_rows_each, replace=False, stratify=y_pos)\n",
    "    X_neg_sample, y_neg_sample = resample(X_neg, y_neg, random_state=rn, n_samples = num_rows_each, replace=False, stratify=y_neg)\n",
    "    \n",
    "    # Concatenate back downsampled data\n",
    "    X_train_sample = pd.concat([X_pos_sample, X_neg_sample], axis=0)\n",
    "    y_train_sample = pd.concat([y_pos_sample, y_neg_sample], axis=0)\n",
    "    \n",
    "    return X_train_sample, y_train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9718d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return downsampled training data\n",
    "X_train_sample, y_train_sample = downsample_train(X_train, y_train, 'Overall_sentiment', 0.03, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f0e590b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current proportion of each sentiment score class is (%)\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: Overall_sentiment, dtype: float64\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "The current number of rows in the training data is 11296\n"
     ]
    }
   ],
   "source": [
    "# Check for current target variable distribution\n",
    "print('The current proportion of each sentiment score class is (%)')\n",
    "print((y_train_sample.value_counts(normalize=True))*100)\n",
    "print('\\n--------------------------------------------\\n')\n",
    "print(f'The current number of rows in the training data is {X_train_sample.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c215c",
   "metadata": {},
   "source": [
    "Thus we have downsampled our training data nearly 330k (376561) rows to just over 10k (11296), and we also obtained a balanced training data. We will hope that this will potentially improve our model performance and also help the models to generalize well in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338d9c3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24082bd3",
   "metadata": {},
   "source": [
    "## Helper Function <a id='a3.5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fdf2d",
   "metadata": {},
   "source": [
    "Our dataset includes multiple non-review features, in the later text vectorization stage, it is not necessary for these columns to be processed by the vectorizers. Hence, we require a helper function to handle these numerical columns separately, and generate a column transformer based on our selection on different text vectorizers including `CountVectorizer` and `TfidfVectorizer`. \n",
    "\n",
    "Additionally, the numerical features in our dataset vary across different ranges, necessitating the scaling of data during the modeling stage. However, the text vectorizers will return a sparse matrix after transformation, while scalers like `StandardScaler` and `MinMaxScaler` require a dense array as input. Hence, we'll also need a function to convert the sparse matrix into a dense array.\n",
    "\n",
    "This code is borrowed from [Allistair Cota](https://github.com/allistaircota/rate_my_restaurant/blob/main/notebooks/NB3-Modelling.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b04ae5",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "| Vectorizer  | Scaler| \n",
    "|:-------:|:--------:|\n",
    "|[TF-IDF Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) |  [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)  |\n",
    "|[Count-Vectorizer](https://en.wikipedia.org/wiki/Bag-of-words_model)  |[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03dfb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical column names\n",
    "numeric_columns = X.select_dtypes(exclude='object').columns.to_list()\n",
    "\n",
    "def define_col_trans(input_text, vectorizer):\n",
    "    '''\n",
    "    Returns a ColumnTransformer which first performs a \n",
    "    passthrough on the numeric columns, then applies\n",
    "    a vectorizer on the `text` column\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - input_text: str, to name the vectorizer tuple\n",
    "    - vectorizer: Sklearn text vectorizer\n",
    "    \n",
    "    RETURNS:\n",
    "    - col_trans: sklearn ColumnTransformer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    col_trans = ColumnTransformer([\n",
    "        ('numeric', 'passthrough', numeric_columns), # numerical_columns defined above\n",
    "        (input_text, vectorizer, 'comments') # 'comments' as review text feature column\n",
    "    ])\n",
    "    \n",
    "    return col_trans\n",
    "\n",
    "def convert_to_array(sparse_matrix):\n",
    "    '''\n",
    "    Converts sparse matrix to dense array\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - sparse_matrix: scipy.sparse.csr_matrix or numpy array\n",
    "    \n",
    "    RETURNS:\n",
    "    - If sparse_matrix is not a scipy.sparse.csr_matrix,\n",
    "      sparse_matrix is returned. Else, returns the dense array\n",
    "      form of sparse_matrix.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if type(sparse_matrix) == csr_matrix:\n",
    "    \n",
    "        return sparse_matrix.toarray()\n",
    "    \n",
    "    else:\n",
    "        return sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0f405",
   "metadata": {},
   "source": [
    "#### Text vectorizer list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5772b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformers\n",
    "ct_bow = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))\n",
    "ct_tfidf = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a4670",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da07db",
   "metadata": {},
   "source": [
    "# Baseline Model <a id='a4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff30002",
   "metadata": {},
   "source": [
    "As we are developing the best performed models for predicting the class of guest sentiments, it is crucial to establish a baseline model for comparison. We will utilise a **Dummy Classifier** model, which makes predictions without accessing dataset features, essentially performing random guessing. By establishing this baseline, we can decide that any model performing worse than the baseline model will not proceed to further analysis.\n",
    "\n",
    "**Run Time**: 3mins 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f725f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transfomed_dummy : (11296, 537)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize data using Bag of Words Vectorizer\n",
    "bow_vec = CountVectorizer(max_features = 500, # Only obtain top 500 features based on vectorizer results\n",
    "                            min_df=5, # Feature occurency should be bigger than 5 in the corpus\n",
    "                            tokenizer=customized_tokenizer)\n",
    "\n",
    "# Fit and transform on the vectorizer to training data\n",
    "X_train_tfidf_d = bow_vec.fit_transform(X_train_sample['comments']).toarray()\n",
    "\n",
    "# Transform on both training data and testing data\n",
    "X_test_tfidf_d = bow_vec.transform(X_test['comments']).toarray()\n",
    "\n",
    "# Reset Index before concatenating\n",
    "X_train_sample_reset_index = X_train_sample.reset_index(drop=True)\n",
    "X_test_reset_index = X_test.reset_index(drop=True)\n",
    "\n",
    "# Merge the resulting arrays with the original numeric features\n",
    "X_train_tfidf_d_transformed = pd.concat([X_train_sample_reset_index.drop(['comments'], axis=1),\n",
    "                                         pd.DataFrame(X_train_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis=1)\n",
    "\n",
    "X_test_tfidf_d_transformed = pd.concat([X_test_reset_index.drop(['comments'], axis=1), \n",
    "                                        pd.DataFrame(X_test_tfidf_d, columns=[i for i in bow_vec.get_feature_names_out()])], axis = 1)\n",
    "\n",
    "# Print shape of the vectorized training feature data\n",
    "print(f'X_train_transfomed_dummy : {X_train_tfidf_d_transformed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acaddbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score (%) for the Baseline Model is: 37.38 %\n"
     ]
    }
   ],
   "source": [
    "# # Dummy Classifier - Baseline Model\n",
    "# Instantiate Dummy Classifier\n",
    "dummy_classifier = DummyClassifier()\n",
    "\n",
    "# Fit the Dummy Classifier on Training data\n",
    "dummy_classifier.fit(X_train_tfidf_d_transformed, y_train_sample)\n",
    "\n",
    "# Predict the fitted model on Testing Data\n",
    "y_predict_d = dummy_classifier.predict(X_test_tfidf_d_transformed)\n",
    "\n",
    "# Print F1 score\n",
    "print(f'The Accuracy Score (%) for the Baseline Model is: {round(accuracy_score(y_test, y_predict_d)*100, 2)} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da9703",
   "metadata": {},
   "source": [
    "#### Classification report <a id='a4.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bd46eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      1.00      0.54     35188\n",
      "           1       0.00      0.00      0.00     58953\n",
      "\n",
      "    accuracy                           0.37     94141\n",
      "   macro avg       0.19      0.50      0.27     94141\n",
      "weighted avg       0.14      0.37      0.20     94141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report to see specific classification evaluation metrics scores\n",
    "baseline_report = classification_report(y_test, y_predict_d)\n",
    "print(baseline_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bcce12",
   "metadata": {},
   "source": [
    "Based on the findings from the classification report, the model classification accuracy score achieved by the dummy classifier is **37.38%**. This baseline performance indicates that future models should aim to surpass this threshold to be considered effective. Therefore, our goal for future models is to achieve an accuracy score higher than 38%, indicating improved predictive capability and accuracy in classifying sentiments. \n",
    "\n",
    "**Note**: This result is reflected by the actual proportion of negative sentiments in the testing dataset as Dummy Classifier takes random guesses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ccdaa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45724545",
   "metadata": {},
   "source": [
    "# Modelling <a id='a5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6788586",
   "metadata": {},
   "source": [
    "After completing data cleaning, pre-processing, and model setup stages, we are ready to train models and make predictions. To determine the best-performing model, we will utilize **GridSearchCV** to find the optimal model with the best hyperparameters. Machine learning metrics and models to be used in our modeling process include:\n",
    "\n",
    "- Text Vectorizer: Bag of Words, TF-IDF\n",
    "- Scaler: StandardScaler\n",
    "- Models: Logistic Regression, Decision Tree Classifier, Random Forest Classifier.\n",
    "\n",
    "Note that for performance purposes, we will be vectorizing the datasets outside of grid search. We will then fit combinations of models to the training data that has been transformed by two types of text vectorizations. During the fitting process, **5-fold cross-validation** will be performed to improve model performance and interpretability. Finally, the model with the highest average validation accuracy score will be selected and evaluated at the end of each GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4550b",
   "metadata": {},
   "source": [
    "## GridSearch_1: General Sweep <a id='a5.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfd48ba",
   "metadata": {},
   "source": [
    "During the first GridSearch, we will be searching for optimal hyperparameters over wide range implementing on the **Logistic Regresion** and **Decision Tree Classifier**. This GridSearch will be run and fitted on two vectorized training sets defined above and we will evaluate the model performances with a brief summary. The selections of models and parameters are summarized below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac438a43",
   "metadata": {},
   "source": [
    "|    Models   |    Hyperparameters   |   Ranges/Options  |\n",
    "|:-------------:|:-------------:|:-------------:|\n",
    "|    **TfidfVectorizer**     |     max_df   |    0.95     |\n",
    "|                  |     min_df  |    5       |\n",
    "|       **CountVectorizer**           |     max_df  |    0.95       |\n",
    "|                  |     min_df  |    5       |\n",
    "|    **Logistic Regression**     |    C     |    0.001, 0.01, 0.1, 1, 10    |\n",
    "|         |    penalty     |    'none', 'l2'     | \n",
    "|    **Decision Tree Classifier**     |     max_depth    |     2, 8, 32, 64, 128    |\n",
    "|                 |    min_samples_leaf     |     2, 4, 8    |\n",
    "|                 |     min_samples_split    |     2, 4, 8    |\n",
    "|                 |     criterion    |     'gini', 'entropy'    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731a793",
   "metadata": {},
   "source": [
    "**Run time**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83a4586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on training data using two types of vectorizers\n",
    "X_train_ct_bow = ct_bow.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf= ct_tfidf.fit_transform(X_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def9d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First GridSearch\n",
    "\n",
    "# Define base pipeline\n",
    "pipeline_1 = Pipeline([\n",
    "    ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Instantiate Pipeline with grid of parameters\n",
    "grid_param_1 = [\n",
    "    \n",
    "    # Logistic Regression\n",
    "    {\n",
    "        'model'              : [LogisticRegression()],\n",
    "        'model__C'           : [0.001, 0.01, 0.1, 1, 10], # C parameter to control penalty weights\n",
    "        'model__penalty'     : ['none', 'l2'], # Control penalty types, l1: Lasso, l2: Ridge\n",
    "        'model__random_state': [123], # Control gradient descent starting point\n",
    "        'model__max_iter'    : [10000] # Make sure model iterates\n",
    "    },\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    {\n",
    "        'model'                   : [DecisionTreeClassifier()],\n",
    "        'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "        'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "        'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "        'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "        'model__random_state'     :[123] # Control randomness of the estimator\n",
    "    }\n",
    "]\n",
    "\n",
    "# Use GridSearch\n",
    "grid_1 = GridSearchCV(estimator=pipeline_1, # Define GridSearch estimator pipeline\n",
    "                     param_grid=grid_param_1, # Define parameter grid\n",
    "                     cv=5, # Define 5-fold cross-validation\n",
    "                     n_jobs=-2) \n",
    "\n",
    "# Fit the grid on training data\n",
    "fittedgrid_1_bow = grid_1.fit(X_train_ct_bow, y_train_sample)\n",
    "fittedgrid_1_tfidf = grid_1.fit(X_train_ct_tfidf, y_train_sample)\n",
    "\n",
    "# Save GridSearch_1 as pickle files\n",
    "joblib.dump(fittedgrid_1_bow, 'data/fittedgridsearch_1_bow.pkl')\n",
    "joblib.dump(fittedgrid_1_tfidf, 'data/fittedgridsearch_1_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafdf6c7",
   "metadata": {},
   "source": [
    "#### Selected model results with Bag of Words transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f07e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid_1_bow = joblib.load('data/fittedgridsearch_1_bow.pkl' )\n",
    "fittedgrid_1_tfidf = joblib.load('data/fittedgridsearch_1_tfidf.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e90ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_bow.best_estimator_)\n",
    "\n",
    "# Print Crossvalidated Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_bow.score(X_train_ct_bow, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "\n",
    "# Vectorize on training data before the implementation of the fittedgrid\n",
    "X_test_ct_bow = ct_bow.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_bow.score(X_test_ct_bow, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e636d",
   "metadata": {},
   "source": [
    "#### Selected model results with TF-IDF transformed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd248403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--------------------\\n')\n",
    "print(fittedgrid_1_tfidf.best_estimator_)\n",
    "\n",
    "# Print Score\n",
    "print('\\n--------------------\\n')\n",
    "print(f'Best Model Train Score (%): {round(fittedgrid_1_tfidf.score(X_train_ct_tfidf, y_train_sample)*100.00, 2)}') \n",
    "\n",
    "# Print Testing Score\n",
    "print('\\n--------------------\\n')\n",
    "# Vectorize on training data before the implementation of the fittedgrid\n",
    "X_test_ct_tfidf = ct_tfidf.transform(X_test)\n",
    "print(f'Best Model Test Score (%): {round(fittedgrid_1_tfidf.score(X_test_ct_tfidf, y_test)*100, 2)}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47876bee",
   "metadata": {},
   "source": [
    "#### Function for Extracting Key Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plotting function for extracting key features\n",
    "def extract_key_words_plot(grid, ct, n_words, ct_prefix):\n",
    "    '''\n",
    "    Returns a barplot that shows the top words with\n",
    "    highest coefficients in the selected best model\n",
    "    in the fitted GridSearch\n",
    "    \n",
    "    PARAMETERS:\n",
    "    - grid: Fitted resulted Grid\n",
    "    - ct: Column Transformer\n",
    "    - n_words: int, Number of words that will be shown in the plot\n",
    "    - ct_prefix: str, The prefix of the word features\n",
    "    \n",
    "    RETURNS:\n",
    "    - two barplots that show the top indicating words and listing features for the best model selected\n",
    "    \n",
    "    '''  \n",
    "    # Extract the best model from grid search result\n",
    "    best_model= grid.best_estimator_\n",
    "    \n",
    "    # Extract feature coefficients out of best model in the resulted grid\n",
    "    coefficients = best_model.named_steps['model'].feature_importances_\n",
    "    \n",
    "    # Extract feature names from column transformer\n",
    "    feature_names = ct.get_feature_names_out()\n",
    "    \n",
    "    # Generate column indicate if the feature is numerical or word related\n",
    "    if_word=[]\n",
    "    for i in range(len(feature_names)):\n",
    "        if feature_names[i][0] == 'n':\n",
    "            if_word.append(0)\n",
    "        else:\n",
    "            if_word.append(1)\n",
    "    \n",
    "    # create dataframe contains feature names with corresponding coefficients resulted from best model\n",
    "    df_features = pd.DataFrame({'coefficients':coefficients, 'feature_names': feature_names, 'if_word': if_word})     \n",
    "    \n",
    "    # Split into numerical feature dataframe and word feature daraframe\n",
    "    df_word = df_features[df_features['if_word']==1]\n",
    "    df_num =  df_features[df_features['if_word']==0]\n",
    "    \n",
    "    # Order the features based on coefficients and remove prefix\n",
    "    df_word = df_word.sort_values('coefficients', ascending=False).reset_index(drop=True).loc[:n_words-1]\n",
    "    df_num = df_num.sort_values('coefficients', ascending=False).reset_index(drop=True).loc[:n_words-5]\n",
    "    \n",
    "    # Plot separate plots for word features and numerical features on two subplots\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(30,10))  # one row, two columns \n",
    "    \n",
    "    # Word Features plot\n",
    "    plt.subplot(1,2, 1)  # slot 1\n",
    "    plt.barh(width=df_word['coefficients'], y=df_word['feature_names'].str.replace(ct_prefix+'__', ''), color='#FF5A5F')\n",
    "    plt.title(f'Top {n_words} Indicating words', fontsize=25)\n",
    "    plt.ylabel('Word Features', fontsize=18)\n",
    "    plt.xlabel('Model Coefficients', fontsize=15)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    \n",
    "    # Numerical Features plot\n",
    "    plt.subplot(1,2, 2)  # slot 2\n",
    "    plt.barh(width=df_num['coefficients'], y=df_num['feature_names'].str.replace('numeric__', ''), color='#FF5A5F')\n",
    "    plt.title(f'Top {n_words-4} Indicating Listing Features', fontsize=25)\n",
    "    plt.ylabel('Listing Features', fontsize=18)\n",
    "    plt.xlabel('Model Coefficients', fontsize=15)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=20)\n",
    "    ax=plt.gca()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('feature_extraction.jpg', dpi =300)\n",
    "    plt.show()\n",
    "\n",
    "# Extract function as pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff6ab8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot graphs for bow fitted grid with bow transformed data\n",
    "extract_key_words_plot(fittedgrid_1_tfidf, ct_tfidf, 10, 'ct_tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df879c",
   "metadata": {},
   "source": [
    "#### GridSearch_1 Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cab12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c3740cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "659ecc65",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202f5eb",
   "metadata": {},
   "source": [
    "## GridSearch_2 : Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047f8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1f739c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [11296, 376561]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:52\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:806\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    804\u001b[0m     refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit\n\u001b[1;32m--> 806\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    807\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    809\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [11296, 376561]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Second GridSearch\n",
    "# Define column transformers with bigrams and trigrams for better interpretability\n",
    "ct_bow_ngram = define_col_trans('ct_bow',  CountVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 3)))\n",
    "ct_tfidf_ngram = define_col_trans('ct_tfidf',  TfidfVectorizer(max_df=0.95, min_df=5, tokenizer=customized_tokenizer, ngram_range=(2, 2)))\n",
    "\n",
    "# Fit and transform on training data using two types of vectorizers\n",
    "X_train_ct_bow_ngram = ct_bow_ngram.fit_transform(X_train_sample)\n",
    "X_train_ct_tfidf_ngram= ct_tfidf_ngram.fit_transform(X_train_sample)\n",
    "\n",
    "\n",
    "# Define base pipeline\n",
    "pipeline_2 = Pipeline([\n",
    "    ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Instantiate Pipeline with grid of parameters\n",
    "grid_param_2 = [\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    {\n",
    "        'model'                   : [DecisionTreeClassifier()],\n",
    "        'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "        'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "        'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "        'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "        'model__random_state'     :[123] # Control randomness of the estimator\n",
    "    },\n",
    "    \n",
    "    # Random Forest\n",
    "    {\n",
    "        'model'                   : [RandomForestClassifier()],\n",
    "        'model__n_estimators'     : [10,20,30,40,50], # Control number of trees in the forest\n",
    "        'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "        'model__min_samples_leaf' : [2,3,4], # Control minimum number of samples at a leaf node\n",
    "        'model__min_samples_split': [1,2,3], # Control minimum number of samples split at a leaf node\n",
    "        'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "        'model__random_state'     :[123] # Control randomness of the estimator  \n",
    "    }  \n",
    "]\n",
    "\n",
    "# Use GridSearch\n",
    "grid_2 = GridSearchCV(estimator=pipeline_2, # Define GridSearch estimator pipeline\n",
    "                     param_grid=grid_param_2, # Define parameter grid\n",
    "                     cv=5, # Define 5-fold cross-validation\n",
    "                     n_jobs=-2) \n",
    "\n",
    "# Fit the grid on training data\n",
    "fittedgrid_2_bow = grid_2.fit(X_train_ct_bow_ngram, y_train_sample)\n",
    "fittedgrid_2_tfidf = grid_2.fit(X_train_ct_tfidf_ngram, y_train_sample)\n",
    "\n",
    "# Save GridSearch_1 as pickle files\n",
    "joblib.dump(fittedgrid_2_bow, 'fittedgridsearch_2_bow.pkl')\n",
    "joblib.dump(fittedgrid_2_tfidf, 'fittedgridsearch_2_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab674bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8294bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca39901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fd0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# First GridSearch\n",
    "\n",
    "# Define base pipeline\n",
    "pipeline_1 = Pipeline([\n",
    "    ('sparse_to_dense', FunctionTransformer(convert_to_array, accept_sparse=True)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Instantiate Pipeline with grid of parameters\n",
    "grid_param_1 = [\n",
    "    \n",
    "    # Logistic Regression\n",
    "    {\n",
    "        'model'              : [LogisticRegression()],\n",
    "        'model__C'           : [0.001, 0.01, 0.1, 1, 10], # C parameter to control penalty weights\n",
    "        'model__penalty'     : ['none', 'l2'], # Control penalty types, l1: Lasso, l2: Ridge\n",
    "        'model__random_state': [123], # Control gradient descent starting point\n",
    "        'model__max_iter'    : [10000] # Make sure model iterates\n",
    "    },\n",
    "    \n",
    "    # Decision Tree Classifier\n",
    "    {\n",
    "        'model'                   : [DecisionTreeClassifier()],\n",
    "        'model__max_depth'        : [2, 8, 32, 64, 128], # Control number of tree splits/depth\n",
    "        'model__min_samples_leaf' : [2, 4, 8], # Control minimum number of samples at a leaf node\n",
    "        'model__min_samples_split': [2, 4, 8], # Control minimum number of samples split at a leaf node\n",
    "        'model__criterion'        : ['gini', 'entropy'], # Control the function to measure the quality of a split\n",
    "        'model__random_state'     :[123] # Control randomness of the estimator\n",
    "    }\n",
    "]\n",
    "\n",
    "# Use GridSearch\n",
    "grid_1 = GridSearchCV(estimator=pipeline_1, # Define GridSearch estimator pipeline\n",
    "                     param_grid=grid_param_1, # Define parameter grid\n",
    "                     cv=5, # Define 5-fold cross-validation\n",
    "                     n_jobs=-2) \n",
    "\n",
    "# Fit the grid on training data\n",
    "fittedgrid_1_bow = grid_1.fit(X_train_ct_bow, y_train_sample)\n",
    "fittedgrid_1_tfidf = grid_1.fit(X_train_ct_tfidf, y_train_sample)\n",
    "\n",
    "# Save GridSearch_1 as pickle files\n",
    "joblib.dump(fittedgrid_1_bow, 'fittedgridsearch_1_bow.pkl')\n",
    "joblib.dump(fittedgrid_1_tfidf, 'fittedgridsearch_1_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c3d894b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2981e92c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch 1 Cross Validation Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.916607</td>\n",
       "      <td>0.002984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.915280</td>\n",
       "      <td>0.002640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.915280</td>\n",
       "      <td>0.002640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.915280</td>\n",
       "      <td>0.002640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.914217</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 8, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>19</td>\n",
       "      <td>{'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 8, 'model__min_samples_split': 2, 'model__random_state': 123}</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  \\\n",
       "83                1   \n",
       "82                1   \n",
       "91                1   \n",
       "92                1   \n",
       "74                1   \n",
       "73                1   \n",
       "84                7   \n",
       "75                7   \n",
       "93                7   \n",
       "85               10   \n",
       "96               10   \n",
       "78               10   \n",
       "95               10   \n",
       "87               10   \n",
       "86               10   \n",
       "77               10   \n",
       "76               10   \n",
       "94               10   \n",
       "88               19   \n",
       "97               19   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                params  \\\n",
       "83   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "82   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "91  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "92  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "74   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "73   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "84   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "75   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "93  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 2, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "85   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "96  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "78   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "95  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "87   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 8, 'model__random_state': 123}   \n",
       "86   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "77   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 4, 'model__random_state': 123}   \n",
       "76   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 32, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "94  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 4, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "88   {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 64, 'model__min_samples_leaf': 8, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "97  {'model': DecisionTreeClassifier(criterion='entropy', max_depth=32, min_samples_leaf=2,\n",
       "                       random_state=123), 'model__criterion': 'entropy', 'model__max_depth': 128, 'model__min_samples_leaf': 8, 'model__min_samples_split': 2, 'model__random_state': 123}   \n",
       "\n",
       "    mean_test_score  std_test_score  \n",
       "83         0.916607        0.002984  \n",
       "82         0.916607        0.002984  \n",
       "91         0.916607        0.002984  \n",
       "92         0.916607        0.002984  \n",
       "74         0.916607        0.002984  \n",
       "73         0.916607        0.002984  \n",
       "84         0.915280        0.002640  \n",
       "75         0.915280        0.002640  \n",
       "93         0.915280        0.002640  \n",
       "85         0.914217        0.004909  \n",
       "96         0.914217        0.004909  \n",
       "78         0.914217        0.004909  \n",
       "95         0.914217        0.004909  \n",
       "87         0.914217        0.004909  \n",
       "86         0.914217        0.004909  \n",
       "77         0.914217        0.004909  \n",
       "76         0.914217        0.004909  \n",
       "94         0.914217        0.004909  \n",
       "88         0.897397        0.005658  \n",
       "97         0.897397        0.005658  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) #set dataframes with expanded columns to view full parameters\n",
    "\n",
    "# Show results in a dataframe\n",
    "gs1_results_df = pd.DataFrame(fittedgrid_1_bow.cv_results_).sort_values('mean_test_score', ascending=False) #rank by mean_test_score\n",
    "gs1_results = gs1_results_df[['rank_test_score', 'params', 'mean_test_score', 'std_test_score']].sort_values('mean_test_score', ascending=False) # Order by highest mean_test_score/5 fold cross validation\n",
    "print(\"GridSearch 1 Cross Validation Results\")\n",
    "gs1_results.head(20) # top 10 cv results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
